/*
 * Copyright (c) 1999-2013 Mark D. Hill and David A. Wood
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are
 * met: redistributions of source code must retain the above copyright
 * notice, this list of conditions and the following disclaimer;
 * redistributions in binary form must reproduce the above copyright
 * notice, this list of conditions and the following disclaimer in the
 * documentation and/or other materials provided with the distribution;
 * neither the name of the copyright holders nor the names of its
 * contributors may be used to endorse or promote products derived from
 * this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

machine(MachineType:Directory, "MESI Two Level directory protocol", interface="AbstractStreamAwareController")
 : DirectoryMemory * directory;
  Cycles to_mem_ctrl_latency := 1;
  Cycles response_latency := 1;
  Cycles directory_latency := 6;

  MessageBuffer * requestToDir, network="From", virtual_network="0",
       vnet_type="request";
  MessageBuffer * responseToDir, network="From", virtual_network="1",
       vnet_type="response";
  MessageBuffer * responseFromDir, network="To", virtual_network="1",
       vnet_type="response";
  MessageBuffer * requestFromDir, network="To", virtual_network="0",
       vnet_type="request"; // Request from Dir to L2.

  MessageBuffer * requestToMemory;
  MessageBuffer * responseFromMemory;

  /**
   * ! Sean: StreamAwareCache
   * ! Ruby requires one virtual network per To/From buffer.
   * ! I use virtual_network 4 for stream migration request, but they
   * ! are actually the lowest priority.
   */

  MessageBuffer * streamIndirectFromMem, network="To", virtual_network="3",
    vnet_type="StreamIndirectRequest"; // this MC -> others
  MessageBuffer * streamIndirectToMem, network="From", virtual_network="3",
    vnet_type="StreamIndirectRequest"; // others -> this MC 
  
  MessageBuffer * streamMigrateFromMem, network="To", virtual_network="4",
    vnet_type="StreamMigrateRequest"; // this MC -> others
  MessageBuffer * streamMigrateToMem, network="From", virtual_network="4",
    vnet_type="StreamMigrateRequest"; // others -> this MC 

{
  // STATES
  state_declaration(State, desc="Directory states", default="Directory_State_I") {
    // Base states
    I, AccessPermission:Read_Write, desc="dir is the owner and memory is up-to-date, all other copies are Invalid";
    ID, AccessPermission:Busy, desc="Intermediate state for DMA_READ when in I";
    ID_W, AccessPermission:Busy, desc="Intermediate state for DMA_WRITE when in I";

    M, AccessPermission:Maybe_Stale, desc="memory copy may be stale, i.e. other modified copies may exist";
    IM, AccessPermission:Busy, desc="Intermediate State I>M";
    MI, AccessPermission:Busy, desc="Intermediate State M>I";
    M_DRD, AccessPermission:Busy, desc="Intermediate State when there is a dma read";
    M_DRDI, AccessPermission:Busy, desc="Intermediate State when there is a dma read";
    M_DWR, AccessPermission:Busy, desc="Intermediate State when there is a dma write";
    M_DWRI, AccessPermission:Busy, desc="Intermediate State when there is a dma write";

    // States to get data from Memory for StreamEngine. 
    I_GH, AccessPermission:Busy, desc="Intermediate State after seen GetH";
    I_GU, AccessPermission:Busy, desc="Intermediate State after seen GetU";
    I_GM, AccessPermission:Busy, desc="Intermediate State after seen STREAM_STORE";
    M_GM, AccessPermission:Busy, desc="Intermediate State of M after seen GetH/STREAM_STORE";
    M_GU, AccessPermission:Busy, desc="Intermediate State of M after seen GetU";
  }

  // Events
  enumeration(Event, desc="Directory events") {
    Fetch, desc="A memory fetch arrives";
    Data, desc="writeback data arrives";
    Memory_Data, desc="Fetched data from memory arrives";
    Memory_Ack, desc="Writeback Ack from memory arrives";
//added by SS for dma
    DMA_READ, desc="A DMA Read memory request";
    DMA_WRITE, desc="A DMA Write memory request";
    CleanReplacement, desc="Clean Replacement in L2 cache";

    GETH,           desc="Load data but not send to cache";
    GETU,           desc="Load data and directly send to L1";
    GETM,           desc="Write to Mem";
    STREAM_CONFIG,  desc="StreamConfig req";
    STREAM_FLOW,    desc="Flow control message for stream";
    STREAM_END,     desc="StreamEnd req";
    STREAM_COMMIT,  desc="StreamCommit req";
    STREAM_STORE,   desc="StreamStore req";
  }

  // TYPES

  // DirectoryEntry
  structure(Entry, desc="...", interface="AbstractCacheEntry", main="false") {
    State DirectoryState,          desc="Directory state";
    MachineID Owner;
  }

  // TBE entries for DMA requests
  structure(TBE, desc="TBE entries for outstanding DMA requests") {
    Addr PhysicalAddress, desc="physical address";
    State TBEState,        desc="Transient State";
    DataBlock DataBlk,     desc="Data to be written (DMA write only)";
    int Len,               desc="...";
    MachineID Requestor,   desc="The DMA engine that sent the request";

    DynamicStreamSliceIdVec sliceIds, desc="Stream slices meta-data";
    DataBlock streamStoreBlk,         desc="Buffer for the update data";
    NetDest Fetch_IDs,     desc="Set of Fetch Requestors";
    NetDest GetU_IDs,      desc="Set of GetU Requestors";
  }

  structure(TBETable, external="yes") {
    TBE lookup(Addr);
    void allocate(Addr);
    void deallocate(Addr);
    bool isPresent(Addr);
    bool functionalRead(Packet *pkt);
    int functionalWrite(Packet *pkt);
  }


  // ** OBJECTS **
  TBETable TBEs, template="<Directory_TBE>", constructor="m_number_of_TBEs";

  /**
   * ! Sean: StreamAwareCache
   */
  structure(LLCStreamEngine, external="yes", desc="Stream Engine at MC") {
    void receiveStreamConfigure(PacketPtr);
    void receiveStreamEnd(PacketPtr);
    void receiveStreamMigrate(LLCDynamicStreamPtr, bool);
    void receiveStreamFlow(DynamicStreamSliceId);
    void receiveStreamDataVec(Cycles, Addr, DynamicStreamSliceIdVec, DataBlock, DataBlock);
    void receiveStreamIndirectRequest(RequestMsg);
    void receiveStreamForwardRequest(RequestMsg);
    void receiveStreamCommit(DynamicStreamSliceId);
    void receiveStreamNDCRequest(PacketPtr);
  }

  LLCStreamEngine se, constructor="this, m_streamMigrateFromMem_ptr, m_requestToDir_ptr, m_streamIndirectFromMem_ptr, m_responseFromDir_ptr";

  Tick clockEdge();
  Tick cyclesToTicks(Cycles c);
  Cycles ticksToCycles(Tick t);

  void set_tbe(TBE tbe);
  void unset_tbe();
  void wakeUpBuffers(Addr a);
  void profileMsgDelay(int virtualNetworkType, Cycles c);
  void incrementLLCIndReqQueueStats();

  bool isStreamSublineEnabled();
  MessageSizeType getMessageSizeType(int);

  Entry getDirectoryEntry(Addr addr), return_by_pointer="yes" {
    Entry dir_entry := static_cast(Entry, "pointer", directory[addr]);

    if (is_valid(dir_entry)) {
      return dir_entry;
    }

    dir_entry := static_cast(Entry, "pointer",
                             directory.allocate(addr, new Entry));
    return dir_entry;
  }

  State getState(TBE tbe, Addr addr) {
    if (is_valid(tbe)) {
      return tbe.TBEState;
    } else if (directory.isPresent(addr)) {
      return getDirectoryEntry(addr).DirectoryState;
    } else {
      return State:I;
    }
  }

  void setState(TBE tbe, Addr addr, State state) {
    if (is_valid(tbe)) {
      tbe.TBEState := state;
    }

    if (directory.isPresent(addr)) {
      getDirectoryEntry(addr).DirectoryState := state;
    }
  }

  AccessPermission getAccessPermission(Addr addr) {
    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      DPRINTF(RubySlicc, "%s\n", Directory_State_to_permission(tbe.TBEState));
      return Directory_State_to_permission(tbe.TBEState);
    }

    if(directory.isPresent(addr)) {
      DPRINTF(RubySlicc, "%s\n", Directory_State_to_permission(getDirectoryEntry(addr).DirectoryState));
      return Directory_State_to_permission(getDirectoryEntry(addr).DirectoryState);
    }

    DPRINTF(RubySlicc, "%s\n", AccessPermission:NotPresent);
    return AccessPermission:NotPresent;
  }

  void functionalRead(Addr addr, Packet *pkt) {
    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      testAndRead(addr, tbe.DataBlk, pkt);
    } else {
      functionalMemoryRead(pkt);
    }
  }

  int functionalWrite(Addr addr, Packet *pkt) {
    int num_functional_writes := 0;

    TBE tbe := TBEs[addr];
    if(is_valid(tbe)) {
      num_functional_writes := num_functional_writes +
        testAndWrite(addr, tbe.DataBlk, pkt);
    }

    num_functional_writes := num_functional_writes + functionalMemoryWrite(pkt);
    return num_functional_writes;
  }

  void setAccessPermission(Addr addr, State state) {
    if (directory.isPresent(addr)) {
      getDirectoryEntry(addr).changePermission(Directory_State_to_permission(state));
    }
  }

  bool isGETRequest(CoherenceRequestType type) {
    return (type == CoherenceRequestType:GETS) ||
      (type == CoherenceRequestType:GET_INSTR) ||
      (type == CoherenceRequestType:GETX);
  }

  // ** OUT_PORTS **
  out_port(responseNetwork_out, ResponseMsg, responseFromDir);
  out_port(requestNetwork_out, RequestMsg, requestFromDir);
  out_port(memQueue_out, MemoryMsg, requestToMemory);

  // ! Sean: StreamAwareCache
  // For the stream migrate and indirect request.
  out_port(streamMigrateFromMem_out, StreamMigrateRequestMsg, streamMigrateFromMem);
  out_port(streamIndirectFromMem_out, RequestMsg, streamIndirectFromMem);

  // ** IN_PORTS **

  in_port(requestNetwork_in, RequestMsg, requestToDir, rank = 0) {
    if (requestNetwork_in.isReady(clockEdge())) {
      peek(requestNetwork_in, RequestMsg) {

        assert(in_msg.Destination.isElement(machineID));
        Addr lineAddr := makeLineAddress(in_msg.addr);

        if (isGETRequest(in_msg.Type)) {
          trigger(Event:Fetch, in_msg.addr, TBEs[in_msg.addr]);
        } else if (in_msg.Type == CoherenceRequestType:DMA_READ) {
          trigger(Event:DMA_READ, makeLineAddress(in_msg.addr),
                  TBEs[makeLineAddress(in_msg.addr)]);
        } else if (in_msg.Type == CoherenceRequestType:DMA_WRITE) {
          trigger(Event:DMA_WRITE, makeLineAddress(in_msg.addr),
                  TBEs[makeLineAddress(in_msg.addr)]);
        // ! Sean: StreamAwareCache.
        } else if (in_msg.Type == CoherenceRequestType:GETH) {
          trigger(Event:GETH, lineAddr, TBEs[lineAddr]);
        } else if (in_msg.Type == CoherenceRequestType:GETU) {
          trigger(Event:GETU, lineAddr, TBEs[lineAddr]);
        } else if (in_msg.Type == CoherenceRequestType:STREAM_CONFIG) {
          trigger(Event:STREAM_CONFIG, lineAddr, TBEs[lineAddr]);
        } else if (in_msg.Type == CoherenceRequestType:STREAM_FLOW) {
          trigger(Event:STREAM_FLOW, lineAddr, TBEs[lineAddr]);
        } else if (in_msg.Type == CoherenceRequestType:STREAM_COMMIT) {
          trigger(Event:STREAM_COMMIT, lineAddr, TBEs[lineAddr]);
        } else if (in_msg.Type == CoherenceRequestType:STREAM_END) {
          trigger(Event:STREAM_END, lineAddr, TBEs[lineAddr]);
        } else if (in_msg.Type == CoherenceRequestType:STREAM_STORE) {
          trigger(Event:STREAM_STORE, lineAddr, TBEs[lineAddr]);
        } else {
          DPRINTF(RubySlicc, "%s\n", in_msg);
          error("Invalid message");
        }
      }
    }
  }

  in_port(responseNetwork_in, ResponseMsg, responseToDir, rank = 1) {
    if (responseNetwork_in.isReady(clockEdge())) {
      peek(responseNetwork_in, ResponseMsg) {
        assert(in_msg.Destination.isElement(machineID));
        if (in_msg.Type == CoherenceResponseType:MEMORY_DATA) {
          trigger(Event:Data, in_msg.addr, TBEs[in_msg.addr]);
        } else if (in_msg.Type == CoherenceResponseType:ACK) {
          trigger(Event:CleanReplacement, in_msg.addr, TBEs[in_msg.addr]);
        } else {
          DPRINTF(RubySlicc, "%s\n", in_msg.Type);
          error("Invalid message");
        }
      }
    }
  }

  // off-chip memory request/response is done
  in_port(memQueue_in, MemoryMsg, responseFromMemory, rank = 2) {
    if (memQueue_in.isReady(clockEdge())) {
      peek(memQueue_in, MemoryMsg) {
        if (in_msg.Type == MemoryRequestType:MEMORY_READ) {
          trigger(Event:Memory_Data, in_msg.addr, TBEs[in_msg.addr]);
        } else if (in_msg.Type == MemoryRequestType:MEMORY_WB) {
          trigger(Event:Memory_Ack, in_msg.addr, TBEs[in_msg.addr]);
        } else {
          DPRINTF(RubySlicc, "%s\n", in_msg.Type);
          error("Invalid message");
        }
      }
    }
  }

  // ! Sean: StreamAwareCache
  // Stream indirect request.
  in_port(streamIndirectToMem_in, RequestMsg, streamIndirectToMem, rank = 1) {
    if(streamIndirectToMem_in.isReady(clockEdge())) {
      peek(streamIndirectToMem_in,  RequestMsg) {

        // This requestor is not the LLC bank generating this request,
        // but the host L1 controller to receive the data.
        // assert(machineIDToMachineType(in_msg.XXNewRewquestor.singleElement()) == MachineType:L1Cache);
        assert(in_msg.Destination.isElement(machineID));

        assert(in_msg.sliceIds.isValid());

        DPRINTF(RubyStream, "Received stream indirect request [%lu, +%lu) %#x.\n", 
          in_msg.sliceIds.singleSliceId().getStartIdx(),
          in_msg.sliceIds.singleSliceId().getNumElements(),
          in_msg.addr);
        // No matter the cache line status, 
        // simply enqueue the request to L1Request message buffer.

        // Can we do this?
        se.receiveStreamIndirectRequest(in_msg);

        // Dequeue from the indirect message buffer.
        incrementLLCIndReqQueueStats();
        Tick delay := streamIndirectToMem_in.dequeue(clockEdge());
        profileMsgDelay(3, ticksToCycles(delay));
      }
    }
  }

  // ! Sean: StreamAwareCache
  // Stream migrate request.
  in_port(streamMigrateToMem_in, StreamMigrateRequestMsg, streamMigrateToMem, rank = 0) {
    if(streamMigrateToMem_in.isReady(clockEdge())) {
      peek(streamMigrateToMem_in, StreamMigrateRequestMsg) {
        se.receiveStreamMigrate(in_msg.Stream, in_msg.IsCommit);
        Tick delay := streamMigrateToMem_in.dequeue(clockEdge());
        profileMsgDelay(3, ticksToCycles(delay));
      }
    }
  }

  // Actions
  action(a_sendAck, "a", desc="Send ack to L2") {
    peek(responseNetwork_in, ResponseMsg) {
      enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:MEMORY_ACK;
        out_msg.Sender := machineID;
        out_msg.Destination.add(in_msg.Sender);
        out_msg.MessageSize := MessageSizeType:Response_Control;
      }
    }
  }

  action(d_sendData, "d", desc="Send data to requestor") {
    peek(memQueue_in, MemoryMsg) {
      enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:MEMORY_DATA;
        out_msg.Sender := machineID;
        out_msg.Destination.add(in_msg.OriginalRequestorMachId);
        out_msg.DataBlk := in_msg.DataBlk;
        out_msg.Dirty := false;
        out_msg.MessageSize := MessageSizeType:Response_Data;

        Entry e := getDirectoryEntry(in_msg.addr);
        e.Owner := in_msg.OriginalRequestorMachId;
      }
    }
  }

  // Actions
  action(aa_sendAck, "aa", desc="Send ack to L2") {
    peek(memQueue_in, MemoryMsg) {
      enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:MEMORY_ACK;
        out_msg.Sender := machineID;
        out_msg.Destination.add(in_msg.OriginalRequestorMachId);
        out_msg.MessageSize := MessageSizeType:Response_Control;
      }
    }
  }

  action(j_popIncomingRequestQueue, "j", desc="Pop incoming request queue") {
    requestNetwork_in.dequeue(clockEdge());
  }

  action(k_popIncomingResponseQueue, "k", desc="Pop incoming request queue") {
    responseNetwork_in.dequeue(clockEdge());
  }

  action(l_popMemQueue, "q", desc="Pop off-chip request queue") {
    memQueue_in.dequeue(clockEdge());
  }

  action(kd_wakeUpDependents, "kd", desc="wake-up dependents") {
    wakeUpBuffers(address);
  }

  action(qf_queueMemoryFetchRequest, "qf", desc="Queue off-chip fetch request") {
    peek(requestNetwork_in, RequestMsg) {
      enqueue(memQueue_out, MemoryMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := MemoryRequestType:MEMORY_READ;
        out_msg.Sender := in_msg.XXNewRewquestor.singleElement();
        out_msg.MessageSize := MessageSizeType:Request_Control;
        out_msg.Len := 0;
      }
    }
  }

  action(qw_queueMemoryWBRequest, "qw", desc="Queue off-chip writeback request") {
    peek(responseNetwork_in, ResponseMsg) {
      enqueue(memQueue_out, MemoryMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := MemoryRequestType:MEMORY_WB;
        out_msg.Sender := in_msg.Sender;
        out_msg.MessageSize := MessageSizeType:Writeback_Data;
        out_msg.DataBlk := in_msg.DataBlk;
        out_msg.Len := 0;
      }
    }
  }

//added by SS for dma
  action(qf_queueMemoryFetchRequestDMA, "qfd", desc="Queue off-chip fetch request") {
    peek(requestNetwork_in, RequestMsg) {
      enqueue(memQueue_out, MemoryMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := MemoryRequestType:MEMORY_READ;
        out_msg.Sender := in_msg.XXNewRewquestor.singleElement();
        out_msg.MessageSize := MessageSizeType:Request_Control;
        out_msg.Len := 0;
      }
    }
  }

  action(p_popIncomingDMARequestQueue, "p", desc="Pop incoming DMA queue") {
    requestNetwork_in.dequeue(clockEdge());
  }

  action(dr_sendDMAData, "dr", desc="Send Data to DMA controller from directory") {
    peek(memQueue_in, MemoryMsg) {
      enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
        assert(is_valid(tbe));
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.DataBlk := in_msg.DataBlk;   // we send the entire data block and rely on the dma controller to split it up if need be
        out_msg.Destination.add(tbe.Requestor);
        out_msg.MessageSize := MessageSizeType:Response_Data;
      }
    }
  }

  action(qw_queueMemoryWBRequest_partial, "qwp",
         desc="Queue off-chip writeback request") {
    peek(requestNetwork_in, RequestMsg) {
      enqueue(memQueue_out, MemoryMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := MemoryRequestType:MEMORY_WB;
        out_msg.Sender := machineID;
        out_msg.MessageSize := MessageSizeType:Writeback_Data;
        out_msg.DataBlk := in_msg.DataBlk;
        out_msg.Len := in_msg.Len;
      }
    }
  }

  action(da_sendDMAAck, "da", desc="Send Ack to DMA controller") {
      enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
        assert(is_valid(tbe));
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:ACK;
        out_msg.Destination.add(tbe.Requestor);
        out_msg.MessageSize := MessageSizeType:Writeback_Control;
      }
  }

  action(z_stallAndWaitRequest, "z", desc="recycle request queue") {
    stall_and_wait(requestNetwork_in, address);
  }

  action(zz_recycleDMAQueue, "zz", desc="recycle DMA queue") {
    requestNetwork_in.recycle(clockEdge(), cyclesToTicks(recycle_latency));
  }

  action(inv_sendCacheInvalidate, "inv", desc="Invalidate a cache block") {
    peek(requestNetwork_in, RequestMsg) {
      enqueue(responseNetwork_out, ResponseMsg, directory_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:INV;
        out_msg.Sender := machineID;
        out_msg.Destination.add(getDirectoryEntry(address).Owner);
        out_msg.MessageSize := MessageSizeType:Response_Control;
      }
    }
  }

  action(invr_sendCacheInvalidateAsRequest, "invr", desc="Invalidate a cache block but as Request") {
    // Send out the INV request as a request to avoid deadlock.
    peek(requestNetwork_in, RequestMsg) {
      enqueue(requestNetwork_out, RequestMsg, directory_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceRequestType:INV;
        out_msg.XXNewRewquestor.add(machineID);
        out_msg.Destination.add(getDirectoryEntry(address).Owner);
        out_msg.MessageSize := MessageSizeType:Request_Control;
      }
    }
  }



  action(drp_sendDMAData, "drp", desc="Send Data to DMA controller from incoming PUTX") {
    peek(responseNetwork_in, ResponseMsg) {
      enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
        assert(is_valid(tbe));
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:DATA;
        out_msg.DataBlk := in_msg.DataBlk;   // we send the entire data block and rely on the dma controller to split it up if need be
        out_msg.Destination.add(tbe.Requestor);
        out_msg.MessageSize := MessageSizeType:Response_Data;
      }
    }
  }

  action(ss_recordFetchID, "\s\s", desc="Record Fetch for load response") {
    peek(requestNetwork_in, RequestMsg) {
      assert(is_valid(tbe));
      tbe.Fetch_IDs.add(in_msg.XXNewRewquestor.singleElement());
    }
  }
  action(su_recordGetUID, "su", desc="Record GetU for load response") {
    peek(requestNetwork_in, RequestMsg) {
      assert(is_valid(tbe));
      tbe.GetU_IDs.add(in_msg.XXNewRewquestor.singleElement());
      tbe.sliceIds.merge(in_msg.sliceIds);
    }
  }
  action(sh_recordGetHID, "sh", desc="Record GetH for load response") {
    peek(requestNetwork_in, RequestMsg) {
      assert(is_valid(tbe));
      tbe.sliceIds.merge(in_msg.sliceIds);
    }
  }
  action(sm_recordGetMID, "sm", desc="Record GetM for load response") {
    peek(requestNetwork_in, RequestMsg) {
      assert(is_valid(tbe));
      tbe.sliceIds.merge(in_msg.sliceIds);
      tbe.streamStoreBlk := in_msg.streamStoreBlk;
    }
  }

  action(v_allocateTBE, "v", desc="Allocate TBE") {
    peek(requestNetwork_in, RequestMsg) {
      TBEs.allocate(address);
      set_tbe(TBEs[address]);
      tbe.DataBlk := in_msg.DataBlk;
      tbe.PhysicalAddress := in_msg.addr;
      tbe.Len := in_msg.Len;
      tbe.Requestor := in_msg.XXNewRewquestor.singleElement();
      tbe.Fetch_IDs.clear();
      tbe.GetU_IDs.clear();
      tbe.sliceIds.clear();
    }
  }

  action(qw_queueMemoryWBRequest_partialTBE, "qwt",
         desc="Queue off-chip writeback request") {
    peek(responseNetwork_in, ResponseMsg) {
      enqueue(memQueue_out, MemoryMsg, to_mem_ctrl_latency) {
        out_msg.addr := tbe.PhysicalAddress;
        out_msg.Type := MemoryRequestType:MEMORY_WB;
        out_msg.Sender := in_msg.Sender;
        out_msg.MessageSize := MessageSizeType:Writeback_Data;
        out_msg.DataBlk := tbe.DataBlk;
        out_msg.Len := tbe.Len;
      }
    }
  }

  action(w_deallocateTBE, "w", desc="Deallocate TBE") {
    TBEs.deallocate(address);
    unset_tbe();
  }

  action(dt_writeDataToTBE, "dt", desc="Store data block into TBE.") {
    assert(is_valid(tbe));
    peek(memQueue_in, MemoryMsg) {
      tbe.DataBlk := in_msg.DataBlk;
    }
  }
  action(drt_writeL2RespDataToTBE, "drt", desc="Store L2 resp data block into TBE.") {
    assert(is_valid(tbe));
    peek(responseNetwork_in, ResponseMsg) {
      tbe.DataBlk := in_msg.DataBlk;
    }
  }
  action(net_notifyStreamEngineFromTBE, "net", desc="notify the stream engine from TBE") {
    assert(is_valid(tbe));
    if (tbe.sliceIds.isValid()) {
      se.receiveStreamDataVec(response_latency, address, tbe.sliceIds, tbe.DataBlk, tbe.streamStoreBlk);
    }
  }

  action(du_sendGetUData, "du", desc="Send Data to GETU Requestor from directory") {
    assert(is_valid(tbe));
    if (tbe.GetU_IDs.count() > 0) {
      enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
        out_msg.addr := address;
        out_msg.Type := CoherenceResponseType:DATA_EXCLUSIVE;
        out_msg.DataBlk := tbe.DataBlk;   // we send the entire data block and rely on the dma controller to split it up if need be
        out_msg.Destination := tbe.GetU_IDs;
        out_msg.MessageSize := MessageSizeType:Response_Data;
        // Copy the stream meta-data.
        out_msg.sliceIds := tbe.sliceIds;
        /**
         * ! Sean: StreamAwareCache.
         * Only transmit the required sub cache line.
         */
        if (isStreamSublineEnabled()) {
          out_msg.MessageSize := getMessageSizeType(tbe.sliceIds.firstSliceId().getSize());
        }
      }
    }
  }

  action(df_sendFetchData, "df", desc="Send Data to Fetch Requestor while has GetU") {
    assert(is_valid(tbe));
    if (tbe.Fetch_IDs.count() > 0) {
      assert(tbe.Fetch_IDs.count() == 1);
      peek(memQueue_in, MemoryMsg) {
        enqueue(responseNetwork_out, ResponseMsg, to_mem_ctrl_latency) {
          out_msg.addr := address;
          out_msg.Type := CoherenceResponseType:MEMORY_DATA;
          out_msg.Sender := machineID;
          out_msg.Destination := tbe.Fetch_IDs;
          out_msg.DataBlk := in_msg.DataBlk;
          out_msg.Dirty := false;
          out_msg.MessageSize := MessageSizeType:Response_Data;

          Entry e := getDirectoryEntry(address);
          e.Owner := tbe.Fetch_IDs.singleElement();
        }
      }
    }
  }

  action(rsc_receiveStreamConfig, "rsc", desc="Receive the StreamConfig") {
    peek(requestNetwork_in, RequestMsg) {
      DPRINTF(RubyStream, "Receive StreamConfig: %#x\n", in_msg.pkt);
      se.receiveStreamConfigure(in_msg.pkt);
    }
  }
  action(rsf_receiveStreamFlow, "rsf", desc="Receive the stream flow message") {
    peek(requestNetwork_in, RequestMsg) {
      se.receiveStreamFlow(in_msg.sliceIds.singleSliceId());
    }
  }
  action(rscmt_receiveStreamCommit, "rscmt", desc="Receive the stream commit message") {
    peek(requestNetwork_in, RequestMsg) {
      se.receiveStreamCommit(in_msg.sliceIds.singleSliceId());
    }
  }
  action(rse_receiveStreamEnd, "rse", desc="Receive the StreamEnd") {
    peek(requestNetwork_in, RequestMsg) {
      se.receiveStreamEnd(in_msg.pkt);
    }
  }


  // TRANSITIONS

//added by SS
  transition(M, CleanReplacement, I) {
    a_sendAck;
    k_popIncomingResponseQueue;
    kd_wakeUpDependents;
  }

  transition(M, Data, MI) {
    qw_queueMemoryWBRequest;
    k_popIncomingResponseQueue;
  }

  transition(MI, Memory_Ack, I) {
    aa_sendAck;
    l_popMemQueue;
    kd_wakeUpDependents;
  }


//added by SS for dma support
  transition(I, DMA_READ, ID) {
    v_allocateTBE;
    qf_queueMemoryFetchRequestDMA;
    j_popIncomingRequestQueue;
  }

  transition(ID, Memory_Data, I) {
    dr_sendDMAData;
    w_deallocateTBE;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  transition(I, DMA_WRITE, ID_W) {
    v_allocateTBE;
    qw_queueMemoryWBRequest_partial;
    j_popIncomingRequestQueue;
  }

  transition(ID_W, Memory_Ack, I) {
    da_sendDMAAck;
    w_deallocateTBE;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  transition({ID, ID_W, M_DRDI, M_DWRI, IM, MI}, {Fetch, Data} ) {
    z_stallAndWaitRequest;
  }

  transition({ID, ID_W, M_DRD, M_DRDI, M_DWR, M_DWRI, IM, MI}, {DMA_WRITE, DMA_READ} ) {
    zz_recycleDMAQueue;
  }


  transition(M, DMA_READ, M_DRD) {
    v_allocateTBE;
    inv_sendCacheInvalidate;
    j_popIncomingRequestQueue;
  }

  transition(M_DRD, Data, M_DRDI) {
    drp_sendDMAData;
    w_deallocateTBE;
    qw_queueMemoryWBRequest;
    k_popIncomingResponseQueue;
  }

  transition(M_DRDI, Memory_Ack, I) {
    aa_sendAck;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  transition(M, DMA_WRITE, M_DWR) {
    v_allocateTBE;
    inv_sendCacheInvalidate;
    j_popIncomingRequestQueue;
  }

  transition(M_DWR, Data, M_DWRI) {
    qw_queueMemoryWBRequest_partialTBE;
    k_popIncomingResponseQueue;
  }

  transition(M_DWRI, Memory_Ack, I) {
    aa_sendAck;
    da_sendDMAAck;
    w_deallocateTBE;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  /**
   * Sean: StreamAwareCache.
   */

  transition(I, GETH, I_GH) {
    v_allocateTBE;
    sh_recordGetHID;
    qf_queueMemoryFetchRequest;
    j_popIncomingRequestQueue;
  }
  transition(I_GH, GETH, I_GH) {
    sh_recordGetHID;
    j_popIncomingRequestQueue;
  }
  transition(I_GH, Fetch, IM) {
    ss_recordFetchID;
    j_popIncomingRequestQueue;
  }
  transition(I_GH, Memory_Data, I) {
    dt_writeDataToTBE;
    net_notifyStreamEngineFromTBE;
    w_deallocateTBE;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  transition(I, Fetch, IM) {
    v_allocateTBE;
    ss_recordFetchID;
    qf_queueMemoryFetchRequest;
    j_popIncomingRequestQueue;
  }
  transition(IM, GETU, IM) {
    su_recordGetUID;
    j_popIncomingRequestQueue;
  }
  transition(IM, Memory_Data, M) {
    dt_writeDataToTBE;
    net_notifyStreamEngineFromTBE;
    du_sendGetUData;
    df_sendFetchData;
    w_deallocateTBE;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  transition(I, GETU, I_GU) {
    v_allocateTBE;
    su_recordGetUID;
    qf_queueMemoryFetchRequest;
    j_popIncomingRequestQueue;
  }
  transition(I_GU, GETU, I_GU) {
    su_recordGetUID;
    j_popIncomingRequestQueue;
  }
  transition(I_GU, Fetch, IM) {
    ss_recordFetchID;
    j_popIncomingRequestQueue;
  }
  transition(I_GU, Memory_Data, I) {
    dt_writeDataToTBE;
    net_notifyStreamEngineFromTBE;
    du_sendGetUData;
    w_deallocateTBE;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  transition(M, Fetch) {
    inv_sendCacheInvalidate;
    z_stallAndWaitRequest;
  }

  // ! So far STREAM_STORE at I state is handled as a READ,
  // ! as we haven't distinguish RMW from normal STORE.
  // ! TODO: Really separate out RWM from normal STORE.
  transition(I, STREAM_STORE, I_GM) {
    v_allocateTBE;
    sm_recordGetMID;
    qf_queueMemoryFetchRequest;
    j_popIncomingRequestQueue;
  }
  transition(I_GM, {Memory_Ack, Memory_Data}, I) {
    dt_writeDataToTBE;
    net_notifyStreamEngineFromTBE;
    w_deallocateTBE;
    l_popMemQueue;
    kd_wakeUpDependents;
  }

  transition(M, GETH, M_GM) {
    v_allocateTBE;
    sh_recordGetHID;
    invr_sendCacheInvalidateAsRequest;
    j_popIncomingRequestQueue;
  }
  transition(M, STREAM_STORE, M_GM) {
    v_allocateTBE;
    sm_recordGetMID
    invr_sendCacheInvalidateAsRequest;
    j_popIncomingRequestQueue;
  }
  transition(M_GM, Data, M_DRDI) {
    drt_writeL2RespDataToTBE;
    net_notifyStreamEngineFromTBE;
    w_deallocateTBE;
    qw_queueMemoryWBRequest;
    k_popIncomingResponseQueue;
  }
  transition(M_GM, STREAM_STORE) {
    z_stallAndWaitRequest;
  }

  transition(M, GETU, M_GU) {
    v_allocateTBE;
    su_recordGetUID;
    invr_sendCacheInvalidateAsRequest;
    j_popIncomingRequestQueue;
  }
  transition(M_GU, Data, M_DRDI) {
    drt_writeL2RespDataToTBE;
    net_notifyStreamEngineFromTBE;
    du_sendGetUData;
    w_deallocateTBE;
    qw_queueMemoryWBRequest;
    k_popIncomingResponseQueue;
  }

  transition({I, ID, ID_W, M, IM, MI, M_DRD, M_DRDI, M_DWR, M_DWRI, I_GH, I_GU, I_GM}, STREAM_CONFIG) {
    rsc_receiveStreamConfig;
    j_popIncomingRequestQueue;
  }
  transition({I, ID, ID_W, M, IM, MI, M_DRD, M_DRDI, M_DWR, M_DWRI, I_GH, I_GU, I_GM}, STREAM_FLOW) {
    rsf_receiveStreamFlow;
    j_popIncomingRequestQueue;
  }
  transition({I, ID, ID_W, M, IM, MI, M_DRD, M_DRDI, M_DWR, M_DWRI}, STREAM_COMMIT) {
    rscmt_receiveStreamCommit;
    j_popIncomingRequestQueue;
  }
  transition({I, ID, ID_W, M, IM, MI, M_DRD, M_DRDI, M_DWR, M_DWRI, I_GH, I_GU, I_GM}, STREAM_END) {
    rse_receiveStreamEnd;
    j_popIncomingRequestQueue;
  }

}
