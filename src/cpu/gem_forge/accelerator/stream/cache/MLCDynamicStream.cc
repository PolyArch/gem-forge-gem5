#include "MLCDynamicStream.hh"

// Generated by slicc.
#include "mem/protocol/CoherenceMsg.hh"
#include "mem/protocol/RequestMsg.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/RubyStream.hh"

MLCDynamicStream::MLCDynamicStream(CacheStreamConfigureData *_configData,
                                   AbstractStreamAwareController *_controller,
                                   MessageBuffer *_responseMsgBuffer,
                                   MessageBuffer *_requestToLLCMsgBuffer)
    : stream(_configData->stream), history(_configData->history),
      controller(_controller), responseMsgBuffer(_responseMsgBuffer),
      requestToLLCMsgBuffer(_requestToLLCMsgBuffer), maxNumElements(256),
      headIdx(0), tailIdx(0), llcTailIdx(0) {

  // Initialize the buffer for 32 entries?
  while (this->tailIdx < this->maxNumElements) {
    this->allocateElement();
  }
  this->llcTailIdx = this->tailIdx;
  // Set the CacheStreamConfigureData to inform the LLC stream engine initial
  // credit.
  _configData->initAllocatedIdx = this->llcTailIdx;
}

void MLCDynamicStream::receiveStreamData(const ResponseMsg &msg) {
  const auto &streamMeta = msg.m_streamMeta;
  assert(streamMeta.m_valid && "Invalid stream meta-data for stream data.");
  auto stream = reinterpret_cast<Stream *>(streamMeta.m_stream);
  assert(this->stream == stream && "Unmatched static stream.");
  DPRINTF(RubyStream, "Receive stream data [%lu, %lu).\n",
          streamMeta.m_startIdx,
          streamMeta.m_startIdx + streamMeta.m_numElements);

  /**
   * Find the correct stream element and insert the data there.
   * Here we reversely search for it to save time.
   */
  for (auto element = this->elements.rbegin(), end = this->elements.rend();
       element != end; ++element) {
    if (element->startIdx == streamMeta.m_startIdx) {
      // Found the element.
      assert(element->numElements == streamMeta.m_numElements &&
             "Mismatch numElements.");
      element->setData(msg.m_DataBlk);
      this->advanceStream();
      return;
    }
  }

  assert(false &&
         "Failed to find the allocated stream element for stream data.");
}

void MLCDynamicStream::receiveStreamRequest(uint64_t idx) {
  DPRINTF(RubyStream, "Receive stream request idx %lu.\n", idx);

  // We should be ahead of the core.
  assert(this->tailIdx > idx && "MLCStream is behind the core?");

  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->elements.empty() && "Empty element list.");
  for (auto &element : this->elements) {
    if (element.startIdx == idx) {
      // Found the element.
      assert(element.coreStatus == MLCStreamElement::CoreStatusE::NONE &&
             "Already seen a request.");
      element.coreStatus = MLCStreamElement::CoreStatusE::WAIT;
      break;
    }
  }

  this->advanceStream();
}

void MLCDynamicStream::receiveStreamRequestHit(uint64_t idx) {
  DPRINTF(RubyStream, "Receive stream request hit idx %lu.\n", idx);

  while (this->tailIdx <= idx) {
    this->allocateElement();
  }
  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->elements.empty() && "Empty element list.");
  for (auto &element : this->elements) {
    if (element.startIdx == idx) {
      // Found the element.
      assert(element.coreStatus == MLCStreamElement::CoreStatusE::NONE &&
             "Already seen a request.");
      element.coreStatus = MLCStreamElement::CoreStatusE::DONE;
      break;
    }
  }
  this->advanceStream();
}

void MLCDynamicStream::advanceStream() {

  /**
   * Maybe let's make response in order?
   */
  while (!this->elements.empty() && this->elements.front().dataReady) {
    bool shouldPop = false;
    const auto &element = this->elements.front();
    if (element.coreStatus == MLCStreamElement::CoreStatusE::WAIT) {
      // Data already ready.
      this->makeResponse();
      shouldPop = true;
    } else if (element.coreStatus == MLCStreamElement::CoreStatusE::DONE) {
      // Simply drop the elements, as the element is
      // already served by upper-level cache.
      shouldPop = true;
    }

    if (shouldPop) {
      assert(this->headIdx == element.startIdx && "Illegal headIdx somehow.");
      this->headIdx += element.numElements;
      this->elements.pop_front();
    } else {
      // We made no progress.
      break;
    }
  }
  // Of course we need to allocate more elements.
  while (this->tailIdx - this->headIdx < this->maxNumElements) {
    this->allocateElement();
  }
  if (this->tailIdx - this->llcTailIdx > this->maxNumElements / 2) {
    // It's time for us to send more credit to LLC stream.
    this->sendCreditToLLC();
  }
}

void MLCDynamicStream::makeResponse() {
  assert(!this->elements.empty() && "Make response when there is no elements.");
  auto &element = this->elements.front();
  assert(element.dataReady && "Data should already be ready.");
  auto cpu = this->getStaticStream()->getCPU();
  auto paddr = cpu->translateAndAllocatePhysMem(element.vaddr);
  auto paddrLine = makeLineAddress(paddr);

  auto selfMachineId = this->controller->getMachineID();
  auto upperMachineId = MachineID(
      static_cast<MachineType>(selfMachineId.type - 1), selfMachineId.num);
  auto msg = std::make_shared<CoherenceMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Class = CoherenceClass_DATA_EXCLUSIVE;
  msg->m_Sender = selfMachineId;
  msg->m_Dest = upperMachineId;
  msg->m_MessageSize = MessageSizeType_Response_Data;

  Cycles latency(1); // Just use 1 cycle latency here.
  this->responseMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                   this->controller->cyclesToTicks(latency));

  DPRINTF(RubyStream, "Make MLCStreamResponse [%lu, %lu) %#x.\n",
          element.startIdx, element.startIdx + element.numElements, paddrLine);
}

void MLCDynamicStream::allocateElement() {
  auto historySize = this->history->history_size();
  uint64_t startIdx = this->tailIdx;
  int numElements = 1;
  Addr vaddr =
      (startIdx < historySize) ? (this->history->history(startIdx).addr()) : 0;
  Addr vaddrLine = makeLineAddress(vaddr);
  this->tailIdx++;
  while (this->tailIdx < historySize) {
    Addr nextVAddr = this->history->history(this->tailIdx).addr();
    Addr nextVAddrLine = makeLineAddress(nextVAddr);
    if (nextVAddrLine != vaddrLine) {
      break;
    }
    // This element is the same line, maybe we can merge.
    numElements++;
    this->tailIdx++;
  }

  DPRINTF(RubyStream, "Allocate MLCStreamElement [%lu, %lu).\n", startIdx,
          startIdx + numElements);

  this->elements.emplace_back(startIdx, numElements, vaddr);
}

void MLCDynamicStream::sendCreditToLLC() {
  // Find where is the LLC stream.
  auto historySize = this->history->history_size();
  Addr vaddr = (this->llcTailIdx < historySize)
                   ? (this->history->history(this->llcTailIdx).addr())
                   : 0;
  auto cpu = this->getStaticStream()->getCPU();
  auto paddr = cpu->translateAndAllocatePhysMem(vaddr);
  auto paddrLine = makeLineAddress(paddr);

  // Find the LLC bank.
  auto selfMachineId = this->controller->getMachineID();
  auto llcMachineId = this->controller->mapAddressToLLC(
      paddrLine, static_cast<MachineType>(selfMachineId.type + 1));

  // Send the flow control.
  DPRINTF(RubyStream,
          "MLC stream %#x extended %lu -> %lu, sent to LLC bank %d %#x.\n",
          this->getStaticStream(), this->llcTailIdx, this->tailIdx,
          llcMachineId.num, paddrLine);
  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_FLOW;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(llcMachineId);
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_streamMeta.m_valid = true;
  msg->m_streamMeta.m_stream =
      reinterpret_cast<uint64_t>(this->getStaticStream());
  msg->m_streamMeta.m_startIdx = this->llcTailIdx;
  msg->m_streamMeta.m_numElements = this->tailIdx - this->llcTailIdx;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->requestToLLCMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  // Update the record.
  this->llcTailIdx = this->tailIdx;
}