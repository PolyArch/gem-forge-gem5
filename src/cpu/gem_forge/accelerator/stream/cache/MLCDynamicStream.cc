#include "MLCDynamicStream.hh"

// Generated by slicc.
#include "mem/ruby/protocol/CoherenceMsg.hh"
#include "mem/ruby/protocol/RequestMsg.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

#include "cpu/gem_forge/accelerator/stream/stream_engine.hh"

#include "base/trace.hh"
#include "debug/MLCRubyStreamBase.hh"

#define DEBUG_TYPE MLCRubyStreamBase
#include "../stream_log.hh"

MLCDynamicStream::MLCDynamicStream(CacheStreamConfigureDataPtr _configData,
                                   AbstractStreamAwareController *_controller,
                                   MessageBuffer *_responseMsgBuffer,
                                   MessageBuffer *_requestToLLCMsgBuffer)
    : stream(_configData->stream), dynamicStreamId(_configData->dynamicId),
      config(_configData), isPointerChase(_configData->isPointerChase),
      isPseudoOffload(_configData->isPseudoOffload), controller(_controller),
      responseMsgBuffer(_responseMsgBuffer),
      requestToLLCMsgBuffer(_requestToLLCMsgBuffer),
      maxNumSlices(_controller->getMLCStreamBufferInitNumEntries()),
      headSliceIdx(0), tailSliceIdx(0),
      advanceStreamEvent([this]() -> void { this->advanceStream(); },
                         "MLC::advanceStream",
                         false /*delete after process. */) {

  /**
   * ! You should never call any virtual function in the
   * ! constructor/deconstructor.
   */

  // Schedule the first advanceStreamEvent.
  this->stream->getCPUDelegator()->schedule(&this->advanceStreamEvent,
                                            Cycles(1));
}

MLCDynamicStream::~MLCDynamicStream() {
  // We got to deschedule the advanceStreamEvent.
  if (this->advanceStreamEvent.scheduled()) {
    this->stream->getCPUDelegator()->deschedule(&this->advanceStreamEvent);
  }
}

void MLCDynamicStream::endStream() {
  for (auto &slice : this->slices) {
    if (slice.coreStatus == MLCStreamSlice::CoreStatusE::WAIT_DATA) {
      // Make a dummy response.
      // Ignore whether the data is ready.
      // ! For indirect stream, the sliceId may not have vaddr.
      // ! In such case, we set it from core's sliceId.
      // TODO: Fix this in a more rigorous way.
      if (slice.sliceId.vaddr == 0) {
        slice.sliceId.vaddr = slice.coreSliceId.vaddr;
      }
      this->makeResponse(slice);
    }
  }
}

void MLCDynamicStream::receiveStreamRequest(
    const DynamicStreamSliceId &sliceId) {
  MLC_SLICE_DPRINTF(sliceId, "Receive request to %#x. Tail %lu.\n",
                    sliceId.vaddr, this->tailSliceIdx);

  auto slice = this->findSliceForCoreRequest(sliceId);
  assert(slice->coreStatus == MLCStreamSlice::CoreStatusE::NONE &&
         "Already seen a request.");
  MLC_SLICE_DPRINTF(slice->sliceId, "Matched to request.\n");
  slice->coreStatus = MLCStreamSlice::CoreStatusE::WAIT_DATA;
  slice->coreWaitCycle = this->controller->curCycle();
  slice->coreSliceId = sliceId;
  if (slice->dataReady) {
    // Sanity check the address.
    // ! Core is line address.
    if (slice->coreSliceId.vaddr != makeLineAddress(slice->sliceId.vaddr)) {
      MLC_SLICE_PANIC(sliceId, "Mismatch between Core %#x and LLC %#x.\n",
                      slice->coreSliceId.vaddr, slice->sliceId.vaddr);
    }
    this->makeResponse(*slice);
  }
  this->advanceStream();
}

void MLCDynamicStream::receiveStreamRequestHit(
    const DynamicStreamSliceId &sliceId) {
  MLC_SLICE_DPRINTF(sliceId, "Receive request hit to %#x.\n", sliceId.vaddr);

  auto slice = this->findSliceForCoreRequest(sliceId);
  if (slice->coreStatus != MLCStreamSlice::CoreStatusE::NONE) {
    MLC_SLICE_PANIC(sliceId, "Already seen a request.");
  }
  slice->coreStatus = MLCStreamSlice::CoreStatusE::DONE;
  slice->coreSliceId = sliceId;
  this->advanceStream();
}

void MLCDynamicStream::popStream() {
  /**
   * So far we don't have a synchronization scheme between MLC and LLC if there
   * is no CoreUser, and that causes performance drop due to running too ahead.
   * Therefore, we try to have an ideal check that the LLCStream is ahead of me.
   * We only do this for direct streams.
   */
  uint64_t llcProgressElementIdx = UINT64_MAX;
  if (this->controller->isStreamIdeaSyncEnabled() &&
      this->getStaticStream()->isDirectMemStream()) {
    if (auto llcDynS =
            LLCDynamicStream::getLLCStream(this->getDynamicStreamId())) {
      llcProgressElementIdx =
          std::min(llcDynS->getNextSliceIdx(), llcProgressElementIdx);
    } else {
      // The LLC stream has not been created.
      llcProgressElementIdx = 0;
    }
    for (const auto &depEdge : this->config->depEdges) {
      if (depEdge.type == CacheStreamConfigureData::DepEdge::Type::SendTo) {
        if (auto llcDynS =
                LLCDynamicStream::getLLCStream(depEdge.data->dynamicId)) {
          llcProgressElementIdx =
              std::min(llcDynS->getNextSliceIdx(), llcProgressElementIdx);
        } else {
          // The LLC stream has not been created.
          llcProgressElementIdx = 0;
        }
      }
    }
  }

  /**
   * Maybe let's make release in order.
   * The slice is released once the core status is DONE or FAULTED.
   */
  while (!this->slices.empty()) {
    const auto &slice = this->slices.front();
    if (slice.coreStatus == MLCStreamSlice::CoreStatusE::DONE ||
        slice.coreStatus == MLCStreamSlice::CoreStatusE::FAULTED) {

      auto mlcHeadSliceIdx = this->tailSliceIdx - this->slices.size();

      if (mlcHeadSliceIdx > llcProgressElementIdx) {
        MLC_SLICE_DPRINTF(
            slice.sliceId,
            "Delayed poping for IdealSync between MLC %llu and LLC %llu.\n",
            mlcHeadSliceIdx, llcProgressElementIdx);
        break;
      }

      MLC_SLICE_DPRINTF(slice.sliceId, "Pop.\n");

      // Update the statistics.
      if (slice.coreWaitCycle != 0 && slice.dataReadyCycle != 0) {
        auto &streamStats = this->stream->statistic;
        if (slice.coreWaitCycle > slice.dataReadyCycle) {
          // Early.
          streamStats.numMLCEarlySlice++;
          streamStats.numMLCEarlyCycle +=
              slice.coreWaitCycle - slice.dataReadyCycle;
        } else {
          // Late.
          streamStats.numMLCLateSlice++;
          streamStats.numMLCLateCycle +=
              slice.dataReadyCycle - slice.coreWaitCycle;
        }
      }

      this->headSliceIdx++;
      this->slices.pop_front();
    } else {
      // We made no progress.
      break;
    }
  }
}

void MLCDynamicStream::makeResponse(MLCStreamSlice &slice) {
  assert(slice.coreStatus == MLCStreamSlice::CoreStatusE::WAIT_DATA &&
         "Element core status should be WAIT_DATA to make response.");
  Addr paddr = this->translateVAddr(slice.sliceId.vaddr);
  auto paddrLine = makeLineAddress(paddr);

  auto selfMachineId = this->controller->getMachineID();
  auto upperMachineId = MachineID(
      static_cast<MachineType>(selfMachineId.type - 1), selfMachineId.num);
  auto msg = std::make_shared<CoherenceMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Class = CoherenceClass_DATA_EXCLUSIVE;
  msg->m_Sender = selfMachineId;
  msg->m_Dest = upperMachineId;
  msg->m_MessageSize = MessageSizeType_Response_Data;
  msg->m_DataBlk = slice.dataBlock;

  // If this is atomic stream, we have to use STREAM_FROM_MLC type.
  if (this->stream->isAtomicStream()) {
    msg->m_Class = CoherenceClass_STREAM_FROM_MLC;
  }

  // Show the data.
  if (Debug::DEBUG_TYPE) {
    std::stringstream ss;
    auto lineOffset = slice.sliceId.vaddr % RubySystem::getBlockSizeBytes();
    auto dataStr = GemForgeUtils::dataToString(
        slice.dataBlock.getData(lineOffset, slice.sliceId.getSize()),
        slice.sliceId.getSize());
    MLC_SLICE_DPRINTF(slice.sliceId,
                      "Make response vaddr %#x size %d data 0x%s.\n",
                      slice.sliceId.vaddr, slice.sliceId.getSize(), dataStr);
  }
  // The latency should be consistency with the cache controller.
  // However, I still failed to find a clean way to exponse this info
  // to the stream engine. So far I manually set it to the default
  // value from the L1 cache controller.
  // TODO: Make it consistent with the cache controller.
  Cycles latency(2);
  this->responseMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                   this->controller->cyclesToTicks(latency));
  // Set the core status to DONE.
  slice.coreStatus = MLCStreamSlice::CoreStatusE::DONE;
  // Update the stats in core SE.
  this->stream->se->numMLCResponse++;
}

void MLCDynamicStream::makeAck(MLCStreamSlice &slice) {
  assert(slice.coreStatus == MLCStreamSlice::CoreStatusE::WAIT_ACK &&
         "Element core status should be WAIT_ACK to make ack.");
  MLC_SLICE_DPRINTF(slice.sliceId, "Make Ack, header %s.\n",
                    this->slices.front().sliceId);
  // So far I just immediately notify the stream.
  auto dynS = this->stream->getDynamicStream(this->dynamicStreamId);
  if (!dynS) {
    MLC_SLICE_PANIC(slice.sliceId, "MakeAck when dynS has been released.");
  }
  dynS->cacheAcked++;
  for (auto elementIdx = slice.sliceId.lhsElementIdx;
       elementIdx < slice.sliceId.rhsElementIdx; ++elementIdx) {
    if (std::dynamic_pointer_cast<LinearAddrGenCallback>(
            this->config->addrGenCallback)) {
      auto elementVAddr =
          this->config->addrGenCallback
              ->genAddr(elementIdx, this->config->addrGenFormalParams,
                        getStreamValueFail)
              .uint64();
      if (elementVAddr + this->config->elementSize >
          slice.sliceId.vaddr + slice.sliceId.getSize()) {
        // This element spans to next slice, do not ack here.
        MLC_SLICE_DPRINTF(slice.sliceId,
                          "Skipping Ack for multi-slice element %llu [%#x, "
                          "+%d) slice [%#x, +%d).\n",
                          elementIdx, elementVAddr, this->config->elementSize,
                          slice.sliceId.vaddr, slice.sliceId.getSize());
        continue;
      }
    }
    MLC_SLICE_DPRINTF(slice.sliceId, "Ack for element %llu.\n", elementIdx);
    dynS->cacheAckedElements.insert(elementIdx);
  }
  // auto element = dynS->getElementByIdx(slice.sliceId.lhsElementIdx);
  // assert(!element->isCacheAcked && "Core element is already acked.");
  // element->isCacheAcked = true;
  // Set the core status to DONE.
  slice.coreStatus = MLCStreamSlice::CoreStatusE::DONE;
}

Addr MLCDynamicStream::translateVAddr(Addr vaddr) const {
  auto cpuDelegator = this->getStaticStream()->getCPUDelegator();
  Addr paddr;
  if (!cpuDelegator->translateVAddrOracle(vaddr, paddr)) {
    panic("Failed translate vaddr %#x.\n", vaddr);
  }
  return paddr;
}

void MLCDynamicStream::readBlob(Addr vaddr, uint8_t *data, int size) const {
  auto cpuDelegator = this->getStaticStream()->getCPUDelegator();
  cpuDelegator->readFromMem(vaddr, size, data);
}

MachineID MLCDynamicStream::mapPAddrToLLCBank(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto llcMachineId = this->controller->mapAddressToLLC(
      paddr, static_cast<MachineType>(selfMachineId.type + 1));
  return llcMachineId;
}

void MLCDynamicStream::scheduleAdvanceStream() {
  if (!this->advanceStreamEvent.scheduled()) {
    this->stream->getCPUDelegator()->schedule(&this->advanceStreamEvent,
                                              Cycles(1));
  }
}

void MLCDynamicStream::panicDump() const {
  MLC_S_HACK("-------------------Panic Dump--------------------\n");
  for (const auto &slice : this->slices) {
    MLC_SLICE_HACK(slice.sliceId, "VAddr %#x Data %d Core %s.\n",
                   slice.sliceId.vaddr, slice.dataReady,
                   MLCStreamSlice::convertCoreStatusToString(slice.coreStatus));
  }
}