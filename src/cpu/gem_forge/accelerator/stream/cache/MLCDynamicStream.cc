#include "MLCDynamicStream.hh"

// Generated by slicc.
#include "mem/protocol/CoherenceMsg.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/RubyStream.hh"

MLCDynamicStream::MLCDynamicStream(CacheStreamConfigureData *_configData,
                                   AbstractStreamAwareController *_controller,
                                   MessageBuffer *_responseMsgBuffer)
    : stream(_configData->stream), history(_configData->history),
      controller(_controller), responseMsgBuffer(_responseMsgBuffer),
      allocateIdx(0) {}

void MLCDynamicStream::receiveStreamData(const ResponseMsg &msg) {
  const auto &streamMeta = msg.m_streamMeta;
  assert(streamMeta.m_valid && "Invalid stream meta-data for stream data.");
  auto stream = reinterpret_cast<Stream *>(streamMeta.m_stream);
  assert(this->stream == stream && "Unmatched static stream.");
  DPRINTF(RubyStream, "Receive stream data [%lu, %lu).\n",
          streamMeta.m_startIdx,
          streamMeta.m_startIdx + streamMeta.m_numElements);

  /**
   * So far we don't have flow control yet, so allocate stream elements
   * on demand.
   * TODO: Add coarse-grained flow control to LLCStreamEngine.
   */
  while (this->allocateIdx <= streamMeta.m_startIdx) {
    this->allocateElement();
  }

  /**
   * Find the correct stream element and insert the data there.
   */
  for (auto &element : this->elements) {
    if (element.startIdx == streamMeta.m_startIdx) {
      // Found the element.
      assert(element.numElements == streamMeta.m_numElements &&
             "Mismatch numElements.");
      element.setData(msg.m_DataBlk);
      this->advanceStream();
      return;
    }
  }

  assert(false && "Failed to find the allocated stream element.");
}

void MLCDynamicStream::receiveStreamRequest(uint64_t idx) {
  DPRINTF(RubyStream, "Receive stream request idx %lu.\n", idx);

  while (this->allocateIdx <= idx) {
    this->allocateElement();
  }
  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->elements.empty() && "Empty element list.");
  for (auto &element : this->elements) {
    if (element.startIdx == idx) {
      // Found the element.
      assert(element.coreStatus == MLCStreamElement::CoreStatusE::NONE &&
             "Already seen a request.");
      element.coreStatus = MLCStreamElement::CoreStatusE::WAIT;
      break;
    }
  }

  this->advanceStream();
}

void MLCDynamicStream::receiveStreamRequestHit(uint64_t idx) {
  DPRINTF(RubyStream, "Receive stream request hit idx %lu.\n", idx);

  while (this->allocateIdx <= idx) {
    this->allocateElement();
  }
  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->elements.empty() && "Empty element list.");
  for (auto &element : this->elements) {
    if (element.startIdx == idx) {
      // Found the element.
      assert(element.coreStatus == MLCStreamElement::CoreStatusE::NONE &&
             "Already seen a request.");
      element.coreStatus = MLCStreamElement::CoreStatusE::DONE;
      break;
    }
  }
  this->advanceStream();
}

void MLCDynamicStream::advanceStream() {

  /**
   * Maybe let's make response in order?
   */
  while (!this->elements.empty() && this->elements.front().dataReady) {
    if (this->elements.front().coreStatus ==
        MLCStreamElement::CoreStatusE::WAIT) {
      // Data already ready.
      this->makeResponse();
    } else if (this->elements.front().coreStatus ==
               MLCStreamElement::CoreStatusE::DONE) {
      // Simply drop the elements.
      this->elements.pop_front();
    }
  }
}

void MLCDynamicStream::makeResponse() {
  assert(!this->elements.empty() && "Make response when there is no elements.");
  auto &element = this->elements.front();
  assert(element.dataReady && "Data should already be ready.");
  auto cpu = this->getStaticStream()->getCPU();
  auto paddr = cpu->translateAndAllocatePhysMem(element.vaddr);
  auto paddrLine = makeLineAddress(paddr);

  auto selfMachineId = this->controller->getMachineID();
  auto upperMachineId = MachineID(
      static_cast<MachineType>(selfMachineId.type - 1), selfMachineId.num);
  auto msg = std::make_shared<CoherenceMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Class = CoherenceClass_DATA_EXCLUSIVE;
  msg->m_Sender = selfMachineId;
  msg->m_Dest = upperMachineId;
  msg->m_MessageSize = MessageSizeType_Response_Data;

  Cycles latency(1); // Just use 1 cycle latency here.
  this->responseMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                   this->controller->cyclesToTicks(latency));

  DPRINTF(RubyStream, "Make MLCStreamResponse [%lu, %lu) %#x.\n",
          element.startIdx, element.startIdx + element.numElements, paddrLine);

  // Release the element from the list.
  this->elements.pop_front();
}

void MLCDynamicStream::allocateElement() {
  auto historySize = this->history->history_size();
  uint64_t startIdx = this->allocateIdx;
  int numElements = 1;
  Addr vaddr =
      (startIdx < historySize) ? (this->history->history(startIdx).addr()) : 0;
  Addr vaddrLine = makeLineAddress(vaddr);
  this->allocateIdx++;
  while (this->allocateIdx < historySize) {
    Addr nextVAddr = this->history->history(this->allocateIdx).addr();
    Addr nextVAddrLine = makeLineAddress(nextVAddr);
    if (nextVAddrLine != vaddrLine) {
      break;
    }
    // This element is the same line, maybe we can merge.
    numElements++;
    this->allocateIdx++;
  }

  DPRINTF(RubyStream, "Allocate MLCStreamElement [%lu, %lu).\n", startIdx,
          startIdx + numElements);

  this->elements.emplace_back(startIdx, numElements, vaddr);
}