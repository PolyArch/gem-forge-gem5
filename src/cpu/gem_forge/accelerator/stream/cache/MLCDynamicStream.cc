#include "MLCDynamicStream.hh"

// Generated by slicc.
#include "mem/protocol/CoherenceMsg.hh"
#include "mem/protocol/RequestMsg.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/MLCRubyStream.hh"

#define MLC_STREAM_DPRINTF(format, args...)                                    \
  DPRINTF(MLCRubyStream, "[MLC_SE%d][%lu-%d]: " format,                        \
          this->controller->getMachineID().num,                                \
          this->dynamicStreamId.staticId,                                      \
          this->dynamicStreamId.streamInstance, ##args)

#define MLC_STREAM_PANIC(format, args...)                                      \
  this->panicDump();                                                           \
  panic("[MLC_SE%d][%lu]: " format, this->controller->getMachineID().num,      \
        this->dynamicStreamId.staticId, ##args)

#define MLC_STREAM_PANIC_IF(cond, format, args...)                             \
  if ((cond)) {                                                                \
    MLC_STREAM_PANIC(format, ##args);                                          \
  }

#define MLC_ELEMENT_DPRINTF(startIdx, numElements, format, args...)            \
  DPRINTF(MLCRubyStream, "[MLC_SE%d][%lu-%d][%lu, +%d): " format,              \
          this->controller->getMachineID().num,                                \
          this->dynamicStreamId.staticId,                                      \
          this->dynamicStreamId.streamInstance, startIdx, numElements, ##args)

MLCDynamicStream::MLCDynamicStream(CacheStreamConfigureData *_configData,
                                   AbstractStreamAwareController *_controller,
                                   MessageBuffer *_responseMsgBuffer,
                                   MessageBuffer *_requestToLLCMsgBuffer,
                                   bool _mergeElements)
    : stream(_configData->stream), dynamicStreamId(_configData->dynamicId),
      isPointerChase(_configData->isPointerChase),
      history(_configData->history), controller(_controller),
      responseMsgBuffer(_responseMsgBuffer),
      requestToLLCMsgBuffer(_requestToLLCMsgBuffer), maxNumElements(64),
      mergeElements(_mergeElements), headIdx(0), tailIdx(0), llcTailIdx(0) {

  /**
   * ! You should never call any virtual function in the
   * ! constructor/deconstructor.
   */

  // Initialize the buffer for 32 entries?
  while (this->tailIdx < this->maxNumElements) {
    this->allocateElement();
  }
  this->llcTailIdx = this->tailIdx;
  // Set the CacheStreamConfigureData to inform the LLC stream engine
  // initial credit.
  _configData->initAllocatedIdx = this->llcTailIdx;
}

void MLCDynamicStream::receiveStreamData(const ResponseMsg &msg) {
  const auto &sliceId = msg.m_sliceId;
  assert(sliceId.isValid() && "Invalid stream slice id for stream data.");

  auto startIdx = sliceId.startIdx;
  auto numElements = sliceId.getNumElements();
  assert(this->dynamicStreamId == sliceId.streamId &&
         "Unmatched dynamic stream id.");
  MLC_ELEMENT_DPRINTF(startIdx, numElements, "Receive data.\n");

  /**
   * It is possible when the core stream engine runs ahead than
   * the LLC stream engine, and the stream data is delivered after
   * the element is released. In such case we will ignore the
   * stream data.
   */
  if (startIdx < this->headIdx) {
    // The stream data is lagging behind. The element is already
    // released.
    return;
  }

  /**
   * Find the correct stream element and insert the data there.
   * Here we reversely search for it to save time.
   */
  for (auto element = this->elements.rbegin(), end = this->elements.rend();
       element != end; ++element) {
    if (element->startIdx == startIdx) {
      // Found the element.
      if (element->numElements != numElements) {
        MLC_STREAM_PANIC("Mismatch numElements, incoming %d, element %d.\n",
                         numElements, element->numElements);
      }
      element->setData(msg.m_DataBlk);
      if (element->coreStatus == MLCStreamElement::CoreStatusE::WAIT) {
        this->makeResponse(*element);
      }
      this->advanceStream();
      return;
    }
  }

  panic("Failed to find the allocated element for data. Tail %lu.\n",
        this->tailIdx);
}

void MLCDynamicStream::receiveStreamRequest(uint64_t idx) {
  MLC_ELEMENT_DPRINTF(idx, 1, "Receive request.\n");

  // We should be ahead of the core.
  MLC_STREAM_PANIC_IF(this->tailIdx <= idx, "MLCStream is behind the core?");

  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->elements.empty() && "Empty element list.");
  for (auto &element : this->elements) {
    if (element.startIdx == idx) {
      // Found the element.
      assert(element.coreStatus == MLCStreamElement::CoreStatusE::NONE &&
             "Already seen a request.");
      element.coreStatus = MLCStreamElement::CoreStatusE::WAIT;
      if (element.dataReady) {
        this->makeResponse(element);
      }
      break;
    }
  }

  this->advanceStream();
}

void MLCDynamicStream::endStream() {
  for (auto &element : this->elements) {
    if (element.coreStatus == MLCStreamElement::CoreStatusE::WAIT) {
      // Make a dummy response.
      // Ignore if the data is ready.
      this->makeResponse(element);
    }
  }
}

void MLCDynamicStream::receiveStreamRequestHit(uint64_t idx) {
  MLC_ELEMENT_DPRINTF(idx, 1, "Receive request hit.\n");

  while (this->tailIdx <= idx) {
    this->allocateElement();
  }
  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->elements.empty() && "Empty element list.");
  for (auto &element : this->elements) {
    if (element.startIdx == idx) {
      // Found the element.
      assert(element.coreStatus == MLCStreamElement::CoreStatusE::NONE &&
             "Already seen a request.");
      element.coreStatus = MLCStreamElement::CoreStatusE::DONE;
      break;
    }
  }
  this->advanceStream();
}

void MLCDynamicStream::advanceStream() {

  /**
   * Maybe let's make release in order.
   * The element is released once the core status is DONE.
   */
  while (!this->elements.empty()) {
    const auto &element = this->elements.front();
    if (element.coreStatus == MLCStreamElement::CoreStatusE::DONE) {
      assert(this->headIdx == element.startIdx && "Illegal headIdx somehow.");
      MLC_ELEMENT_DPRINTF(element.startIdx, element.numElements, "Pop.\n");
      this->headIdx += element.numElements;
      this->elements.pop_front();
    } else {
      // We made no progress.
      break;
    }
  }
  // Of course we need to allocate more elements.
  while (this->tailIdx - this->headIdx < this->maxNumElements) {
    this->allocateElement();
  }
  if (this->tailIdx - this->llcTailIdx > this->maxNumElements / 2) {
    // It's time for us to send more credit to LLC stream.
    this->sendCreditToLLC();
  }
}

void MLCDynamicStream::makeResponse(MLCStreamElement &element) {
  assert(element.coreStatus == MLCStreamElement::CoreStatusE::WAIT &&
         "Element core status should be WAIT to make response.");
  auto cpu = this->getStaticStream()->getCPU();
  auto paddr = cpu->translateAndAllocatePhysMem(element.vaddr);
  auto paddrLine = makeLineAddress(paddr);

  auto selfMachineId = this->controller->getMachineID();
  auto upperMachineId = MachineID(
      static_cast<MachineType>(selfMachineId.type - 1), selfMachineId.num);
  auto msg = std::make_shared<CoherenceMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Class = CoherenceClass_DATA_EXCLUSIVE;
  msg->m_Sender = selfMachineId;
  msg->m_Dest = upperMachineId;
  msg->m_MessageSize = MessageSizeType_Response_Data;

  MLC_ELEMENT_DPRINTF(element.startIdx, element.numElements,
                      "Make response.\n");
  // The latency should be consistency with the cache controller.
  // However, I still failed to find a clean way to exponse this info
  // to the stream engine. So far I manually set it to the default
  // value from the L1 cache controller.
  // TODO: Make it consistent with the cache controller.
  Cycles latency(2);
  this->responseMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                   this->controller->cyclesToTicks(latency));
  // Set the core status to DONE.
  element.coreStatus = MLCStreamElement::CoreStatusE::DONE;
}

Addr MLCDynamicStream::getVAddrAtIndex(uint64_t index) const {
  auto historySize = this->history->history_size();
  // ! So far just return the last address.
  // ! Do something reasonable here.
  // ! Make sure this is consistent with the core stream engine.
  Addr vaddr = (index < historySize)
                   ? (this->history->history(index).addr())
                   : (this->history->history(historySize - 1).addr());
  return vaddr;
}

Addr MLCDynamicStream::translateVAddr(Addr vaddr) const {
  auto cpu = this->getStaticStream()->getCPU();
  auto paddr = cpu->translateAndAllocatePhysMem(vaddr);
  return paddr;
}

void MLCDynamicStream::allocateElement() {
  auto historySize = this->history->history_size();
  uint64_t startIdx = this->tailIdx;
  int numElements = 1;
  Addr vaddr = this->getVAddrAtIndex(startIdx);
  Addr vaddrLine = makeLineAddress(vaddr);
  this->tailIdx++;
  /**
   * Try to merge element if we are not pointer chase stream.
   * It is impossible for pointer chase stream to merge requests
   * as you don't know the next virtual address until the previous
   * request is resolved.
   */
  if (!this->isPointerChase && this->mergeElements) {
    while (this->tailIdx < historySize) {
      Addr nextVAddr = this->history->history(this->tailIdx).addr();
      Addr nextVAddrLine = makeLineAddress(nextVAddr);
      if (nextVAddrLine != vaddrLine) {
        break;
      }
      // This element is the same line, maybe we can merge.
      numElements++;
      this->tailIdx++;
    }
  }

  MLC_ELEMENT_DPRINTF(startIdx, numElements, "Allocated.\n");
  this->elements.emplace_back(startIdx, numElements, vaddr);
}

void MLCDynamicStream::sendCreditToLLC() {
  /**
   * Find where the LLC stream is.
   * In this implementation, the LLC stream will aggressively
   * migrate to llcTailIdx, even the credit has only been allocated to
   * (llcTailIdx - 1).
   */
  auto vaddr = this->getVAddrAtIndex(this->llcTailIdx);
  auto paddr = this->translateVAddr(vaddr);
  auto paddrLine = makeLineAddress(paddr);

  // Find the LLC bank.
  auto selfMachineId = this->controller->getMachineID();
  auto llcMachineId = this->controller->mapAddressToLLC(
      paddrLine, static_cast<MachineType>(selfMachineId.type + 1));

  // Send the flow control.
  MLC_STREAM_DPRINTF("Extended %lu -> %lu, sent credit to LLC%d.\n",
                     this->llcTailIdx, this->tailIdx, llcMachineId.num);
  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_FLOW;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(llcMachineId);
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_sliceId.streamId = this->dynamicStreamId;
  msg->m_sliceId.startIdx = this->llcTailIdx;
  msg->m_sliceId.endIdx = this->tailIdx;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->requestToLLCMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  // Update the record.
  this->llcTailIdx = this->tailIdx;
}

Addr MLCDynamicStream::getLLCStreamTailPAddr() const {
  auto vaddr = this->getVAddrAtIndex(this->llcTailIdx);
  return this->translateVAddr(vaddr);
}

void MLCDynamicStream::panicDump() const {
  MLC_STREAM_DPRINTF("-------------------Panic Dump--------------------\n");
  for (const auto &element : this->elements) {
    MLC_ELEMENT_DPRINTF(
        element.startIdx, element.numElements, "Data %d Core %s.\n",
        element.dataReady,
        MLCStreamElement::convertCoreStatusToString(element.coreStatus)
            .c_str());
  }
}