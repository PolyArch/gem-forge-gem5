#include "MLCDynamicStream.hh"

// Generated by slicc.
#include "mem/ruby/protocol/CoherenceMsg.hh"
#include "mem/ruby/protocol/RequestMsg.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/MLCRubyStream.hh"

#define MLC_STREAM_DPRINTF(format, args...)                                    \
  DPRINTF(MLCRubyStream, "[MLC_SE%d][%lu-%d]: " format,                        \
          this->controller->getMachineID().num,                                \
          this->dynamicStreamId.staticId,                                      \
          this->dynamicStreamId.streamInstance, ##args)

#define MLC_STREAM_PANIC(format, args...)                                      \
  this->panicDump();                                                           \
  panic("[MLC_SE%d][%lu]: " format, this->controller->getMachineID().num,      \
        this->dynamicStreamId.staticId, ##args)

#define MLC_STREAM_PANIC_IF(cond, format, args...)                             \
  if ((cond)) {                                                                \
    MLC_STREAM_PANIC(format, ##args);                                          \
  }

#define MLC_SLICE_DPRINTF(sliceId, format, args...)                            \
  DPRINTF(MLCRubyStream, "[MLC_SE%d][%lu-%d][%lu, +%d): " format,              \
          this->controller->getMachineID().num,                                \
          this->dynamicStreamId.staticId,                                      \
          this->dynamicStreamId.streamInstance, (sliceId).startIdx,            \
          (sliceId).endIdx - (sliceId).startIdx, ##args)

MLCDynamicStream::MLCDynamicStream(CacheStreamConfigureData *_configData,
                                   AbstractStreamAwareController *_controller,
                                   MessageBuffer *_responseMsgBuffer,
                                   MessageBuffer *_requestToLLCMsgBuffer,
                                   bool _mergeElements)
    : stream(_configData->stream), dynamicStreamId(_configData->dynamicId),
      isPointerChase(_configData->isPointerChase), slicedStream(_configData),
      controller(_controller), responseMsgBuffer(_responseMsgBuffer),
      requestToLLCMsgBuffer(_requestToLLCMsgBuffer),
      maxNumSlices(_controller->getMLCStreamBufferInitNumEntries()),
      mergeElements(_mergeElements), headSliceIdx(0), tailSliceIdx(0),
      llcTailSliceIdx(0) {

  /**
   * ! You should never call any virtual function in the
   * ! constructor/deconstructor.
   */

  // Initialize the buffer for 32 entries?
  while (this->tailSliceIdx < this->maxNumSlices) {
    this->allocateSlice();
  }
  this->llcTailSliceIdx = this->tailSliceIdx;
  // Set the CacheStreamConfigureData to inform the LLC stream engine
  // initial credit.
  _configData->initAllocatedIdx = this->llcTailSliceIdx;
}

void MLCDynamicStream::receiveStreamData(const ResponseMsg &msg) {
  const auto &sliceId = msg.m_sliceId;
  assert(sliceId.isValid() && "Invalid stream slice id for stream data.");

  auto numElements = sliceId.getNumElements();
  assert(this->dynamicStreamId == sliceId.streamId &&
         "Unmatched dynamic stream id.");
  MLC_SLICE_DPRINTF(sliceId, "Receive data %#x.\n", sliceId.vaddr);

  /**
   * It is possible when the core stream engine runs ahead than
   * the LLC stream engine, and the stream data is delivered after
   * the slice is released. In such case we will ignore the
   * stream data.
   *
   * TODO: Properly handle this with sliceIdx.
   */
  if (sliceId.vaddr < this->slices.front().sliceId.vaddr) {
    // The stream data is lagging behind. The slice is already
    // released.
    return;
  }

  /**
   * Find the correct stream slice and insert the data there.
   * Here we reversely search for it to save time.
   */
  for (auto slice = this->slices.rbegin(), end = this->slices.rend();
       slice != end; ++slice) {
    if (slice->sliceId.vaddr == sliceId.vaddr) {
      // Found the slice.
      if (slice->sliceId.getNumElements() != numElements) {
        MLC_STREAM_PANIC("Mismatch numElements, incoming %d, slice %d.\n",
                         numElements, slice->sliceId.getNumElements());
      }
      slice->setData(msg.m_DataBlk);
      if (slice->coreStatus == MLCStreamSlice::CoreStatusE::WAIT) {
        this->makeResponse(*slice);
      }
      this->advanceStream();
      return;
    }
  }

  panic("Failed to find the allocated slice for data. Tail %lu.\n",
        this->tailSliceIdx);
}

void MLCDynamicStream::receiveStreamRequest(
    const DynamicStreamSliceId &sliceId) {
  MLC_SLICE_DPRINTF(sliceId, "Receive request to %#x.\n", sliceId.vaddr);

  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->slices.empty() && "Empty slice list.");
  bool found = false;
  for (auto &slice : this->slices) {
    /**
     * So far we match them on vaddr.
     * TODO: Really assign the sliceIdx and match that.
     */
    if (slice.sliceId.vaddr == sliceId.vaddr) {
      // Found the slice.
      assert(slice.coreStatus == MLCStreamSlice::CoreStatusE::NONE &&
             "Already seen a request.");
      found = true;
      MLC_SLICE_DPRINTF(slice.sliceId, "Matched to request.\n");
      slice.coreStatus = MLCStreamSlice::CoreStatusE::WAIT;
      if (slice.dataReady) {
        this->makeResponse(slice);
      }
      break;
    }
  }

  assert(found && "Failed to found match.");
  this->advanceStream();
}

void MLCDynamicStream::endStream() {
  for (auto &slice : this->slices) {
    if (slice.coreStatus == MLCStreamSlice::CoreStatusE::WAIT) {
      // Make a dummy response.
      // Ignore if the data is ready.
      this->makeResponse(slice);
    }
  }
}

void MLCDynamicStream::receiveStreamRequestHit(
    const DynamicStreamSliceId &sliceId) {
  MLC_SLICE_DPRINTF(sliceId, "Receive request hit.\n");

  // // It's possible that we are lagging behind the core if there
  // // are many hit.
  // while (this->tailSliceIdx <= idx) {
  //   this->allocateSlice();
  // }
  /**
   * Let's not make assumption that the request will come in order.
   */
  assert(!this->slices.empty() && "Empty slice list.");
  for (auto &slice : this->slices) {
    if (slice.sliceId.vaddr == sliceId.vaddr) {
      // Found the slice.
      assert(slice.coreStatus == MLCStreamSlice::CoreStatusE::NONE &&
             "Already seen a request.");
      slice.coreStatus = MLCStreamSlice::CoreStatusE::DONE;
      break;
    }
  }
  this->advanceStream();
}

void MLCDynamicStream::advanceStream() {

  /**
   * Maybe let's make release in order.
   * The slice is released once the core status is DONE.
   */
  while (!this->slices.empty()) {
    const auto &slice = this->slices.front();
    if (slice.coreStatus == MLCStreamSlice::CoreStatusE::DONE) {
      MLC_SLICE_DPRINTF(slice.sliceId, "Pop.\n");
      this->headSliceIdx++;
      this->slices.pop_front();
    } else {
      // We made no progress.
      break;
    }
  }
  // Of course we need to allocate more slices.
  while (this->tailSliceIdx - this->headSliceIdx < this->maxNumSlices) {
    this->allocateSlice();
  }
  if (this->tailSliceIdx - this->llcTailSliceIdx > this->maxNumSlices / 2) {
    // It's time for us to send more credit to LLC stream.
    this->sendCreditToLLC();
  }
}

void MLCDynamicStream::makeResponse(MLCStreamSlice &slice) {
  assert(slice.coreStatus == MLCStreamSlice::CoreStatusE::WAIT &&
         "Element core status should be WAIT to make response.");
  Addr paddr = this->translateVAddr(slice.sliceId.vaddr);
  auto paddrLine = makeLineAddress(paddr);

  auto selfMachineId = this->controller->getMachineID();
  auto upperMachineId = MachineID(
      static_cast<MachineType>(selfMachineId.type - 1), selfMachineId.num);
  auto msg = std::make_shared<CoherenceMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Class = CoherenceClass_DATA_EXCLUSIVE;
  msg->m_Sender = selfMachineId;
  msg->m_Dest = upperMachineId;
  msg->m_MessageSize = MessageSizeType_Response_Data;

  MLC_SLICE_DPRINTF(slice.sliceId, "Make response.\n");
  // The latency should be consistency with the cache controller.
  // However, I still failed to find a clean way to exponse this info
  // to the stream engine. So far I manually set it to the default
  // value from the L1 cache controller.
  // TODO: Make it consistent with the cache controller.
  Cycles latency(2);
  this->responseMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                   this->controller->cyclesToTicks(latency));
  // Set the core status to DONE.
  slice.coreStatus = MLCStreamSlice::CoreStatusE::DONE;
}

MLCDynamicStream::MLCStreamSlice &
MLCDynamicStream::getSlice(uint64_t sliceIdx) {
  assert(sliceIdx >= this->headSliceIdx && "Underflow of sliceIdx.");
  assert(sliceIdx < this->tailSliceIdx && "Overflow of sliceIdx.");
  return this->slices.at(sliceIdx - this->headSliceIdx);
}

const MLCDynamicStream::MLCStreamSlice &
MLCDynamicStream::getSlice(uint64_t sliceIdx) const {
  assert(sliceIdx >= this->headSliceIdx && "Underflow of sliceIdx.");
  assert(sliceIdx < this->tailSliceIdx && "Overflow of sliceIdx.");
  return this->slices.at(sliceIdx - this->headSliceIdx);
}

Addr MLCDynamicStream::translateVAddr(Addr vaddr) const {
  auto cpuDelegator = this->getStaticStream()->getCPUDelegator();
  Addr paddr;
  if (!cpuDelegator->translateVAddrOracle(vaddr, paddr)) {
    panic("Failed translate vaddr %#x.\n", vaddr);
  }
  return paddr;
}

void MLCDynamicStream::allocateSlice() {
  auto sliceId = this->slicedStream.getNextSlice();
  MLC_SLICE_DPRINTF(sliceId, "Allocated %#x.\n", sliceId.vaddr);
  this->slices.emplace_back(sliceId);
  this->tailSliceIdx++;
}

void MLCDynamicStream::sendCreditToLLC() {
  /**
   * Find where the LLC stream is.
   * In this implementation, the LLC stream will aggressively
   * migrate to llcTailSliceIdx, even the credit has only been allocated to
   * (llcTailSliceIdx - 1).
   *
   * This will not work for pointer chasing stream.
   */
  assert(this->tailSliceIdx > this->llcTailSliceIdx &&
         "Don't know where to send credit.");
  auto vaddr = this->getSlice(this->llcTailSliceIdx).sliceId.vaddr;
  auto paddr = this->translateVAddr(vaddr);
  auto paddrLine = makeLineAddress(paddr);

  // Find the LLC bank.
  auto selfMachineId = this->controller->getMachineID();
  auto llcMachineId = this->controller->mapAddressToLLC(
      paddrLine, static_cast<MachineType>(selfMachineId.type + 1));

  // Send the flow control.
  MLC_STREAM_DPRINTF("Extended %lu -> %lu, sent credit to LLC%d.\n",
                     this->llcTailSliceIdx, this->tailSliceIdx,
                     llcMachineId.num);
  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_FLOW;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(llcMachineId);
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_sliceId.streamId = this->dynamicStreamId;
  msg->m_sliceId.startIdx = this->llcTailSliceIdx;
  msg->m_sliceId.endIdx = this->tailSliceIdx;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->requestToLLCMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  // Update the record.
  this->llcTailSliceIdx = this->tailSliceIdx;
}

Addr MLCDynamicStream::getLLCStreamTailPAddr() const {
  auto vaddr = this->getSlice(this->llcTailSliceIdx).sliceId.vaddr;
  return this->translateVAddr(vaddr);
}

void MLCDynamicStream::panicDump() const {
  MLC_STREAM_DPRINTF("-------------------Panic Dump--------------------\n");
  for (const auto &slice : this->slices) {
    MLC_SLICE_DPRINTF(
        slice.sliceId, "Data %d Core %s.\n", slice.dataReady,
        MLCStreamSlice::convertCoreStatusToString(slice.coreStatus).c_str());
  }
}