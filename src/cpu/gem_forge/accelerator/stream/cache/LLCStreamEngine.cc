
#include "LLCStreamEngine.hh"
#include "LLCStreamAtomicLockManager.hh"
#include "LLCStreamCommitController.hh"
#include "LLCStreamMigrationController.hh"
#include "LLCStreamNDCController.hh"
#include "LLCStreamRangeBuilder.hh"
#include "MLCStreamEngine.hh"
#include "StreamRequestBuffer.hh"
#include "pum/DataMoveCompiler.hh"
#include "pum/PUMEngine.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

// Generated by slicc.
#include "mem/ruby/protocol/StreamMigrateRequestMsg.hh"
#include "mem/simple_mem.hh"

#include "cpu/gem_forge/accelerator/stream/stream_atomic_op.hh"
#include "cpu/gem_forge/accelerator/stream/stream_engine.hh"
#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/LLCRubyStreamBase.hh"
#include "debug/LLCRubyStreamLife.hh"
#include "debug/LLCRubyStreamMulticast.hh"
#include "debug/LLCRubyStreamNotIssue.hh"
#include "debug/LLCRubyStreamReduce.hh"
#include "debug/LLCRubyStreamStore.hh"
#include "debug/LLCStreamEngineWake.hh"
#include "debug/LLCStreamLoopBound.hh"
#include "debug/LLCStreamPUM.hh"
#include "debug/LLCStreamPredicate.hh"
#include "debug/LLCStreamSample.hh"
#include "debug/StreamRangeSync.hh"
#define DEBUG_TYPE LLCRubyStreamBase
#include "../stream_log.hh"

#define LLCSE_DPRINTF(format, args...)                                         \
  DPRINTF(LLCRubyStreamBase, "[%s_SE%d]: " format,                             \
          this->curRemoteMachineType(), this->curRemoteBank(), ##args)

namespace gem5 {

LLCStreamEngine::LLCStreamEngine(
    ruby::AbstractStreamAwareController *_controller,
    ruby::MessageBuffer *_streamMigrateMsgBuffer,
    ruby::MessageBuffer *_streamIssueMsgBuffer,
    ruby::MessageBuffer *_streamIndirectIssueMsgBuffer,
    ruby::MessageBuffer *_streamResponseMsgBuffer)
    : ruby::Consumer(_controller), controller(_controller),
      streamMigrateMsgBuffer(_streamMigrateMsgBuffer),
      streamIssueMsgBuffer(_streamIssueMsgBuffer),
      streamIndirectIssueMsgBuffer(_streamIndirectIssueMsgBuffer),
      streamResponseMsgBuffer(_streamResponseMsgBuffer),
      issueWidth(_controller->getLLCStreamEngineIssueWidth()),
      migrateWidth(_controller->getLLCStreamEngineMigrateWidth()),
      maxInflyRequests(8), maxInqueueRequests(2), translationBuffer(nullptr),
      seTracer(_controller->getMachineID().getNum(),
               std::string(_controller->getMachineTypeString()) + "_SE") {
  this->controller->registerLLCStreamEngine(this);
  this->commitController = std::make_unique<LLCStreamCommitController>(this);
  this->atomicLockManager = std::make_unique<LLCStreamAtomicLockManager>(this);
  this->ndcController = std::make_unique<LLCStreamNDCController>(this);
  this->indReqBuffer = std::make_unique<StreamRequestBuffer>(
      this->controller, this->streamIndirectIssueMsgBuffer, Cycles(1),
      false /* For now disable indirect multicast */,
      this->controller->myParams->ind_stream_max_inqueue_req, /* per stream. */
      this->controller->myParams->ind_stream_req_max_per_multicast_msg,
      this->controller->myParams->ind_stream_req_multicast_group_size);
  this->migrateController = std::make_unique<LLCStreamMigrationController>(
      this->controller,
      this->controller->myParams
          ->neighbor_stream_threshold /* NeighborStreamsThreshold */,
      Cycles(this->controller->myParams->neighbor_migration_delay) /* Delay */
  );
  this->reuseBuffer = std::make_unique<StreamReuseBuffer>(
      this->controller->getMachineID(),
      this->controller->myParams->reuse_buffer_lines_per_core,
      true /* PerCoreMode */
  );
  this->pumEngine = std::make_unique<PUMEngine>(this);
}

LLCStreamEngine::~LLCStreamEngine() { this->streams.clear(); }

int LLCStreamEngine::getNumDirectStreams() const {
  return this->streams.size() + this->migratingStreams.size();
}

int LLCStreamEngine::getNumNonOverflownDirectStreamsWithStaticId(
    const DynStreamId &dynStreamId) const {
  int count = 0;
  for (auto dynS : this->streams) {
    if (dynS->getDynStreamId().staticId == dynStreamId.staticId &&
        !dynS->isNextElemOverflown()) {
      count++;
    }
  }
  for (auto dynS : this->migratingStreams) {
    if (dynS->getDynStreamId().staticId == dynStreamId.staticId &&
        !dynS->isNextElemOverflown()) {
      count++;
    }
  }
  return count;
}

int LLCStreamEngine::curRemoteBank() const {
  return this->controller->getMachineID().num;
}

ruby::MachineType LLCStreamEngine::myMachineType() const {
  return this->controller->getMachineID().getType();
}

const char *LLCStreamEngine::curRemoteMachineType() const {
  return this->controller->getMachineTypeString();
}

void LLCStreamEngine::receiveStreamConfigure(PacketPtr pkt) {

  // Initialize the translation buffer.
  this->initializeTranslationBuffer();

  auto streamConfigureData = *(pkt->getPtr<CacheStreamConfigureDataPtr>());
  LLCSE_DPRINTF("Received Pkt %#x, StreamConfigure %#x, initVAddr "
                "%#x, "
                "initPAddr %#x.\n",
                pkt, streamConfigureData, streamConfigureData->initVAddr,
                streamConfigureData->initPAddr);

  // Create the stream.
  auto S = LLCDynStream::getLLCStreamPanic(DynStrandId(
      streamConfigureData->dynamicId, streamConfigureData->strandIdx,
      streamConfigureData->totalStrands));
  LLC_S_DPRINTF_(LLCRubyStreamLife, S->getDynStrandId(),
                 "Config InitCredit %d TripCount %lld.\n",
                 streamConfigureData->initCreditedIdx, S->getTotalTripCount());
  S->remoteConfigured(this->controller);

  // Add the initial credits.
  if (streamConfigureData->initCreditedIdx > 0) {
    S->addCredit(streamConfigureData->initCreditedIdx);
  }

  // Remember the stream to the CommitController if we have that.
  if (S->shouldRangeSync()) {
    this->commitController->registerStream(S);
  }

  // Check if we have indirect streams.
  for (const auto IS : S->getAllIndStreams()) {
    LLC_S_DPRINTF_(LLCRubyStreamLife, IS->getDynStrandId(),
                   "Config IndS MemElemSize %d TotalTripCount %lld.\n",
                   IS->getMemElementSize(), IS->getTotalTripCount());
    IS->remoteConfigured(this->controller);
  }

  // Release memory.
  *(pkt->getPtr<CacheStreamConfigureDataPtr>()) = nullptr;
  delete pkt;

  S->traceEvent(::LLVM::TDG::StreamFloatEvent::CONFIG);
  // Let's check if StreamEnd packet has arrived earlier.
  if (this->pendingEndStrandIds.count(S->getDynStrandId())) {
    S->terminate();
  } else {
    this->streams.emplace_back(S);
    this->addStreamToMulticastTable(S);
    this->addIssuingDirDynS(S);
    // Let's schedule a wakeup event.
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::receiveStreamEnd(PacketPtr pkt) {
  auto endStrandIdPtr = *(pkt->getPtr<DynStrandId *>());
  const auto &endStrandId = *endStrandIdPtr;
  LLC_S_DPRINTF_(LLCRubyStreamLife, endStrandId, "Recv StreamEnd at %s.\n",
                 this->controller->getMachineID());
  auto endS = LLCDynStream::getLLCStreamPanic(endStrandId, "Recv StreamEnd.");
  // Search for this stream.
  for (auto iter = this->streams.begin(); iter != this->streams.end(); ++iter) {
    auto &S = *iter;
    if (S == endS) {
      // Found it.
      // ? Can we just sliently release it?
      this->tryRemoveIssuingDirDynS(S);
      this->removeStreamFromMulticastTable(S);
      S->terminate();
      this->streams.erase(iter);
      // Don't forgot to release the memory.
      delete endStrandIdPtr;
      delete pkt;
      if (this->streams.empty()) {
        this->seTracer.write();
      }
      return;
    }
  }
  /**
   * No need to search in migratingStreams?
   * For migrating streams, the end message should be sent to the
   * destination llcBank.
   *
   * However: there is a problem with terminated PtrChaseS.
   * Somehow it does not migrate to the bank of the EndMsg.
   * So far I try to magically terminate it.
   * TODO: Fix this for bfs_pull_adj_uno_aff.
   */
  if (endS->isPointerChase()) {
    /**
     * We directly search in our migrating stream.
     */
    for (auto iter = this->migratingStreams.begin();
         iter != this->migratingStreams.end(); ++iter) {
      auto S = *iter;
      if (S == endS) {
        LLC_S_DPRINTF_(LLCRubyStreamLife, endStrandId,
                       "End Migrating PtrChaseS at %s.\n",
                       this->controller->getMachineID());
        this->migratingStreams.erase(iter);
        this->removeStreamFromMulticastTable(S);
        S->terminate();
        delete endStrandIdPtr;
        delete pkt;
        if (this->streams.empty()) {
          this->seTracer.write();
        }
        return;
      }
    }

    /**
     * Magically put StreamEnd at where the PtrCaseS is.
     */
    auto endCtrl = endS->curOrNextRemoteCtrl();
    auto endSE = endCtrl->getLLCStreamEngine();
    if (endSE != this) {
      LLC_S_DPRINTF_(LLCRubyStreamLife, endStrandId,
                     "Move PtrChaseS End to %s.\n", endCtrl->getMachineID());
      endSE->receiveStreamEnd(pkt);
      return;
    } else {
      // It's coming here.
      assert(endS->getState() == LLCDynStream::State::MIGRATING);
    }
  }

  /**
   * If not found, it is similar case as stream flow control message.
   * We are waiting for the stream to migrate here.
   * Add the message to the pending
   */
  this->pendingEndStrandIds.insert(endStrandId);

  // Don't forgot to release the memory.
  delete endStrandIdPtr;
  delete pkt;
  return;
}

void LLCStreamEngine::receiveStreamMigrate(LLCDynStreamPtr dynS,
                                           bool isCommit) {

  this->initializeTranslationBuffer();

  /**
   * Handle the case for commit migration.
   */
  if (isCommit) {
    LLC_S_DPRINTF_(StreamRangeSync, dynS->getDynStrandId(),
                   "[Commit] Received migrate.\n");
    if (dynS->isTerminated()) {
      LLC_S_DPRINTF_(StreamRangeSync, dynS->getDynStrandId(),
                     "[Commit] Already terminated.\n");

    } else {
      this->commitController->registerStream(dynS);
      this->scheduleEvent(Cycles(1));
    }
    return;
  }

  // Sanity check.
  auto vaddrAndMachineType = dynS->peekNextAllocVAddrAndMachineType();
  auto vaddr = vaddrAndMachineType.first;
  Addr paddr;
  panic_if(!dynS->translateToPAddr(vaddr, paddr),
           "Paddr should always be valid to migrate a stream.");
  [[maybe_unused]] Addr paddrLine = ruby::makeLineAddress(paddr);
  [[maybe_unused]] auto machineType = vaddrAndMachineType.second;
  assert(this->isPAddrHandledByMe(paddrLine, machineType) &&
         "Stream migrated to wrong remote bank.\n");

  if (!this->controller->isStreamAdvanceMigrateEnabled()) {
    if (dynS->hasIndirectDependent()) {
      // This is only enforced when there is dependent streams.
      assert(dynS->inflyRequests == 0 && "Stream migrated with inflyRequests.");
    }
    assert(!dynS->hasDepIndElemReadyToIssue() &&
           "Stream migrated with readyIndirectElements.");
  }

  LLC_S_DPRINTF(dynS->getDynStrandId(),
                "Received migrate. DirectStreams %llu.\n",
                this->streams.size());

  dynS->migratingDone(this->controller);

  // Check for if the stream is already ended.
  if (this->pendingEndStrandIds.count(dynS->getDynStrandId())) {
    dynS->terminate();
    // Try to write trace if we have no streams left.
    if (this->streams.empty()) {
      this->seTracer.write();
    }
    return;
  }

  this->streams.emplace_back(dynS);
  this->addStreamToMulticastTable(dynS);
  this->addIssuingDirDynS(dynS);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamFlow(const DynStreamSliceId &sliceId) {
  // Simply append it to the list.
  LLC_SLICE_DPRINTF_(LLCRubyStreamLife, sliceId, "Recv credit [%lu, +%lu).\n",
                     sliceId.getStartIdx(), sliceId.getNumElements());
  this->pendingStreamFlowControlMsgs.push_back(sliceId);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamCommit(const DynStreamSliceId &sliceId) {
  LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                     "Received stream commit [%llu, %llu).\n",
                     sliceId.getStartIdx(), sliceId.getEndIdx());
  auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
  if (!dynS) {
    // The stream is already released.
    return;
  }
  dynS->addCommitMessage(sliceId);
}

void LLCStreamEngine::receiveStreamDataVecFromCache(
    Cycles delayCycle, Addr paddrLine, const DynStreamSliceIdVec &sliceIds,
    const ruby::DataBlock &dataBlock, const ruby::DataBlock &storeValueBlock) {
  auto readyCycle = this->controller->curCycle() + delayCycle;

  this->traceEvent(readyCycle, ::LLVM::TDG::StreamFloatEvent::LOCAL_REQ_DONE);

  this->receiveStreamDataVec(delayCycle, paddrLine, sliceIds, dataBlock,
                             storeValueBlock);
}

void LLCStreamEngine::receiveStreamDataVec(
    Cycles delayCycle, Addr paddrLine, const DynStreamSliceIdVec &sliceIds,
    const ruby::DataBlock &dataBlock, const ruby::DataBlock &storeValueBlock) {
  auto readyCycle = this->controller->curCycle() + delayCycle;

  /**
   * Notice that we replace the data block here if we are using
   * back storage.
   */
  ruby::DataBlock loadValueBlock = dataBlock;
  auto rubySystem = this->controller->params().ruby_system;
  if (rubySystem->getAccessBackingStore()) {
    // Get the data from backing store.
    RequestPtr req =
        std::make_shared<Request>(paddrLine, rubySystem->getBlockSizeBytes(),
                                  0 /* Flags */, 0 /* MasterId */);
    PacketPtr pkt = Packet::createRead(req);
    pkt->dataStatic(loadValueBlock.getDataMod(0 /* offset */));
    rubySystem->getPhysMem()->functionalAccess(pkt);
    delete pkt;
  }

  for (const auto &sliceId : sliceIds.sliceIds) {
    this->enqueueIncomingStreamDataMsg(readyCycle, paddrLine, sliceId,
                                       loadValueBlock, storeValueBlock);
    LLC_SLICE_DPRINTF(sliceId, "Recv StreamData vaddr %#x %s.\n", sliceId.vaddr,
                      loadValueBlock);
  }
  this->scheduleEvent(Cycles(delayCycle));
}

void LLCStreamEngine::notifyStreamRequestMiss(
    const DynStreamSliceIdVec &sliceIds) {
  if (this->myMachineType() == ruby::MachineType_L2Cache) {
    for (const auto &sliceId : sliceIds.sliceIds) {
      auto llcS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
      if (llcS) {
        auto S = llcS->getStaticS();
        S->statistic.numMissL2++;
      }
    }
  }
}

void LLCStreamEngine::receiveStreamNDCRequest(PacketPtr pkt) {
  this->ndcController->receiveStreamNDCRequest(pkt);
}

void LLCStreamEngine::enqueueIncomingStreamDataMsg(
    Cycles readyCycle, Addr paddrLine, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &dataBlock, const ruby::DataBlock &storeValueBlock) {
  auto iter = this->incomingStreamDataQueue.rbegin();
  for (auto end = this->incomingStreamDataQueue.rend(); iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      break;
    }
  }
  this->incomingStreamDataQueue.emplace(iter.base(), readyCycle, paddrLine,
                                        sliceId, dataBlock, storeValueBlock);
  LLC_SLICE_DPRINTF(sliceId, "[IncomingElemQueue] Enqueued %lu.\n",
                    this->incomingStreamDataQueue.size());
  // Some sanity check.
  // if (this->incomingStreamDataQueue.size() > 2048) {
  //   LLC_SLICE_PANIC(sliceId, "[IncomingElemQueue] overflow.");
  // }
}

void LLCStreamEngine::drainIncomingStreamDataMsg() {
  auto curCycle = this->controller->curCycle();
  while (!this->incomingStreamDataQueue.empty()) {
    auto &msg = this->incomingStreamDataQueue.front();
    if (msg.readyCycle <= curCycle) {
      this->receiveStreamData(msg.paddrLine, msg.sliceId, msg.dataBlock,
                              msg.storeValueBlock);
      this->incomingStreamDataQueue.pop_front();
    } else {
      break;
    }
  }
}

void LLCStreamEngine::receiveStreamData(
    Addr paddrLine, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &dataBlock, const ruby::DataBlock &storeValueBlock) {
  /**
   * Since we notify the stream engine for all stream data,
   * it is possible that we don't find the stream if it is not direct
   * stream. Thus we just look up the global map.
   */
  auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
  if (!dynS) {
    // Try stream near-data computing.
    this->ndcController->receiveStreamData(sliceId, dataBlock, storeValueBlock);
    return;
  }

  /**
   * We need to handle NoMigration stream be forwarding the response back to
   * its req. bank.
   */
  if (dynS->isMigrationDisabled() &&
      dynS->getLLCController() != this->controller) {
    this->issueNonMigrateStreamDataToLLC(
        dynS, sliceId, dataBlock, storeValueBlock,
        ruby::RubySystem::getBlockSizeBytes() /* PayloadSize */);
    return;
  }

  // Update inflyRequests.
  if (dynS->inflyRequests == 0) {
    LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
  }
  dynS->inflyRequests--;

  auto S = dynS->getStaticS();

  /**
   * Check if we need to cache this stream for reuse.
   */
  if (this->reuseBuffer->shouldCacheStream(S, dynS->getDynStreamId())) {
    this->reuseBuffer->addLine(sliceId, paddrLine, dataBlock);
  }

  bool needIndirect = !dynS->getIndStreams().empty();
  bool needUpdate = S->isUpdateStream() || S->isAtomicStream();
  bool needSendTo = !(dynS->sendToEdges.empty());

  LLC_SLICE_DPRINTF(sliceId,
                    "Recv Data, InflyReqs %d, NeedIndirect %d, NeedUpdate %d "
                    "NeedSendTo %d StoreBlock %s.\n",
                    dynS->inflyRequests, needIndirect, needUpdate, needSendTo,
                    storeValueBlock);

  // Alert MLC prefetch stream is done.
  if (dynS->configData->isPUMPrefetch) {
    if (dynS->isIndirect()) {
      LLC_SLICE_PANIC(sliceId, "PUMPrefetchStream should not be indirect.");
    }
    this->tryFinishPUMPrefetchStream(dynS, sliceId);
    return;
  }

  /**
   * So far we send back the data for RemoteNestConfig in ideal packet.
   * LoadComputeStream is sent after value is computed.
   */
  if (dynS->configData->hasDepRemoteNestRegion) {

    // Set the elem bank.
    auto coreDynS = S->getDynStream(sliceId.getDynStreamId());
    if (coreDynS) {
      LLC_SLICE_DPRINTF(sliceId, "[Nest] RemoteNestRegion Bank %d.\n",
                        this->curRemoteBank());
      for (auto elemIdx = sliceId.getStartIdx(),
                elemEndIdx = sliceId.getEndIdx();
           elemIdx < elemEndIdx; ++elemIdx) {

        auto elem = dynS->getElemPanic(elemIdx, "setElementRemoteBank");
        int sliceOffset;
        int elemOffset;
        [[maybe_unused]] int overlapSize = elem->computeOverlap(
            sliceId.vaddr, sliceId.getSize(), sliceOffset, elemOffset);
        assert(overlapSize > 0);
        if (elemOffset == 0) {
          // Avoid setting the RemoteBank for the element twice?
          coreDynS->setElementRemoteBank(elemIdx, this->curRemoteBank());
        }
      }
    }

    if (!S->isLoadComputeStream()) {
      LLC_SLICE_DPRINTF(
          sliceId,
          "[Nest] Send back idea RemoteNestRegion VAddr %#x Size %d.\n",
          sliceId.vaddr, sliceId.size);
      auto lineOffset = sliceId.vaddr % ruby::RubySystem::getBlockSizeBytes();
      auto size = sliceId.size;
      this->issueStreamDataToMLC(sliceId, paddrLine,
                                 dataBlock.getData(lineOffset, size), size,
                                 size, lineOffset, true /* forceIdea */
      );
    }
  }

  /**
   * Construct the ElementValue except for AtomicComputeS.
   * AtomicComputeS's value will be set in triggerAtomic.
   * StoreComputeS's value will set when computed.
   */
  if (!S->isAtomicComputeStream() && !S->isStoreComputeStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto elem = dynS->getElemPanic(idx, "RecvElementData");
      if (elem->isReady()) {
        LLC_SLICE_PANIC(sliceId, "Elem already ready.");
      }
      elem->extractElementDataFromSlice(dynS->getStaticS()->getCPUDelegator(),
                                        sliceId, dataBlock);
    }
  }

  /**
   * For DirectStream, we should have the slice in our
   * AllocatedSlice.
   */
  LLCStreamSlicePtr slice = nullptr;
  if (!dynS->isIndirect()) {
    slice = this->tryGetSlice(sliceId);
    if (!slice) {
      LLC_SLICE_PANIC(sliceId, "Failed to get slice when receiving "
                               "data for DirectStream.");
    }
    slice->responded(dataBlock, storeValueBlock);
  }

  /**
   * There are many things to do here.
   * 1. Slice - For StoreStream, perform the store and send back Ack.
   * 2. Slice - For SendTo dependence, send the slice to the
   * receiver.
   * 3. Element - Evaluate LoopBoundFunc.
   * 4. Element - Trigger indirect elements if the base is ready (in
   * order).
   * 5. Element - Trigger update operations (out-of-order).
   * 6. Element - Release ready elements in order.
   */

  if (S->isStoreStream()) {
    this->receiveStoreStreamData(dynS, sliceId, storeValueBlock);
  }

  /**
   * Normally we could just send the data to the receiver stream.
   * However, for LoadComputeStream, we should send after the value
   * is computed.
   */
  if (!S->isLoadComputeStream()) {
    for (const auto &edge : dynS->sendToEdges) {
      this->issueStreamDataToLLC(
          dynS, sliceId, dataBlock, edge,
          ruby::RubySystem::getBlockSizeBytes() /* PayloadSize */);
    }
    for (const auto &edge : dynS->sendToPUMEdges) {
      this->issueStreamDataToPUM(
          dynS, sliceId, dataBlock, edge,
          ruby::RubySystem::getBlockSizeBytes() /* PayloadSize */);
    }
    if (dynS->configData->isPUMPrefetch &&
        this->myMachineType() == ruby::MachineType_Directory) {
      // We need to send back the prefetched line to LLC.
      this->issuePUMPrefetchStreamDataToLLC(dynS, sliceId, dataBlock);
    }
  }

  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    // Evaluate Predicate.
    dynS->evaluatePredication(this, idx);
    // Evaluate LoopBound.
    dynS->evaluateLoopBound(this, idx);
  }

  if (!dynS->getIndStreams().empty()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto elem = dynS->getElemPanic(idx, "RecvElemData to TriggerInd.");
      LLC_SLICE_DPRINTF(sliceId, "Try Trigger Elem %llu Ready %d.\n", elem->idx,
                        elem->isReady());
      if (!elem->isReady()) {
        // Not ready yet. Continue.
        continue;
      }
      this->triggerIndElems(dynS, elem);
    }
  }

  /**
   * The following logic is only for IndirectStream.
   * For DirectStream, these cases are handled in processSlice().
   */
  if (!dynS->isIndirect()) {
    return;
  }

  if (S->isAtomicComputeStream()) {
    this->processIndirectAtomicSlice(dynS, sliceId);
  } else if (S->isUpdateStream()) {
    this->processIndirectUpdateSlice(dynS, sliceId, storeValueBlock);
  }

  if (S->isLoadComputeStream()) {
    /**
     * We register a slice here, directly advance to RESPONDED state,
     * and schedule the computation to merge the code path for
     * DirectStream.
     */
    if (sliceId.getNumElements() != 1) {
      LLC_SLICE_PANIC(sliceId, "IndirectLoadComputeStream with more "
                               "than one element per slice.");
    }
    auto element =
        dynS->getElemPanic(sliceId.getStartIdx(),
                           "ReceiveStreamData for IndirectLoadComputeStream");
    auto slice = std::make_shared<LLCStreamSlice>(S, sliceId);
    slice->allocate(this);
    slice->issue();
    slice->responded(dataBlock, storeValueBlock);
    this->allocatedSlices.push_back(slice);
    element->addSlice(slice);
    this->processLoadComputeSlice(dynS, slice);
  }

  /**
   * Here we release the indirect element, with a few exceptions:
   * 1. DirectStream element released after all slices are released.
   * 2. For IndirectAtomicComputeStream:
   *   a. If it issues after commit, will be released when the final request is
   *      handled.
   *   b. If not, will be released in postProcessIndirectAtomicSlice().
   * 3. IndirectLoadComputeStream is released in releaseSlice().
   */
  LLC_S_DPRINTF(dynS->getDynStrandId(),
                "[IndRelease] Check ShouldIssueAfterCommit %d "
                "IsLoadCompute %d.\n",
                dynS->shouldIssueAfterCommit(), S->isLoadComputeStream());
  if (!dynS->shouldIssueAfterCommit() && !S->isLoadComputeStream() &&
      !S->isAtomicComputeStream()) {
    while (!dynS->idxToElementMap.empty()) {
      auto elemIter = dynS->idxToElementMap.begin();
      const auto &elem = elemIter->second;
      if (!elem->isPredicatedOff()) {
        if (!elem->areBaseElemsReady()) {
          LLC_SE_ELEM_DPRINTF(elem, "Cannot release AreBaseElementsReady %d.\n",
                              elem->areBaseElemsReady());
          break;
        }
        if (S->isStoreComputeStream()) {
          if (!elem->isIndirectStoreAcked()) {
            LLC_SE_ELEM_DPRINTF(elem,
                                "Cannot release IndirectStore not acked.\n");
            break;
          }
        } else {
          if (!elem->isReady()) {
            LLC_SE_ELEM_DPRINTF(elem,
                                "Cannot release NotReady & NotPredOff.\n");
            break;
          }
        }
      }
      dynS->eraseElem(elemIter);
    }
  }

  return;
}

void LLCStreamEngine::receiveStoreStreamData(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &storeValueBlock) {
  /**
   * We received the response for the StoreStream, we now perform the
   * store. And issue Ack back here if this is DirectStream and no
   * range sync.
   *
   * Although we really should perform the store after the core
   * committed, here I store and only delay sending back the Ack in
   * releaseSlice. So far this only works with DirectStream.
   *
   * This means we still immediately send back StreamAck for:
   * 1. StoreComputeStream without RangeSync.
   * 2. Indirect StoreComputeStream.
   *
   * NOTE: We have to construct the overlap instead of storing the
   * whole line.
   * NOTE: Also be careful that storeValueBlock is a CacheLine! While SliceVAddr
   * may be the element vaddr for indirect stream.
   */
  Addr paddr;
  if (!dynS->translateToPAddr(sliceId.vaddr, paddr)) {
    LLC_SLICE_PANIC(sliceId,
                    "Failed to translate StoreStream slice vaddr %#x to paddr.",
                    sliceId.vaddr);
  }
  auto sliceLineVAddr = ruby::makeLineAddress(sliceId.vaddr);
  auto sliceLinePAddr = ruby::makeLineAddress(paddr);
  auto blockSize = ruby::RubySystem::getBlockSizeBytes();
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    assert(dynS->idxToElementMap.count(idx) &&
           "Missing element for StoreStream.");
    auto elem = dynS->getElemPanic(idx, "ReceiveStoreStreamData");

    // Compute the overlap and set the data.
    int elemOffset;
    int sliceOffset;
    int overlapSize = elem->computeOverlap(sliceLineVAddr, blockSize,
                                           sliceOffset, elemOffset);
    auto storeValue = storeValueBlock.getData(sliceOffset, overlapSize);
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore done with Elem %llu, Slice vaddr %#x paddr "
                       "%#x, SliceOffset %d OverlapSize %d Value %s.\n",
                       idx, sliceId.vaddr, paddr, sliceOffset, overlapSize,
                       GemForgeUtils::dataToString(storeValue, overlapSize));
    this->performStore(sliceLinePAddr + sliceOffset, overlapSize, storeValue);
  }
  if (!dynS->shouldRangeSync() || dynS->isIndirect()) {
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore send back StreamAck.\n");
    if (dynS->isIndirect()) {
      auto elem = dynS->getElemPanic(sliceId.getStartIdx(), "AckIndirectStore");
      elem->setIndirectStoreAcked();
    }
    /**
     * Normally without RangeSync, we would send out one Ack per
     * slice. However, we could just sent this out coarse grained.
     * For simplicity, here I just hack by force some idea ack.
     */
    bool forceIdea = dynS->isNextIdeaAck();
    dynS->ackedOneSlice();
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
}

bool LLCStreamEngine::isNextElemHandledHere(LLCDynStreamPtr dynS) const {

  /**
   * If the stream is disabled from migration, always consider the next element
   * handled here.
   */
  if (dynS->isMigrationDisabled()) {
    return true;
  }

  /**
   * We introduce a new special case: If the stream has trip count and have
   * reached the end, do not migrate. The MLC SE need to take care of this
   * special case to correctly send the StreamEnd message.
   */
  if (dynS->hasTotalTripCount()) {
    auto nextElemIdx = dynS->peekNextAllocElemIdx();
    if (nextElemIdx == dynS->getTotalTripCount()) {
      // Do not migrate as we have reached the end.
      return true;
    }
  }

  auto nextVAddrAndMachineType = dynS->peekNextAllocVAddrAndMachineType();
  auto nextVAddr = nextVAddrAndMachineType.first;
  auto nextMachineType = nextVAddrAndMachineType.second;
  Addr nextPAddr;
  if (!dynS->translateToPAddr(nextVAddr, nextPAddr)) {
    // If the address is faulted, we stay here.
    return true;
  }
  // Check if it is still on this bank.
  if (this->isPAddrHandledByMe(nextPAddr, nextMachineType)) {
    // Still here.
    return true;
  }
  return false;
}

bool LLCStreamEngine::canMigrateStream(LLCDynStream *dynS) const {
  /**
   * In this implementation, the stream will aggressively
   * migrate to the next element bank, even the credit has only been
   * allocated to the previous element. Therefore, we do not need to
   * check if the next element is allocated.
   */
  if (this->isNextElemHandledHere(dynS)) {
    return false;
  }
  if (dynS->isLoopBoundBrokenOut()) {
    return false;
  }
  /**
   * We can only enable AdvanceMigrate for DirectStreams.
   * PointerChaseStream can never advance migrate.
   * Streams with LoopBound function can not advance migrate.
   * Streams with PUMSendTo edges can not advance migrate.
   */
  if (!this->controller->isStreamAdvanceMigrateEnabled() ||
      dynS->isPointerChase() || dynS->hasLoopBound() ||
      !dynS->sendToPUMEdges.empty()) {
    if (dynS->hasIndirectDependent() || dynS->isPointerChase() ||
        dynS->hasLoopBound() || !dynS->sendToEdges.empty()) {
      if (dynS->inflyRequests > 0) {
        // We are still waiting data for indirect usages:
        // 1. Indirect streams.
        // 2. Update request.
        // 3. Pointer chasing.
        // 4. Send to PUM.
        LLC_S_DPRINTF(dynS->getDynStrandId(),
                      "[Delay Migrate] InflyRequests %llu.\n",
                      dynS->inflyRequests);
        return false;
      }
    }
    if (dynS->hasLoopBound()) {
      /**
       * We need to check that all loop bound has been evaluated here.
       * For now -- we check all elems before nextAllocElemIdx has been
       * evaluated for LoopBound.
       */
      const auto &nextAllocSliceId = dynS->peekNextAllocSliceId();
      auto nextAllocElemIdx = nextAllocSliceId.getStartIdx();
      for (const auto &idxElem : dynS->idxToElementMap) {
        const auto &elemIdx = idxElem.first;
        const auto &elem = idxElem.second;
        if (elemIdx < nextAllocElemIdx && !elem->isLoopBoundDone()) {
          LLC_SE_ELEM_DPRINTF_(LLCStreamLoopBound, elem,
                               "[Delay Migrate] NextAllocSliceId %s.\n",
                               nextAllocSliceId);
          return false;
        }
      }
    }
    if (dynS->hasDepIndElemReadyToIssue()) {
      // We are still waiting for some indirect streams to be issued.
      LLC_S_DPRINTF(dynS->getDynStrandId(),
                    "[Delay Migrate] ReadyIndirectElems %llu.\n",
                    dynS->getNumDepIndElemReadyToIssue());
      return false;
    }
    /**
     * ! A hack to delay migrate if there is reduction/ptr-chase for any
     * ! indirect stream.
     */
    for (auto IS : dynS->getIndStreams()) {
      if (IS->getStaticS()->isReduction() ||
          IS->getStaticS()->isPointerChaseIndVar()) {
        // We wait for the reduction element to be done.

        if (IS->incompleteComputations > 0) {
          LLC_S_DPRINTF(dynS->getDynStrandId(),
                        "[Delay Migrate] IS %s IncompleteCmp %d.\n",
                        IS->getDynStrandId(), IS->incompleteComputations);
          return false;
        }

        if (!IS->idxToElementMap.empty()) {
          const auto &elem = IS->idxToElementMap.begin()->second;
          /**
           * ! Due to the current hack implementation, an element may
           * already be allocated for the next bank. Our way to
           * hack this is check if the base is already ready. If
           * not, then they are for next bank.
           */
          if (!elem->isReady()) {
            for (const auto &baseE : elem->baseElements) {
              if (baseE->strandId == dynS->getDynStrandId()) {
                if (baseE->isReady()) {
                  // The base element is ready, which means this is
                  // from this bank. If it's not ready, then we
                  // should have inflyRequest.
                  LLC_S_DPRINTF(dynS->getDynStrandId(),
                                "[Delay Migrate] Reduction Elem %s-%lu.\n",
                                IS->getDynStrandId(), elem->idx);
                  return false;
                }
              }
            }
          }
        }
      }
    }
  }
  return true;
}

void LLCStreamEngine::wakeup() {

  // Sanity check.
  if (this->streams.size() >= 1000) {
    panic("Too many LLCStream.\n");
  }

  if (this->streams.size() > 0) {
    this->controller->m_statLLCNumDirectStreams.sample(this->streams.size());
  }
  if (!this->readyComputations.empty()) {
    this->controller->m_statLLCNumReadyComputations.sample(
        this->readyComputations.size());
  }
  if (!this->inflyComputations.empty()) {
    this->controller->m_statLLCNumInflyComputations.sample(
        this->inflyComputations.size());
  }

  // Sample LLC streams.
  this->sampleLLCStreams();

  // Drain incoming element data.
  this->drainIncomingStreamDataMsg();

  this->processStreamFlowControlMsg();
  this->issueStreams();
  this->issueStreamRangesToMLC();
  this->findMigratingStreams();
  this->migrateStreams();
  this->startComputation();
  this->completeComputation();
  this->processSlices();
  this->commitController->commit();

  // So we limit the issue rate in issueStreams.
  while (!this->requestQueue.empty()) {
    const auto &req = this->requestQueue.front();
    if (!req.translationDone) {
      break;
    }
    this->issueStreamReqToRemoteBank(req);
    this->requestQueue.pop_front();
  }

  this->pumEngine->tick();

  if (!this->streams.empty() || !this->issuingIndStreamList.empty() ||
      !this->migratingStreams.empty() || !this->requestQueue.empty() ||
      !this->incomingStreamDataQueue.empty() ||
      !this->allocatedSlices.empty() || !this->readyComputations.empty() ||
      !this->inflyComputations.empty() ||
      this->commitController->hasStreamToCommit()) {
    if (Debug::LLCStreamEngineWake) {
      std::stringstream ss;
      ss << "[Wake] Streams " << this->streams.size() << " IssuingIndS "
         << this->issuingIndStreamList.size() << " MigratingS "
         << this->migratingStreams.size() << " ReqQueue "
         << this->requestQueue.size() << " IncomeDataQueue "
         << this->incomingStreamDataQueue.size() << " Slices "
         << this->allocatedSlices.size() << " ReadyCmp "
         << this->readyComputations.size() << " InflyCmp "
         << this->inflyComputations.size() << " CommitCtrl "
         << this->commitController->hasStreamToCommit();
      if (!this->streams.empty()) {
        ss << "\n Streams:";
        for (auto S : this->streams) {
          ss << "\n  " << S->getDynStrandId();
        }
      }
      LLC_SE_DPRINTF_(LLCStreamEngineWake, "%s\n", ss.str());
    }
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::initializeTranslationBuffer() {
  if (!this->translationBuffer) {
    this->translationBuffer =
        std::make_unique<StreamTranslationBuffer<RequestQueueIter>>(
            this->controller->getCPUDelegator()->getDataTLB(),
            [this](PacketPtr pkt, ThreadContext *tc, RequestQueueIter reqIter)
                -> void { this->translationCallback(pkt, tc, reqIter); },
            true /* AccessLastLevelTLBOnly */
        );
  }
}

bool LLCStreamEngine::canMergeAsMulticast(LLCDynStreamPtr dynSA,
                                          LLCDynStreamPtr dynSB) const {
  /**
   * Streams are considered possible to merged into one multicast
   * stream iff:
   * 1. They are from cores within the same multicast group.
   * 2. They both have linear address generation function.
   * 3. They have same dynamic parameters for address generation.
   * 4. They have the same request type.
   */
  const auto &dynSAId = dynSA->getDynStreamId();
  const auto &dynSBId = dynSB->getDynStreamId();
  if (dynSAId.coreId == dynSBId.coreId) {
    // Ignore streams from the same core.
    return false;
  }
  if (dynSA->getStaticS()->isAtomicComputeStream() ||
      dynSB->getStaticS()->isAtomicComputeStream()) {
    // Should never multicast atomic streams.
    return false;
  }
  auto multicastGroupIdA = this->controller->getMulticastGroupId(
      dynSAId.coreId, this->controller->myParams->stream_multicast_group_size);
  auto multicastGroupIdB = this->controller->getMulticastGroupId(
      dynSBId.coreId, this->controller->myParams->stream_multicast_group_size);
  if (multicastGroupIdA != multicastGroupIdB) {
    // They are not from the same multicast group.
    return false;
  }
  if (dynSA->getStaticId() != dynSA->getStaticId()) {
    return false;
  }
  auto linearAddrGenA = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSA->configData->addrGenCallback);
  auto linearAddrGenB = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSB->configData->addrGenCallback);
  if (!linearAddrGenA || !linearAddrGenB) {
    return false;
  }
  const auto &formalParamsA = dynSA->configData->addrGenFormalParams;
  const auto &formalParamsB = dynSB->configData->addrGenFormalParams;
  if (formalParamsA.size() != formalParamsB.size()) {
    return false;
  }
  for (auto i = 0; i < formalParamsA.size(); ++i) {
    const auto &paramA = formalParamsA.at(i);
    const auto &paramB = formalParamsB.at(i);
    if (!paramA.isInvariant || !paramB.isInvariant) {
      // One of the parameters rely on stream.
      return false;
    }
    if (paramA.invariant != paramB.invariant) {
      return false;
    }
  }
  if (this->getStreamReqType(dynSA) != this->getStreamReqType(dynSB)) {
    return false;
  }
  return true;
}

void LLCStreamEngine::addStreamToMulticastTable(LLCDynStreamPtr dynS) {
  bool hasIndirectDependent = dynS->hasIndirectDependent();
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                 "Add to MulticastTable, HasIndirectDependent %d "
                 "DepEdges %d.\n",
                 hasIndirectDependent, dynS->configData->depEdges.size());
  /**
   * Currently we do not try to multicast streams with indirect
   * dependence. This includes streams with SendTo dependence.
   */
  // We only try to merge into multicast if it has no indirect
  // dependent.
  if (!hasIndirectDependent && dynS->configData->depEdges.empty()) {
    for (auto &entry : this->multicastStreamMap) {
      auto dynSRoot = entry.first;
      auto &group = entry.second;
      auto canMerge = this->canMergeAsMulticast(dynS, dynSRoot);
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynStrandId(),
                     "Check CanMergeAsMulticast %d.\n", canMerge);
      if (canMerge) {
        // Found the entry.
        group.push_back(dynS);
        dynS->setMulticastGroupLeader(dynSRoot);
        this->sortMulticastGroup(group);
        LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynStrandId(),
                       "Merged into MulticastGroup.\n");
        return;
      }
    }
  }
  // Not found.
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                 "New MulticastGroup.\n");
  this->multicastStreamMap
      .emplace(std::piecewise_construct, std::forward_as_tuple(dynS),
               std::forward_as_tuple())
      .first->second.push_back(dynS);
  dynS->setMulticastGroupLeader(dynS);
}

void LLCStreamEngine::removeStreamFromMulticastTable(LLCDynStreamPtr dynS) {
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                 "Remove from MulticastTable.\n");
  auto multicastGroupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(multicastGroupLeader);
  assert(mapIter != this->multicastStreamMap.end() &&
         "Failed to find multicast group.");
  // First we remove dynS from this group.
  auto &group = mapIter->second;
  bool erased = false;
  for (auto iter = group.begin(), end = group.end(); iter != end; ++iter) {
    if ((*iter) == dynS) {
      group.erase(iter);
      erased = true;
      break;
    }
  }
  panic_if(!erased, "Failed to erase from MulticastGroup.");
  // Clear the multicast leader for dynS.
  dynS->setMulticastGroupLeader(nullptr);
  if (mapIter->first == dynS) {
    if (!group.empty()) {
      // If this is the leader and the group is not empty after
      // removing, we reinsert this group with a new leader.
      auto newLeader = group.front();
      for (auto &S : group) {
        S->setMulticastGroupLeader(newLeader);
      }
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, newLeader->getDynStrandId(),
                     "Select as NewLeader.\n");
      this->multicastStreamMap.emplace(newLeader, group);
    }
    // We can remove the group from the table now.
    [[maybe_unused]] auto erased = this->multicastStreamMap.erase(dynS);
    assert(erased == 1 && "Failed to remove the group");
  }
}

bool LLCStreamEngine::hasMergedAsMulticast(LLCDynStreamPtr dynS) const {
  return this->getMulticastGroup(dynS).size() > 1;
}

LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynStreamPtr dynS) {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

const LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynStreamPtr dynS) const {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

bool LLCStreamEngine::canIssueByMulticastPolicy(LLCDynStreamPtr dynS) const {
  /**
   * There are some policies to tune if we want to delay a stream
   * from issuing to have more multicast oppotunties. Here are the
   * policies:
   * ----- Most Relaxed (Optimize for Latency) ------
   * - Do nothing. Always return ture.
   * - The first stream with NextSliceAllocated in the
   * MulticastGroup.
   * - The stream must be the first one in the MulticastGroup.
   * ---- Most Constranit (Optimize for Traffic) ----
   */

  const auto &group = this->getMulticastGroup(dynS);

  const auto policy = this->controller->getStreamMulticastIssuePolicy();
  switch (policy) {
  case ruby::AbstractStreamAwareController::MulticastIssuePolicy::Any:
    return true;
  case ruby::AbstractStreamAwareController::MulticastIssuePolicy::
      FirstAllocated:
    for (const auto &S : group) {
      if (!S->isNextSliceCredited()) {
        continue;
      }
      // This is the first available stream.
      return S == dynS;
    }
    // Should never happen.
    panic("DynS not found in MulticastGroup.");
  case ruby::AbstractStreamAwareController::MulticastIssuePolicy::First:
    return group.front() == dynS;
  default:
    return true;
  }
}

void LLCStreamEngine::sortMulticastGroup(StreamVec &group) const {
  auto comparator = [this](const LLCDynStreamPtr &SA,
                           const LLCDynStreamPtr &SB) -> bool {
    auto sliceIdxA = SA->getNextAllocSliceIdx();
    auto sliceIdxB = SB->getNextAllocSliceIdx();
    if (sliceIdxA != sliceIdxB) {
      return sliceIdxA < sliceIdxB;
    }
    /**
     * When the next sliceId is the same, it's interesting how we
     * break the tie.
     * 1. If we considered streams with next slice not allocated
     * "smaller", we are more frequently blocked and this achieves
     * maximum save of the traffic, as it exposes more multicast
     * opportunity.
     * 2. Otherwise, we try to issue ready streams with smaller
     * sliceId as soon as possible. This reduces the multicast
     * opportunity, but may help the latency.
     */
    if (SA->isNextSliceCredited() != SB->isNextSliceCredited()) {
      return !SA->isNextSliceCredited(); // Option 1
      // return SA->isNextSliceCredited(); // Option 2
    }
    // Break the tie with core id.
    return SA->getDynStreamId().coreId < SB->getDynStreamId().coreId;
  };
  std::sort(group.begin(), group.end(), comparator);
  if (Debug::LLCRubyStreamMulticast) {
    DPRINTF(LLCRubyStreamMulticast, "Sorted MulticastGroup:---\n");
    for (auto &dynS : group) {
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                     "NextAllocSliceIdx %lu, Allocated %d.\n",
                     dynS->getNextAllocSliceIdx(), dynS->isNextSliceCredited());
    }
    DPRINTF(LLCRubyStreamMulticast, "---\n");
  }
}

void LLCStreamEngine::generateMulticastRequest(RequestQueueIter reqIter,
                                               LLCDynStreamPtr targetDynS) {
  assert(this->controller->isStreamMulticastEnabled());
  auto &group = this->getMulticastGroup(targetDynS);

  const auto &targetSliceId = reqIter->sliceId;
  auto targetSliceIdx = targetDynS->getNextAllocSliceIdx();
  assert(targetSliceIdx > 0 &&
         "DynS should have positive NextSliceIdx as it generated "
         "reqIter.");
  LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, targetSliceId,
                     "Generate MulticastRequest.\n");
  // Start to scan, skip dynS.
  for (auto idx = 0; idx < group.size(); ++idx) {
    auto dynS = group.at(idx);
    if (dynS == targetDynS) {
      // We just issued.
      continue;
    }
    if (!dynS->getCoreDynS()) {
      // The CoreDynS has already been released. Skip this one.
      continue;
    }
    if (!dynS->isNextSliceCredited()) {
      // Not allocated, skip this one.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 < targetSliceIdx) {
      // This is behind stream, skip it.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 > targetSliceIdx) {
      // This is future stream, we are done.
      break;
    }
    // Found a multicast stream candidate.
    auto slice = this->allocateSlice(dynS);
    slice->issue();
    const auto &sliceId = slice->getSliceId();
    // Sanity check for multicast slices.
    if (sliceId.vaddr != targetSliceId.vaddr) {
      LLC_SLICE_PANIC(sliceId, "Mismatch VAddr %#x for Multicast Slice %#x.",
                      sliceId.vaddr, targetSliceId.vaddr);
    }
    if (sliceId.getSize() != targetSliceId.getSize()) {
      LLC_SLICE_PANIC(sliceId, "Mismatch Size %d for Multicast Slice %d.",
                      sliceId.getSize(), targetSliceId.getSize());
    }

    auto SS = dynS->getStaticS();
    this->incrementIssueSlice(SS->statistic);

    // Add this to the request.
    auto reqType = this->getStreamReqType(dynS);
    if (reqType != reqIter->requestType) {
      LLC_SLICE_PANIC(sliceId, "Multicast ReqType Mismatch Target %s, Ours %s.",
                      reqIter->requestType, reqType);
    }
    if (reqType == ruby::CoherenceRequestType_GETU) {
      SS->statistic.numLLCSentSlice++;
      SS->se->numLLCSentSlice++;
      SS->statistic.numLLCMulticastSlice++;
      SS->statistic.numLLCCanMulticastSlice++;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast Issue.\n");
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    if (hasIndirectDependent) {
      LLC_SLICE_PANIC(sliceId, "Multicast Issue with IndirectDependent.\n");
    }
    dynS->prevIssuedCycle = this->controller->curCycle();
    dynS->updateIssueClearCycle();
    // Track infly requests.
    dynS->inflyRequests++;

    reqIter->multicastSliceIds.push_back(sliceId);
  }

  if (!reqIter->multicastSliceIds.empty()) {
    targetDynS->getStaticS()->statistic.numLLCMulticastSlice++;
  }

  // Finally we want to make sure we are sorted.
  this->sortMulticastGroup(group);
}

void LLCStreamEngine::processStreamFlowControlMsg() {
  auto iter = this->pendingStreamFlowControlMsgs.begin();
  auto end = this->pendingStreamFlowControlMsgs.end();
  while (iter != end) {
    const auto &msg = *iter;
    bool processed = false;
    auto dynS = LLCDynStream::getLLCStream(msg.getDynStrandId());
    if (dynS) {
      if (dynS->getState() == LLCDynStream::State::RUNNING &&
          dynS->getLLCController() == this->controller &&
          msg.getStartIdx() == dynS->creditedSliceIdx) {
        // The stream is at our bank. Update the idx.
        LLC_S_DPRINTF_(LLCRubyStreamLife, dynS->getDynStrandId(),
                       "Add credit %lu -> %lu.\n", msg.getStartIdx(),
                       msg.getEndIdx());
        dynS->addCredit(msg.getNumElements());
        // Maybe we want to resort the Multicast group.
        if (this->controller->isStreamMulticastEnabled() &&
            this->hasMergedAsMulticast(dynS)) {
          this->sortMulticastGroup(this->getMulticastGroup(dynS));
        }
        processed = true;
      }
    } else {
      // Delete the credit message if the stream is already released
      // due to StreamLoopBound.
      LLC_S_DPRINTF_(LLCRubyStreamLife, msg.getDynStrandId(),
                     "[Credit] Discard credit %lu -> %lu as LLCDynStream "
                     "already released.\n",
                     msg.getStartIdx(), msg.getEndIdx());
      processed = true;
    }
    if (processed) {
      iter = this->pendingStreamFlowControlMsgs.erase(iter);
    } else {
      ++iter;
    }
  }
}

void LLCStreamEngine::issueStreams() {

  /**
   * Enforce thresholds for issue stream requests here.
   * 1. If there are many requests in the queue, there is no need to
   * inject more packets to block the queue.
   * 2. As a sanity check, we limit the total number of infly direct
   * requests.
   */

  if (this->streamIssueMsgBuffer->getSize(this->controller->clockEdge()) >=
      this->maxInqueueRequests) {

    // Record this in streams.
    for (auto dynS : this->streams) {
      auto &statistic = dynS->getStaticS()->statistic;
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MaxEngineInflyRequest);
    }

    return;
  }

  // By cheching i < nStreams we avoid issuing the same stream more
  // than once.
  auto issuedStreams = 0;

  /**
   * New issuing logic: manage IndS separately.
   * Ready IndS is now stored in issuingIndStreamList/Set, and we need to
   * check them first.
   */
  for (auto indSIter = this->issuingIndStreamList.begin(),
            indSEnd = this->issuingIndStreamList.end();
       indSIter != indSEnd && issuedStreams < this->issueWidth;) {

    auto dynStrandId = *indSIter;
    auto dynIS = LLCDynStream::getLLCStream(dynStrandId);

    if (!dynIS) {
      auto removeIter = indSIter++;
      LLC_S_DPRINTF(dynStrandId, "[IndS] Already Released Not Issue.\n");
      this->removeIssuingIndDynS(removeIter);
      continue;
    }

    if (!dynIS->hasElemReadyToIssue()) {
      /**
       * The IndS has no element to issue. This is possible for the current
       * implementation that it is issued by some other LLC SE.
       * In such cases, we simply remove from the list.
       * TODO: Fix this and relax the issuing order for IndS.
       */
      auto removeIter = indSIter++;
      LLC_S_DPRINTF(dynIS->getDynStrandId(), "[IndS] No Elem to Issue.\n");
      this->removeIssuingIndDynS(removeIter);
      continue;
    }

    auto IS = dynIS->getStaticS();
    if (auto elem = dynIS->getFirstReadyToIssueElem()) {
      auto elemIdx = elem->idx;

      /**
       * Hack: We enforce ordering of alised IndirectUpdateStream
       * here.
       * TODO: Really implement the ordering scheme by piggyback the
       * previous element going to that bank and let the indrect LLC
       * SE handles ordering. However, delay issuing here actually
       * pays more overhead, so we should be okay as we are not
       * cheating for performance.
       */
      if (IS->isUpdateStream()) {
        bool hasAliasedWithPreviousElement = false;
        for (const auto &idxElement : dynIS->idxToElementMap) {
          if (idxElement.first >= elemIdx) {
            break;
          }
          const auto &prevElement = idxElement.second;
          if (prevElement->vaddr == elem->vaddr &&
              !prevElement->isComputedValueReady()) {
            LLC_SE_ELEM_DPRINTF(elem,
                                "[NotIssue] Aliased Indirect "
                                "UpdateElement %llu %#x.\n",
                                prevElement->idx, prevElement->vaddr);
            IS->statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::
                    AliasedIndirectUpdate);
            hasAliasedWithPreviousElement = true;
            break;
          }
        }
        if (hasAliasedWithPreviousElement) {
          // We need to try again some time later.
          ++indSIter;
          continue;
        }
      }

      /**
       * We are able to issue.
       * Move to the next one.
       */
      this->issueStreamIndirect(dynIS);
      issuedStreams++;
      ++indSIter;

    } else {
      /**
       * Somehow the next issuing elem is not ready yet.
       * We just remove from the list and later when the issuing elem is marked
       * ready, we will be added back to the list.
       */
      auto removeIter = indSIter;
      ++indSIter;
      LLC_S_DPRINTF(dynIS->getDynStrandId(),
                    "[IndS] No NextIssueElem %lu ReadyElems %d.\n",
                    dynIS->getNextIssueElemIdx(),
                    dynIS->getNumElemReadyToIssue());
      this->removeIssuingIndDynS(removeIter);
    }
  }

  /**
   * New Issue Logic: Now check IssuingDirStreams.
   */
  auto streamIter = this->issuingDirStreamList.begin();
  auto streamEnd = this->issuingDirStreamList.end();
  auto checkedStreams = 0;
  auto nStreams = this->issuingDirStreamList.size();
  for (; checkedStreams < nStreams && issuedStreams < this->issueWidth;
       ++checkedStreams) {
    auto curIter = streamIter;

    auto dynS = LLCDynStream::getLLCStreamPanic(*curIter, "Issue DirS.");

    /**
     * If this dynS is overflown, remove it from the IssueList.
     */
    if (dynS->isNextElemOverflown() || dynS->isNextSliceOverflown()) {
      LLC_S_DPRINTF(dynS->getDynStrandId(),
                    "[Not Issue] Overflown %lld Remove from IssueList.\n",
                    dynS->getTotalTripCount());
      streamIter = this->issuingDirStreamList.erase(streamIter);
      continue;
    }

    // Move to the next one.
    ++streamIter;

    auto readyS = this->findStreamReadyToIssue(dynS);
    if (readyS) {
      this->issueStreamDirect(readyS);
      issuedStreams++;
      // Push the stream back to the end.
      this->issuingDirStreamList.splice(streamEnd, this->issuingDirStreamList,
                                        curIter);
    }
  }
  for (; checkedStreams < nStreams; ++checkedStreams) {
    // Record that they are not checked.
    assert(streamIter != streamEnd && "Should never happen.");
    auto dynS = LLCDynStream::getLLCStreamPanic(*streamIter, "MaxIssue DirS");
    auto &statistic = dynS->getStaticS()->statistic;
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxIssueWidth);
  }
}

LLCDynStreamPtr LLCStreamEngine::findStreamReadyToIssue(LLCDynStreamPtr dynS) {

  auto S = dynS->getStaticS();
  auto &statistic = S->statistic;

  if (!dynS->isNextSliceCredited()) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                   "[Not Issue] NextSliceNotAllocated.\n");
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::NextSliceNotAllocated);
    return nullptr;
  }

  /**
   * If we enabled Multicast and this is not the lowest stream in
   * the multicast group, i.e. lagging the most behind, then we do
   * not issue it as we are waiting for behind streams to catch up
   * and explore multicast opportunity.
   */
  if (this->controller->isStreamMulticastEnabled()) {
    if (!this->canIssueByMulticastPolicy(dynS)) {
      LLC_S_DPRINTF(dynS->getDynStrandId(), "[Not Issue] MulticastPolicy.\n");
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MulticastPolicy);
      return nullptr;
    }
  }

  /**
   * Check if we have reached issue limit for this stream. Only do
   * this for streams with core user.
   */
  const auto curCycle = this->controller->curCycle();
  if (dynS->shouldUpdateIssueClearCycle()) {
    if (curCycle < dynS->prevIssuedCycle + dynS->issueClearCycle) {
      // We can not issue yet.
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                     "[Not Issue] IssueClearCycle %s Current %s.\n",
                     dynS->issueClearCycle, curCycle - dynS->prevIssuedCycle);
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::IssueClearCycle);
      return nullptr;
    }
  }

  /**
   * Enforce the per stream maxInflyRequests constraint.
   * PointerChaseStream always has at most one infly request.
   */
  if (dynS->inflyRequests == dynS->getMaxInflyRequests()) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                   "[Not Issue] MaxInflyReqs %d.\n",
                   dynS->getMaxInflyRequests());
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
    return nullptr;
  }

  /**
   * Check that the next address is still handled here.
   * Due to the waiting indirect element, a stream may not be
   * migrated immediately after the stream engine found the next
   * element is not handled here. In such case, we simply give up and
   * return false.
   * Also, when the stream is disabled from migrating, we always consider the
   * next element handled here.
   *
   * In case of faulting, the slice will be skipped (see
   * issueDirectStream()).
   */
  auto vaddrAndMachineType = dynS->peekNextAllocVAddrAndMachineType();
  Addr vaddr = vaddrAndMachineType.first;
  auto machineType = vaddrAndMachineType.second;
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {
    if (!dynS->isMigrationDisabled() &&
        !this->isPAddrHandledByMe(paddr, machineType)) {
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                     "[Not Issue] PendingMigrate.\n");
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::PendingMigrate);
      return nullptr;
    }
  }

  /**
   * If this stream needs to be coordinated with the PUMEngine, check that the
   * PUMEngine is done.
   */
  if (dynS->configData->needSyncWithPUMEngine()) {
    auto nextElemIdx = dynS->peekNextAllocElemIdx();
    auto waitForPUMRounds = dynS->configData->waitForPUMRounds(nextElemIdx);
    if (this->pumEngine->shouldWaitPUMRound(
            dynS->configData->pumContextId, waitForPUMRounds,
            dynS->configData->waitPUMRoundStart)) {
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                     "[Not Issue] Elem %lu Waiting for PUM Round %ld.\n",
                     nextElemIdx, waitForPUMRounds);
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::WaitingPUM);
      return nullptr;
    }
  }

  /**
   * Allocate the element on Atomic/Store/UpdateS. Additional check:
   *
   * UpdateS should have BaseElems ready (except itself).
   * StoreS should have StoreValue ready.
   */
  if (S->isStoreComputeStream() || S->isAtomicComputeStream() ||
      S->isUpdateStream()) {
    auto nextSlice = dynS->getNextAllocSlice();
    if (!nextSlice) {
      LLC_S_PANIC(dynS->getDynStrandId(), "Failed to get next alloc slice.");
    }
    const auto &nextSliceId = nextSlice->getSliceId();
    if (S->isStoreComputeStream()) {
      /**
       * Try to schedule compuation for each slice.
       * This is to break the limitation that only one StoreComputeSlice is
       * scheduled at one time.
       */
      for (auto iter = dynS->idxToElementMap.find(nextSliceId.getStartIdx()),
                end = dynS->idxToElementMap.end();
           iter != end; ++iter) {
        auto &elem = iter->second;
        /**
         * If the element is from next slice, we need to check that it's handled
         * here.
         */
        if (elem->idx >= nextSliceId.getEndIdx()) {
          Addr paddr;
          panic_if(!dynS->translateToPAddr(elem->vaddr, paddr),
                   "Failed to translate for DirectStoreComputeStream.");
          auto elemMachineType = dynS->getFloatMachineTypeAtElem(elem->idx);
          if (!this->isPAddrHandledByMe(paddr, elemMachineType)) {
            // This element is not handled here.
            break;
          }
        }
        if (!elem->isReady()) {
          if (!elem->areBaseElemsReady() ||
              dynS->incompleteComputations >=
                  this->controller->myParams
                      ->llc_stream_engine_max_infly_computation) {
            // In order issue with maximum number incomplete
            // computations equals to the LLC SE throughput.
            break;
          }
          if (elem->areBaseElemsReady() && !elem->isComputationScheduled()) {
            this->pushReadyComputation(elem, true /* TryVectorize */);
          }
        }
      }
      for (auto idx = nextSliceId.getStartIdx(); idx < nextSliceId.getEndIdx();
           ++idx) {
        auto elem = dynS->getElemPanic(idx, "Check StoreValue Ready.");
        // Check if the element is ready.
        if (!elem->isReady()) {
          LLC_SLICE_DPRINTF_(
              LLCRubyStreamNotIssue, nextSliceId,
              "StoreValue from Elem %llu not ready, delay issuing.\n", idx);
          if (!elem->areBaseElemsReady()) {
            statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::BaseValueNotReady);
          } else {
            statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::ValueNotReady);
          }
          return nullptr;
        }
      }
    } else if (S->isUpdateStream()) {
      for (auto idx = nextSliceId.getStartIdx(); idx < nextSliceId.getEndIdx();
           ++idx) {
        auto elem = dynS->getElemPanic(idx, "Check UpdateBaseElem Ready.");
        // Check if the element is ready.
        if (!elem->areBaseElemsReady()) {
          LLC_SLICE_DPRINTF_(LLCRubyStreamNotIssue, nextSliceId,
                             "UpdateElem %llu Base not ready, delay issuing.\n",
                             idx);
          statistic.sampleLLCStreamEngineIssueReason(
              StreamStatistic::LLCStreamEngineIssueReason::BaseValueNotReady);
          return nullptr;
        }
      }
    }
  }

  // We should be able to issue this stream.
  statistic.sampleLLCStreamEngineIssueReason(
      StreamStatistic::LLCStreamEngineIssueReason::Issued);
  return dynS;
}

void LLCStreamEngine::addIssuingDirDynS(LLCDynStreamPtr dynS) {
  this->issuingDirStreamList.push_back(dynS->getDynStrandId());
}

LLCStreamEngine::StrandIdList::iterator
LLCStreamEngine::removeIssuingDirDynS(StrandIdList::iterator iter) {
  return this->issuingDirStreamList.erase(iter);
}

void LLCStreamEngine::tryRemoveIssuingDirDynS(LLCDynStreamPtr dynS) {
  for (auto iter = this->issuingDirStreamList.begin(),
            end = this->issuingDirStreamList.end();
       iter != end;) {
    if (dynS->getDynStrandId() == (*iter)) {
      iter = this->issuingDirStreamList.erase(iter);
    } else {
      ++iter;
    }
  }
}

void LLCStreamEngine::addIssuingIndDynS(LLCDynStreamPtr dynIS) {
  if (this->issuingIndStreamSet.count(dynIS->getDynStrandId())) {
    return;
  }
  if (this->issuingIndStreamList.empty()) {
    this->scheduleEvent(Cycles(1));
  }
  this->issuingIndStreamList.push_back(dynIS->getDynStrandId());
  this->issuingIndStreamSet.insert(dynIS->getDynStrandId());
}

void LLCStreamEngine::removeIssuingIndDynS(StrandIdList::iterator iter) {
  auto dynStrandId = *iter;
  LLC_S_DPRINTF(dynStrandId, "[IndS] Remove from Issue List.\n");
  this->issuingIndStreamSet.erase(dynStrandId);
  this->issuingIndStreamList.erase(iter);
}

void LLCStreamEngine::removeDynS(LLCDynStreamPtr dynS) {
  for (auto iter = this->streams.begin(), end = this->streams.end();
       iter != end; ++iter) {
    if (*iter == dynS) {
      this->streams.erase(iter);
      return;
    }
  }
  LLC_S_PANIC(dynS->getDynStrandId(), "Failed to remove from StreamList.");
}

void LLCStreamEngine::issueStreamDirect(LLCDynStream *dynS) {

  auto S = dynS->getStaticS();
  auto &statistic = S->statistic;

  // Get the next address.
  auto slice = this->allocateSlice(dynS);
  const auto &sliceId = slice->getSliceId();
  Addr vaddr = sliceId.vaddr;
  auto machineType = dynS->getFloatMachineTypeAtElem(sliceId.getStartIdx());
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {

    // The paddr is valid. We issue request to the LLC.
    Addr vaddrLine = ruby::makeLineAddress(vaddr);
    Addr paddrLine = ruby::makeLineAddress(paddr);

    // Remember that the slice has issued.
    slice->issue();

    if (!dynS->isMigrationDisabled() &&
        !this->isPAddrHandledByMe(paddr, machineType)) {
      LLC_S_PANIC(dynS->getDynStrandId(), "Next addr is not handled here %#x.",
                  paddr);
    }

    this->incrementIssueSlice(statistic);

    // Push to the request queue.
    auto reqType = this->getStreamReqType(dynS);
    if (reqType == ruby::CoherenceRequestType_GETU) {
      statistic.numLLCSentSlice++;
      S->se->numLLCSentSlice++;
      if (this->hasMergedAsMulticast(dynS)) {
        statistic.numLLCCanMulticastSlice++;
      }
    }
    auto requestIter = this->enqueueRequest(S, sliceId, vaddrLine, paddrLine,
                                            this->myMachineType(), reqType);

    if (S->isStoreStream()) {
      /**
       * For StoreStream, we build the stored data by extracting
       * overlap region from elements. Notice that we can release any
       * older elements, as later we perform the store in slice
       * granularity, not element granularity. Thus element is not
       * used anymore.
       */
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        assert(dynS->idxToElementMap.count(idx) &&
               "Missing element for StoreStream.");
        const auto &elem = dynS->idxToElementMap.at(idx);
        assert(elem->isReady() && "StoreElement is not ready.");

        // Compute the overlap and set the data.
        int elemOffset;
        int sliceOffset;
        int overlapSize = elem->computeOverlap(sliceId.vaddr, sliceId.getSize(),
                                               sliceOffset, elemOffset);
        requestIter->dataBlock.setData(elem->getUInt8Ptr(elemOffset),
                                       sliceOffset, overlapSize);
        requestIter->storeSize = overlapSize;
        LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                           "Get StoreValue from elem %llu, line [%#x, +%d), "
                           "elemOffset %#x.\n",
                           elem->idx, sliceId.vaddr + sliceOffset, overlapSize,
                           elemOffset);
      }
    }

    // Check if we track inflyRequests.
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    dynS->inflyRequests++;
    LLC_SLICE_DPRINTF(sliceId, "Issue, InflyRequests + 1 = %d.\n",
                      dynS->inflyRequests);
    /**
     * Try to handle multicast for streams:
     * 1. Has multicast group.
     * 2. No indirect dependent (can be relaxed later).
     */
    if (!hasIndirectDependent && this->controller->isStreamMulticastEnabled()) {
      this->generateMulticastRequest(requestIter, dynS);
    }

  } else {

    /**
     * ! The paddr is not valid. We ignore this slice.
     */
    LLC_SLICE_DPRINTF(sliceId, "Discard due to fault.\n");
    slice->faulted();

    if (!dynS->getIndStreams().empty()) {
      // Unless this is PtrChaseIV stream.
      if (dynS->isPointerChase()) {
      } else {
        LLC_SLICE_PANIC(sliceId, "Faulted at %#x with Indirect Streams.",
                        sliceId.vaddr);
      }
    }
    statistic.numLLCFaultSlice++;
  }

  // This is also considered issued.
  dynS->prevIssuedCycle = this->controller->curCycle();
  dynS->updateIssueClearCycle();

  // If this is PUMPrefetchStream, release the slice.
  if (dynS->configData->isPUMPrefetch) {
    slice->responded(ruby::DataBlock(), ruby::DataBlock());
    auto sliceIter = this->tryGetSliceIter(sliceId);
    assert(sliceIter != this->allocatedSlices.end());
    while (!dynS->idxToElementMap.empty()) {
      auto elemIter = dynS->idxToElementMap.begin();
      auto &elem = elemIter->second;
      if (elem->idx >= sliceId.getStartIdx()) {
        break;
      }
      dynS->eraseElem(elemIter);
    }
    this->releaseSlice(sliceIter);
  }
}

ruby::CoherenceRequestType
LLCStreamEngine::getStreamReqType(LLCDynStream *stream) const {
  auto reqType = ruby::CoherenceRequestType_GETH;
  auto SS = stream->getStaticS();
  switch (SS->getStreamType()) {
  case ::LLVM::TDG::StreamInfo_Type_AT:
  case ::LLVM::TDG::StreamInfo_Type_ST:
    reqType = ruby::CoherenceRequestType_STREAM_STORE;
    break;
  case ::LLVM::TDG::StreamInfo_Type_LD: {
    if (SS->isUpdateStream()) {
      reqType = ruby::CoherenceRequestType_STREAM_STORE;
    } else if (SS->isLoadComputeStream()) {
      // LoadComputeStream sends back the computed value.
      reqType = ruby::CoherenceRequestType_GETH;
    } else if (stream->configData->hasDepRemoteNestRegion) {
      // Always get here then send back in idea message.
      reqType = ruby::CoherenceRequestType_GETH;
    } else {
      if (auto dynS = stream->getCoreDynS()) {
        if (dynS->shouldCoreSEIssue()) {
          // We have to send back the data.
          reqType = ruby::CoherenceRequestType_GETU;
        }
      } else {
        // The dynamic stream is already released, we don't really
        // care.
      }
    }
    break;
  }
  default:
    panic("Invalid offloaded stream type.\n");
  }

  // (Override) Prefetch streams are always uncached.
  if (stream->configData->isPUMPrefetch) {
    reqType = ruby::CoherenceRequestType_GETH;
  }

  return reqType;
}

void LLCStreamEngine::issueStreamIndirect(LLCDynStream *dynIS) {

  auto elem = dynIS->getFirstReadyToIssueElem();
  if (!elem) {
    LLC_S_PANIC(dynIS->getDynStrandId(), "Try to issue, but no ready element.");
  }
  if (auto llcSE = elem->getLLCSE()) {
    if (llcSE != this) {
      // Make sure the IndS is issued from the correct bank.
      llcSE->issueStreamIndirect(dynIS);
      // Also try to wake it up.
      llcSE->scheduleEvent(Cycles(1));
      return;
    }
  }
  auto elemIdx = elem->idx;
  if (dynIS->shouldIssueBeforeCommit()) {
    this->generateIndirectStreamReq(dynIS, elem);
  } else {
    // We delay issuing this after committed.
    LLC_S_DPRINTF(dynIS->getDynStrandId(),
                  "Delay Issuing for AfterCommit element %llu\n.", elemIdx);
  }
  // Don't forget to the element issued.
  dynIS->markElemIssued(elemIdx);
}

void LLCStreamEngine::generateIndirectStreamReq(LLCDynStream *dynIS,
                                                LLCStreamElementPtr elem) {

  auto IS = dynIS->getStaticS();
  if (IS->isReduction() || IS->isPointerChaseIndVar()) {
    LLC_S_PANIC(dynIS->getDynStrandId(),
                "Reduction is no longer handled here.");
    return;
  }

  if (IS->isStoreComputeStream() || IS->isAtomicComputeStream()) {
    this->issueIndirectStoreOrAtomicReq(dynIS, elem);
  } else {
    // Finally normal indirect load stream.
    this->issueIndirectLoadReq(dynIS, elem);
  }
  return;
}

void LLCStreamEngine::issueIndirectLoadReq(LLCDynStream *dynIS,
                                           LLCStreamElementPtr elem) {
  /**
   * This function handles the most basic case: IndirectLoadStream.
   */
  auto elemIdx = elem->idx;
  DynStreamSliceId sliceId;
  sliceId.getDynStrandId() = dynIS->getDynStrandId();
  sliceId.getStartIdx() = elemIdx;
  sliceId.getEndIdx() = elemIdx + 1;
  auto elemSize = dynIS->getMemElementSize();
  Addr elemVAddr = elem->vaddr;
  auto elemMachineType = dynIS->getFloatMachineTypeAtElem(elemIdx);

  const auto blockBytes = ruby::RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticS();
  auto dynCoreIS = dynIS->getCoreDynS();

  auto reqType = this->getStreamReqType(dynIS);
  LLC_SLICE_DPRINTF(sliceId,
                    "Issue IndirectLoad InflyReq %d %s VAddr %#x CoreDynS %d "
                    "ShouldCoreSEIssue %d IsLoadCompute %d.\n",
                    dynIS->inflyRequests,
                    ruby::CoherenceRequestType_to_string(reqType), elemVAddr,
                    dynCoreIS != nullptr,
                    dynCoreIS ? dynCoreIS->shouldCoreSEIssue() : -1,
                    IS->isLoadComputeStream());

  assert(!dynIS->isPseudoOffload() &&
         "Indirect stream should never be PseudoOffload.");
  auto totalSliceSize = 0;
  auto totalSlices = 0;
  while (totalSliceSize < elemSize) {
    Addr curSliceVAddr = elemVAddr + totalSliceSize;
    // Make sure the slice is contained within one line.
    int lineOffset = curSliceVAddr % blockBytes;
    auto curSliceSize = std::min(elemSize - totalSliceSize,
                                 static_cast<int>(blockBytes) - lineOffset);
    // Here we set the slice vaddr and size.
    sliceId.vaddr = curSliceVAddr;
    sliceId.size = curSliceSize;
    Addr curSlicePAddr;
    if (dynIS->translateToPAddr(curSliceVAddr, curSlicePAddr)) {
      Addr curSliceVAddrLine = ruby::makeLineAddress(curSliceVAddr);
      Addr curSlicePAddrLine = ruby::makeLineAddress(curSlicePAddr);
      this->incrementIssueSlice(IS->statistic);
      if (reqType == ruby::CoherenceRequestType_GETU) {
        IS->statistic.numLLCSentSlice++;
        IS->se->numLLCSentSlice++;
      }

      // Push to the request queue.
      this->enqueueRequest(IS, sliceId, curSliceVAddrLine, curSlicePAddrLine,
                           elemMachineType, reqType);
      dynIS->inflyRequests++;
    } else {
      // For faulted slices, we simply ignore it.
      LLC_SLICE_DPRINTF(sliceId, "Discard due to fault, vaddr %#x.\n",
                        sliceId.vaddr);
      dynIS->getStaticS()->statistic.numLLCFaultSlice++;
    }

    totalSliceSize += curSliceSize;
    totalSlices++;
  }

  if (IS->isLoadComputeStream() && totalSlices != 1) {
    LLC_S_PANIC(dynIS->getDynStrandId(),
                "IndirectLoadComputeStream with Multi-Line Element "
                "is not supported.");
  }
}

void LLCStreamEngine::issueIndirectStoreOrAtomicReq(LLCDynStream *dynIS,
                                                    LLCStreamElementPtr elem) {

  auto elemIdx = elem->idx;
  DynStreamSliceId sliceId;
  sliceId.getDynStrandId() = dynIS->getDynStrandId();
  sliceId.getStartIdx() = elemIdx;
  sliceId.getEndIdx() = elemIdx + 1;
  auto elemSize = dynIS->getMemElementSize();
  Addr elemVAddr = elem->vaddr;
  auto elemMachineType = dynIS->getFloatMachineTypeAtElem(elemIdx);
  LLC_SLICE_DPRINTF(sliceId, "Issue IndStore/Atomic VAddr %#x At %s.\n",
                    elemVAddr, elemMachineType);

  [[maybe_unused]] const auto blockBytes =
      ruby::RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticS();
  const auto &indirectConfig = dynIS->configData;

  // This is a store/atomic, we need to issue STREAM_STORE request.
  assert(elemSize <= sizeof(uint64_t) && "Oversized merged store stream.");
  if (dynIS->hasTotalTripCount()) {
    assert(elemIdx < dynIS->getTotalTripCount() &&
           "Try to store beyond TotalTripCount.");
  }

  assert((elemVAddr % blockBytes) + elemSize <= blockBytes &&
         "Multi-line merged store stream.");

  sliceId.vaddr = elemVAddr;
  sliceId.size = elemSize;
  Addr elemPAddr;
  if (dynIS->translateToPAddr(elemVAddr, elemPAddr)) {
    this->incrementIssueSlice(IS->statistic);
    auto vaddrLine = ruby::makeLineAddress(elemVAddr);
    auto paddrLine = ruby::makeLineAddress(elemPAddr);
    /**
     * Compute the store value.
     * If this is a MergededPedicatedStream, it is a constant value.
     * If this is a MergededLoadStoreDepStream, it is computed use
     * the StoreCallback.
     * TODO: These should be merged together.
     */
    uint64_t storeValue = 0;
    if (IS->isMergedPredicated()) {
      // TODO: This is no longer supported.
      panic("MergedPredicated is not supported for now.");
      // storeValue = indirectConfig->constUpdateValue;
    } else if (IS->isStoreComputeStream()) {
      // Compute the value.
      auto getBaseStreamValue = [&elem](uint64_t baseStreamId) -> StreamValue {
        return elem->getBaseStreamValue(baseStreamId);
      };
      auto params = convertFormalParamToParam(indirectConfig->storeFormalParams,
                                              getBaseStreamValue);
      storeValue = indirectConfig->storeCallback->invoke(params).front();
    } else {
      assert("Unknow merged stream type.");
    }

    // Push to the request queue.
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore -> RequestQueue, StoreValue %lu.\n",
                       storeValue);
    bool isIdeaStore = false;
    int storeSize = sliceId.size;
    if (this->controller->isStreamIdeaStoreEnabled()) {
      isIdeaStore = true;
    } else if (this->controller->isStreamCompactStoreEnabled()) {
      /**
       * Check if we can compact.
       * This is just an approximation, as the request is sending
       * out immediately.
       * TODO: Implement a realistic compact scheme.
       */
      if (dynIS->prevStorePAddrLine == paddrLine) {
        // We can compact.
        isIdeaStore = true;
      } else {
        // As an overhead, we set StoreSize to 64 due to compaction.
        if (IS->isDirectMemStream()) {
          storeSize = ruby::RubySystem::getBlockSizeBytes();
        }
      }
    }

    dynIS->prevStorePAddrLine = paddrLine;
    dynIS->prevStoreCycle = this->controller->curCycle();
    if (isIdeaStore) {
      this->performStore(elemPAddr, elemSize,
                         reinterpret_cast<uint8_t *>(&storeValue));
      LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                         "Ideal StreamStore done with value %llu, "
                         "send back StreamAck.\n",
                         storeValue);

      const bool forceIdeaAck = true;
      this->issueStreamAckToMLC(sliceId, forceIdeaAck);
      if (!this->requestQueue.empty()) {
        this->scheduleEvent(Cycles(1));
      }
    } else {
      auto reqType = this->getStreamReqType(dynIS);
      auto reqIter = this->enqueueRequest(IS, sliceId, vaddrLine, paddrLine,
                                          elemMachineType, reqType);
      dynIS->inflyRequests++;
      auto lineOffset = sliceId.vaddr % ruby::RubySystem::getBlockSizeBytes();
      reqIter->dataBlock.setData(reinterpret_cast<uint8_t *>(&storeValue),
                                 lineOffset, sliceId.size);
      reqIter->storeSize = storeSize;
    }

  } else {
    panic("Faulted merged store stream.");
  }
}

void LLCStreamEngine::issueIndirectAtomicUnlockRequest(
    LLCDynStream *dynIS, LLCStreamElementPtr elem) {

  auto elemIdx = elem->idx;
  DynStreamSliceId sliceId;
  sliceId.getDynStrandId() = dynIS->getDynStrandId();
  sliceId.getStartIdx() = elemIdx;
  sliceId.getEndIdx() = elemIdx + 1;
  auto elemSize = dynIS->getMemElementSize();
  Addr elemVAddr = elem->vaddr;
  auto elemMachineType = dynIS->getFloatMachineTypeAtElem(elemIdx);
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Issue IndirectStore/Atomic VAddr %#x At %s.\n", elemVAddr,
                     elemMachineType);

  [[maybe_unused]] const auto blockBytes =
      ruby::RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticS();

  if (!(dynIS->shouldIssueBeforeCommit() && dynIS->shouldIssueAfterCommit() &&
        IS->isAtomicComputeStream())) {
    LLC_SLICE_PANIC(sliceId, "[IndirectUnlock] Not Requiring Unlock.");
  }

  assert(elemSize <= sizeof(uint64_t) && "Oversized merged store stream.");
  if (dynIS->hasTotalTripCount()) {
    assert(elemIdx < dynIS->getTotalTripCount() &&
           "Try to store beyond TotalTripCount.");
  }

  assert((elemVAddr % blockBytes) + elemSize <= blockBytes &&
         "Multi-line merged store stream.");

  sliceId.vaddr = elemVAddr;
  sliceId.size = elemSize;
  Addr elemPAddr;
  if (dynIS->translateToPAddr(elemVAddr, elemPAddr)) {
    this->incrementIssueSlice(IS->statistic);
    auto vaddrLine = ruby::makeLineAddress(elemVAddr);
    auto paddrLine = ruby::makeLineAddress(elemPAddr);

    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamUnlock -> RequestQueue.\n");

    /**
     * For the second request of AtomicStream, we need to issue StreamUnlock.
     * Push to the request queue.
     */
    auto reqType = ruby::CoherenceRequestType_STREAM_UNLOCK;
    this->enqueueRequest(IS, sliceId, vaddrLine, paddrLine, elemMachineType,
                         reqType);
    dynIS->inflyRequests++;

  } else {
    panic("Faulted IndirectAtomic StreamUnlock.");
  }
}

LLCStreamEngine::RequestQueueIter LLCStreamEngine::enqueueRequest(
    Stream *S, const DynStreamSliceId &sliceId, Addr vaddrLine, Addr paddrLine,
    ruby::MachineType destMachineType, ruby::CoherenceRequestType type) {
  this->requestQueue.emplace_back(S, sliceId, paddrLine, destMachineType, type,
                                  this->controller->curCycle());
  auto requestQueueIter = std::prev(this->requestQueue.end());
  // To match with TLB interface, we first create a fake packet.
  auto cpuDelegator = S->getCPUDelegator();
  auto tc = cpuDelegator->getSingleThreadContext();
  RequestPtr req = std::make_shared<Request>(paddrLine, sliceId.getSize(), 0,
                                             cpuDelegator->dataRequestorId());
  // Set the vaddrLine as this is what we want to translate.
  req->setVirt(vaddrLine);
  // Simply always read request, since this is a fake request.
  auto pkt = Packet::createRead(req);
  // Do not allocate data for this fake packet.
  uint8_t *pktData = nullptr;
  pkt->dataStatic(pktData);
  // Start the translation.
  LLC_SLICE_DPRINTF(sliceId, "Enqueue %s Req: Start Translation.\n",
                    ruby::CoherenceRequestType_to_string(type));
  this->translationBuffer->addTranslation(pkt, tc, requestQueueIter);
  // Since this generates a request, we schedule a wakeup.
  this->scheduleEvent(Cycles(1));
  return requestQueueIter;
}

void LLCStreamEngine::translationCallback(PacketPtr pkt, ThreadContext *tc,
                                          RequestQueueIter reqIter) {
  assert(!reqIter->translationDone && "Translation already done.");
  reqIter->translationDone = true;
  LLC_SLICE_DPRINTF(reqIter->sliceId, "Translated %s Req.\n",
                    ruby::CoherenceRequestType_to_string(reqIter->requestType));
  // Remember to release the pkt.
  delete pkt;
}

void LLCStreamEngine::issueStreamReqToRemoteBank(const LLCStreamRequest &req) {
  const auto &sliceId = req.sliceId;
  const auto paddrLine = req.paddrLine;
  auto selfMachineId = this->controller->getMachineID();

  auto destMachineType = req.destMachineType;
  if (destMachineType != ruby::MachineType_L2Cache &&
      destMachineType != ruby::MachineType_Directory) {
    LLC_SLICE_PANIC(sliceId, "Issue to Unsupported ruby::MachineType %s.\n",
                    destMachineType);
  }

  auto destMachineId = selfMachineId;
  bool handledHere = (destMachineType == selfMachineId.getType()) &&
                     this->isPAddrHandledByMe(req.paddrLine, destMachineType);
  if (handledHere) {
    LLC_SLICE_DPRINTF(sliceId,
                      "Issue [local] %s request vaddr %#x paddrLine %#x value "
                      "%s.\n",
                      req.requestType, sliceId.vaddr, paddrLine, req.dataBlock);

    /**
     * Check if the data is cached in reuse buffer.
     */
    if (req.requestType == ruby::CoherenceRequestType_GETH) {
      const auto &dynSId = sliceId.getDynStreamId();
      if (this->reuseBuffer->shouldCheckReuse(req.S, dynSId) &&
          this->reuseBuffer->contains(sliceId, paddrLine)) {
        LLC_SLICE_DPRINTF(sliceId,
                          "Reuse [local] %s request vaddr %#x paddrLine %#x.\n",
                          req.requestType, sliceId.vaddr, paddrLine);

        req.S->statistic.numRemoteReuseSlice++;

        const auto &reuseDataBlock =
            this->reuseBuffer->reuse(sliceId, paddrLine);

        /**
         * We charge 4 cycle delay.
         */
        Cycles reuseDelayCycles(4);
        DynStreamSliceIdVec sliceIds;
        sliceIds.add(sliceId);
        ruby::DataBlock fakeStoreValueBlock;
        this->receiveStreamDataVecFromReuse(reuseDelayCycles, paddrLine,
                                            sliceIds, reuseDataBlock,
                                            fakeStoreValueBlock);

        return;
      }
    }

  } else {
    destMachineId =
        this->controller->mapAddressToLLCOrMem(paddrLine, destMachineType);
    LLC_SLICE_DPRINTF(
        sliceId,
        "Issue [remote] %s request to %s paddr %#x inqueue %d buffered %d "
        "value %s.\n",
        req.requestType, destMachineId, paddrLine,
        this->streamIndirectIssueMsgBuffer->getSize(curTick()),
        this->indReqBuffer->getTotalBufferedRequests(), req.dataBlock);
  }

  auto msg = std::make_shared<ruby::RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = req.requestType;
  msg->m_Requestors.add(ruby::MachineID(ruby::MachineType_L1Cache,
                                        sliceId.getDynStreamId().coreId));
  msg->m_Destination.add(destMachineId);
  msg->m_MessageSize = ruby::MessageSizeType_Control;
  msg->m_sliceIds.add(sliceId);

  // Sample the delay from issurance to generating the request.
  auto reqGenLatency = this->controller->curCycle() - req.issueCycle;
  req.S->statistic.remoteIssueToReqGenDelay.sample(reqGenLatency);
  req.S->statistic.getStaticStat().remoteIssueToReqGenDelay.sample(
      reqGenLatency);

  // We need to set hold the store value.
  if (req.requestType == ruby::CoherenceRequestType_STREAM_STORE) {
    msg->m_streamStoreBlk = req.dataBlock;
    if (req.storeSize > 8) {
      // We model this as a whole cache line put back.
      msg->m_MessageSize = ruby::MessageSizeType_Response_Data;
    }
  } else if (req.requestType == ruby::CoherenceRequestType_STREAM_FORWARD) {
    msg->m_DataBlk = req.dataBlock;
    // Only used for NonMigrate stream.
    msg->m_streamStoreBlk = req.storeValueBlock;
    msg->m_sendToStrandId = req.forwardToStrandId;
    /**
     * We model special size for StreamForward request.
     */
    msg->m_MessageSize = this->controller->getMessageSizeType(req.payloadSize);
  }

  if (Debug::LLCRubyStreamMulticast && !req.multicastSliceIds.empty()) {
    std::stringstream ss;
    for (const auto &multicastSliceId : req.multicastSliceIds) {
      auto mlcMachineID = ruby::MachineID(
          static_cast<ruby::MachineType>(selfMachineId.type - 1),
          multicastSliceId.getDynStreamId().coreId);
      ss << ' ' << mlcMachineID;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast to %s.\n",
                       ss.str());
  }

  for (const auto &multicastSliceId : req.multicastSliceIds) {
    // TODO: We should really also pass on the sliceId.
    auto mlcMachineID =
        ruby::MachineID(static_cast<ruby::MachineType>(selfMachineId.type - 1),
                        multicastSliceId.getDynStreamId().coreId);
    msg->m_Requestors.add(mlcMachineID);
    msg->m_sliceIds.add(multicastSliceId);
  }

  if (req.requestType == ruby::CoherenceRequestType_STREAM_FORWARD ||
      req.requestType == ruby::CoherenceRequestType_STREAM_STORE) {
    /**
     * Due to broadcast strand, we may not have the DynS.
     * Always find the first strand for recording this statistic.
     *
     * We also record StreamStore to inverstigate indirect traffic.
     */
    auto sendStrandId = sliceId.getDynStrandId();
    sendStrandId.strandIdx = DynStrandId::DefaultFirstStrandIdx;
    auto dynS = LLCDynStream::getLLCStream(sendStrandId);
    if (dynS) {
      auto totalNodesBeforeLLC =
          ruby::MachineType_base_number(ruby::MachineType_L2Cache);
      dynS->getStaticS()->statistic.sampleLLCSendTo(
          selfMachineId.getRawNodeID() - totalNodesBeforeLLC,
          destMachineId.getRawNodeID() - totalNodesBeforeLLC);
    }
  }

  if (handledHere) {
    // Quick path for StreamForward to myself.
    if (req.requestType == ruby::CoherenceRequestType_STREAM_FORWARD) {
      this->receiveStreamFwdReq(*msg);
      return;
    }
    /**
     * Quick path for the second request to release an indirect
     * atomic.
     */
    if (this->tryToProcessIndirectAtomicUnlockReq(*msg)) {
      return;
    }
    Cycles latency(1);
    this->streamIssueMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
    this->traceEvent(::LLVM::TDG::StreamFloatEvent::LOCAL_REQ_START);
  } else {
    /**
     * Issue to StreamRequestBuffer to enforce
     * MaxInqueueRequestPerStream.
     */
    if (req.requestType == ruby::CoherenceRequestType_STREAM_FORWARD) {
      if (this->controller->myParams->enable_stream_idea_forward) {
        auto recvCtrl = ruby::AbstractStreamAwareController::getController(
            msg->getDestination().singleElement());
        auto recvSE = recvCtrl->getLLCStreamEngine();
        recvSE->receiveStreamFwdReq(*msg);
        return;
      }
    }

    /**
     * Check for Idea StreamReq: STREAM_STORE, GETU, GETH.
     */
    if (req.requestType == ruby::CoherenceRequestType_STREAM_STORE ||
        req.requestType == ruby::CoherenceRequestType_GETH ||
        req.requestType == ruby::CoherenceRequestType_GETU) {
      if (this->controller->myParams->enable_stream_idea_ind_req) {
        auto recvCtrl = ruby::AbstractStreamAwareController::getController(
            msg->getDestination().singleElement());
        auto recvSE = recvCtrl->getLLCStreamEngine();
        recvSE->receiveStreamIndirectReqImpl(*msg);
        return;
      }
    }

    this->indReqBuffer->pushRequest(msg);
  }
}

LLCStreamEngine::ResponseMsgPtr LLCStreamEngine::createStreamMsgToMLC(
    const DynStreamSliceId &sliceId, ruby::CoherenceResponseType type,
    Addr paddrLine, const uint8_t *data, int dataSize, int payloadSize,
    int lineOffset) {
  auto selfMachineId = this->controller->getMachineID();
  ruby::MachineID mlcMachineId(ruby::MachineType_L1Cache,
                               sliceId.getDynStreamId().coreId);

  auto msg = std::make_shared<ruby::ResponseMsg>(this->controller->clockEdge());
  // For StreamAck, we do not care about the address?
  msg->m_addr = paddrLine;
  msg->m_Type = type;
  msg->m_Sender = selfMachineId;
  msg->m_Destination.add(mlcMachineId);
  msg->m_MessageSize = ruby::MessageSizeType_Response_Control;
  msg->m_sliceIds.add(sliceId);
  // Try to copy data.
  if (data) {
    assert(lineOffset + dataSize <= ruby::RubySystem::getBlockSizeBytes());
    msg->m_DataBlk.setData(data, lineOffset, dataSize);
    msg->m_MessageSize = this->controller->getMessageSizeType(payloadSize);
  }
  return msg;
}

void LLCStreamEngine::issueStreamMsgToMLC(ResponseMsgPtr msg, bool forceIdea) {

  auto mlcMachineId = msg->m_Destination.singleElement();
  const auto &sliceId = msg->m_sliceIds.singleSliceId();

  // Sample the traffic.
  if (auto llcDynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId())) {
    auto S = llcDynS->getStaticS();
    auto &statistic = S->statistic;
    statistic.sampleSrcDest(statistic.remoteToLocalMsg, this->curRemoteBank(),
                            mlcMachineId.getNum());
  }

  if (forceIdea) {
    auto mlcController =
        ruby::AbstractStreamAwareController::getController(mlcMachineId);
    auto mlcSE = mlcController->getMLCStreamEngine();
    // StreamAck is also disguised as StreamData.
    mlcSE->receiveStreamData(*msg);
    LLC_SLICE_DPRINTF(sliceId, "Send ideal %s to MLC.\n",
                      ruby::CoherenceResponseType_to_string(msg->m_Type));
  } else {
    /**
     * This should match with LLC controller l2_response_latency.
     * TODO: Really get this value from the controller.
     */
    Cycles latency(2);
    this->streamResponseMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
    LLC_SLICE_DPRINTF(sliceId, "Send %s to MLC.\n",
                      ruby::CoherenceResponseType_to_string(msg->m_Type));
  }
}

void LLCStreamEngine::issueStreamAckToMLC(const DynStreamSliceId &sliceId,
                                          bool forceIdea) {

  // For StreamAck, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(sliceId,
                                        ruby::CoherenceResponseType_STREAM_ACK,
                                        paddrLine, nullptr, 0, 0, 0);
  if (this->controller->isStreamIdeaAckEnabled()) {
    forceIdea = true;
  }
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDoneToMLC(const DynStreamSliceId &sliceId,
                                           bool forceIdea) {

  // For StreamDone, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(sliceId,
                                        ruby::CoherenceResponseType_STREAM_DONE,
                                        paddrLine, nullptr, 0, 0, 0);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamRangesToMLC() {
  if (!this->controller->isStreamRangeSyncEnabled()) {
    return;
  }
  for (auto stream : this->streams) {
    auto &rangeBuilder = stream->getRangeBuilder();
    if (!rangeBuilder->hasReadyRanges()) {
      continue;
    }
    auto range = rangeBuilder->popReadyRange();
    /**
     * For DirectStream without IndirectStreams, we issue
     * immediately, as the MLC should really be the one creating this
     * range.
     */
    bool isDirectRange = !stream->isIndirect() &&
                         stream->getIndStreams().empty() &&
                         !stream->isPointerChase();
    bool isIdeal =
        isDirectRange && this->controller->myParams->mlc_generate_direct_range;
    LLC_SE_DPRINTF_(StreamRangeSync, "Issue %s %s range to MLC: %s.\n",
                    isDirectRange ? "direct" : "mixed",
                    isIdeal ? "idea" : "real", *range);

    this->issueStreamRangeToMLC(range, isIdeal);
  }
}

void LLCStreamEngine::issueStreamRangeToMLC(DynStreamAddressRangePtr &range,
                                            bool forceIdea) {
  // Create a fake paddr and slice id.
  Addr paddrLine = 0;
  DynStreamSliceId sliceId;
  sliceId.elementRange = range->elementRange;
  auto msg = this->createStreamMsgToMLC(
      sliceId, ruby::CoherenceResponseType_STREAM_RANGE, paddrLine, nullptr, 0,
      0, 0);
  msg->m_range = range;
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToMLC(const DynStreamSliceId &sliceId,
                                           Addr paddrLine, const uint8_t *data,
                                           int dataSize, int payloadSize,
                                           int lineOffset, bool forceIdea) {
  auto msg = this->createStreamMsgToMLC(
      sliceId, ruby::CoherenceResponseType_DATA_EXCLUSIVE, paddrLine, data,
      dataSize, payloadSize, lineOffset);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToLLC(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &dataBlock,
    const CacheStreamConfigureData::DepEdge &sendToEdge, int payloadSize) {
  /**
   * Unlike sending data to MLC, we have to calculate the virtual
   * address of the receiving stream and translate that. Also, we can
   * only handle the simpliest case so far: no spliting, and no
   * multi-line receiver element.
   *
   * Now that we have strands, we have to be careful translating between
   * StreamElemIdx and StrandElemIdx.
   *
   * SendStrandElemIdx -> SendStreamElemIdx -> RecvStreamElemIdx
   */
  auto recvConfig = sendToEdge.data;

  auto convertSendStrandElemIdxToRecvStreamElemIdx =
      [&sendToEdge](const CacheStreamConfigureDataPtr &sendConfig,
                    uint64_t sendStrandElemIdx) -> uint64_t {
    auto sendStreamElemIdx =
        sendConfig->getStreamElemIdxFromStrandElemIdx(sendStrandElemIdx);
    auto recvStreamElemIdx = CacheStreamConfigureData::convertBaseToDepElemIdx(
        sendStreamElemIdx, sendToEdge.reuse, sendToEdge.skip);
    return recvStreamElemIdx;
  };

  auto getRecvElemVAddr = [&recvConfig](uint64_t recvStreamElemIdx) -> Addr {
    assert(!recvConfig->isStrandConfig() &&
           "RecvConfig should be StreamConfig");
    auto recvElemVAddr =
        recvConfig->addrGenCallback
            ->genAddr(recvStreamElemIdx, recvConfig->addrGenFormalParams,
                      getStreamValueFail)
            .front();
    return recvElemVAddr;
  };

  auto sendStrandElemIdx = sliceId.getStartIdx();
  if (dynS->isOneIterationBehind()) {
    assert(sendStrandElemIdx > 0);
    sendStrandElemIdx--;
  }

  /**
   * Handle strand broadcast.
   */
  auto broadcastStrands = dynS->configData->broadcastStrands;
  broadcastStrands.insert(broadcastStrands.begin(), dynS->configData);

  for (const auto &sendConfig : broadcastStrands) {

    auto recvStreamElemIdx = convertSendStrandElemIdxToRecvStreamElemIdx(
        sendConfig, sendStrandElemIdx);
    auto recvStrandId =
        recvConfig->getStrandIdFromStreamElemIdx(recvStreamElemIdx);

    auto sendStreamElemIdx =
        sendConfig->getStreamElemIdxFromStrandElemIdx(sendStrandElemIdx);
    auto recvStrandElemIdx =
        recvConfig->getStrandElemIdxFromStreamElemIdx(recvStreamElemIdx);
    LLC_SLICE_DPRINTF(
        sliceId,
        "[LLCFwd] SendStrandElemIdx %lu SendStreamElemIdx %lu R/S %ld/%ld -> "
        "RecvStreamElemIdx %lu RecvStrand %s RecvStrandElemIdx %lu.\n",
        sendStrandElemIdx, sendStreamElemIdx, sendToEdge.reuse, sendToEdge.skip,
        recvStreamElemIdx, recvStrandId, recvStrandElemIdx);

    auto recvElemVAddr = getRecvElemVAddr(recvStreamElemIdx);
    auto recvElemVAddrEnd = recvElemVAddr + recvConfig->elementSize;

    // Check that receiver does not across lines.
    for (auto sendStrandElemIdx = sliceId.getStartIdx() + 1;
         sendStrandElemIdx < sliceId.getEndIdx(); ++sendStrandElemIdx) {

      auto recvStreamElemIdx = convertSendStrandElemIdxToRecvStreamElemIdx(
          sendConfig, sendStrandElemIdx);

      assert(recvStrandId ==
                 recvConfig->getStrandIdFromStreamElemIdx(recvStreamElemIdx) &&
             "Forward to MultiStrand.");

      auto vaddr = getRecvElemVAddr(recvStreamElemIdx);
      auto vaddrEnd = vaddr + recvConfig->elementSize;

      recvElemVAddr = std::min(recvElemVAddr, vaddr);
      recvElemVAddrEnd = std::max(recvElemVAddrEnd, vaddrEnd);
    }

    auto recvElemVAddrLine = ruby::makeLineAddress(recvElemVAddr);
    auto recvElemVAddrEndLine = ruby::makeLineAddress(recvElemVAddr);
    if (recvElemVAddrLine != recvElemVAddrEndLine) {
      LLC_SLICE_PANIC(sliceId, "Multiline StreamForward Receiver: %s.",
                      recvConfig->dynamicId);
    }

    Addr recvElemPAddrLine;
    if (dynS->translateToPAddr(recvElemVAddrLine, recvElemPAddrLine)) {

      /**
       * For now just adjust the sliceId according to the broadcast strand.
       */
      auto sendSliceId = sliceId;
      sendSliceId.getDynStrandId() = sendConfig->getStrandId();

      /**
       * If the RecvS is NonMigrating, we simply send to its initPAddr.
       */
      if (auto recvDynS = LLCDynStream::getLLCStream(recvStrandId)) {
        if (recvDynS->isMigrationDisabled()) {
          recvElemPAddrLine = ruby::makeLineAddress(
              recvDynS->getLLCController()->getAddressToOurLLC());
        }
      }

      // Now we enqueue the translation request.
      auto recvElemMachineType =
          recvConfig->floatPlan.getMachineTypeAtElem(recvStreamElemIdx);
      auto reqIter = this->enqueueRequest(
          dynS->getStaticS(), sendSliceId, recvElemVAddrLine, recvElemPAddrLine,
          recvElemMachineType, ruby::CoherenceRequestType_STREAM_FORWARD);

      // Remember the receiver StrandId and forwarded data block.
      reqIter->forwardToStrandId =
          recvConfig->getStrandIdFromStreamElemIdx(recvStreamElemIdx);
      reqIter->dataBlock = dataBlock;
      reqIter->payloadSize = payloadSize;
    } else {
      LLC_SLICE_PANIC(sliceId, "Fault on RecvS: %s%lu(%lu) VAddr %#x.",
                      recvStrandId, recvStrandElemIdx, recvStreamElemIdx,
                      recvElemVAddrLine);
    }
  }
}

void LLCStreamEngine::issueNonMigrateStreamDataToLLC(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &dataBlock, const ruby::DataBlock &storeValueBlock,
    int payloadSize) {

  LLC_SLICE_DPRINTF(sliceId, "[NoMigrate] Send back to %s.\n",
                    dynS->getLLCController()->getMachineID());

  // Should just send back to the dynS's LLC SE.
  auto recvElemMachineType = ruby::MachineType_L2Cache;
  auto recvElemVAddrLine = ruby::makeLineAddress(sliceId.vaddr);
  auto recvElemPAddrLine =
      ruby::makeLineAddress(dynS->getLLCController()->getAddressToOurLLC());

  auto reqIter = this->enqueueRequest(
      dynS->getStaticS(), sliceId, recvElemVAddrLine, recvElemPAddrLine,
      recvElemMachineType, ruby::CoherenceRequestType_STREAM_FORWARD);

  // Remember the receiver StrandId and forwarded data block.
  reqIter->forwardToStrandId = dynS->getDynStrandId();
  reqIter->dataBlock = dataBlock;
  reqIter->storeValueBlock = storeValueBlock;
  reqIter->payloadSize = payloadSize;
}

void LLCStreamEngine::issueStreamDataToPUM(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &dataBlock,
    const CacheStreamConfigureData::DepEdge &sendToEdge, int payloadSize) {
  /**
   * Unlike sending Data to another Stream, sending Data to PUM usually involves
   * multicasting. We first get the SubRegion for multicast, and then determine
   * the receiving banks and masks.
   */
  auto recvConfig = sendToEdge.data;

  assert(sliceId.getNumElements() == 1 && "Coalesced SendToPUM stream.");
  assert(!dynS->isOneIterationBehind() && "PUMSendTo with OneIterBehind.");

  auto strandElemIdx = sliceId.getStartIdx();
  auto streamElemIdx =
      dynS->configData->getStreamElemIdxFromStrandElemIdx(strandElemIdx);

  auto broadcastPat = sendToEdge.broadcastPat;
  int64_t adjustStart = sendToEdge.recvPat(streamElemIdx);
  LLC_SLICE_DPRINTF(sliceId,
                    "[PUMSendTo] StreamElemIdx %lu BroadcastPat %s RecvPat %s "
                    "AdjustStart %ld.\n",
                    streamElemIdx, broadcastPat, sendToEdge.recvPat,
                    adjustStart);

  broadcastPat.start += adjustStart;

  DataMoveCompiler compiler(StreamNUCAMap::getPUMHWConfig(),
                            sendToEdge.recvTile);

  // Split the broadcast SubRegion into masks.
  AffinePatternVecT bitline_masks;
  AffinePatternVecT tile_masks;
  compiler.generateSubRegionMasks(broadcastPat, bitline_masks, tile_masks);
  if (Debug::LLCStreamPUM) {
    LLC_SLICE_DPRINTF(sliceId, "[PUMSendTo] ---- Get masks Broadcast %s.\n",
                      broadcastPat);
    for (int i = 0; i < bitline_masks.size(); ++i) {
      LLC_SLICE_DPRINTF(sliceId, "  Tile %s Bitline %s.\n", tile_masks[i],
                        bitline_masks[i]);
    }
  }

  // Intersect with each LLC bank.
  std::vector<AffinePatternVecT> llcBankSubRegions =
      compiler.getLLCBankSubRegions();
  auto numLLCBanks = llcBankSubRegions.size();
  LLC_SLICE_DPRINTF(sliceId, "[PUMSendTo] ---- Intersect with LLCSubRegion.\n");
  for (auto maskIdx = 0; maskIdx < bitline_masks.size(); ++maskIdx) {

    ruby::NetDest recvBanks;

    for (auto bankIdx = 0; bankIdx < numLLCBanks; ++bankIdx) {
      bool hasIntersection = false;
      for (const auto &llcSubRegion : llcBankSubRegions.at(bankIdx)) {
        const auto &tileMask = tile_masks[maskIdx];
        auto tileIntersect = AffinePattern::intersectSubRegions(
            compiler.tile_nums, tileMask, llcSubRegion);

        if (tileIntersect.getTotalTrip() == 0) {
          continue;
        }

        LLC_SLICE_DPRINTF(
            sliceId, "Bank %d IntersectTile %s = TileMask %s /\\ LLC %s.\n",
            bankIdx, tileIntersect, tileMask, llcSubRegion);
        hasIntersection = true;
      }

      if (hasIntersection) {
        ruby::MachineID recvMachineId(ruby::MachineType_L2Cache, bankIdx);
        recvBanks.add(recvMachineId);
      }
    }

    assert(recvBanks.count() > 0 && "No RecvBanks.");

    // Construct a packet and send out.
    this->pumEngine->sendPUMDataToLLC(sliceId, recvBanks,
                                      dynS->getMemElementSize());
    for (const auto &dstNodeId : recvBanks.getAllDest()) {
      dynS->sentPUMDataPacketMap.emplace(dstNodeId, 0).first->second++;
    }
    dynS->sentPUMPackets += recvBanks.count();
  }

  /**
   * We need to sync when we reach the end of the current ComputeRound.
   * Since elements are released out-of-order, we need to check:
   * 1. I am the first unreleased element.
   * 2. All elements between myself and the first one of the next round are
   * released.
   */
  auto elem = dynS->getElemPanic(strandElemIdx, "SendToPUM");
  elem->sentToPUM = true;
  assert(dynS->configData->needSyncWithPUMEngine() &&
         "PUMSendTo should always sync.");
  assert(!dynS->idxToElementMap.empty() && "Already no element?");
  if (dynS->idxToElementMap.begin()->first != strandElemIdx) {
    // I am not the first unreleased one yet. Nothing to do.
    return;
  }

  auto waitPUMRound = dynS->configData->waitForPUMRounds(strandElemIdx);
  auto nextRoundStrandElemIdx =
      dynS->configData->getFirstPUMRoundElemIdx(waitPUMRound + 1);
  LLC_SLICE_DPRINTF(sliceId,
                    "[PUMSendTo] WaitRound %ld NextRoundFirstStrandElemIdx %lu "
                    "TotalSentPkts %ld.\n",
                    waitPUMRound, nextRoundStrandElemIdx, dynS->sentPUMPackets);
  bool allElemInCurrentRoundSent = true;
  for (auto elemIdx = strandElemIdx + 1; elemIdx < nextRoundStrandElemIdx;
       ++elemIdx) {
    auto elem = dynS->getElem(elemIdx);
    if (!elem || !elem->sentToPUM) {
      // This is not allocated yet.
      allElemInCurrentRoundSent = false;
      break;
    }
  }
  if (!allElemInCurrentRoundSent) {
    return;
  }

  // We have reached the end of one round.
  LLC_SLICE_DPRINTF(sliceId, "[PUMSendTo] Reached the end of OneRound.\n");
  this->pumEngine->sendSyncToLLCs(dynS->sentPUMDataPacketMap, sliceId);
  auto sentPUMPkts = dynS->sentPUMPackets;
  dynS->sentPUMPackets = 0;
  dynS->sentPUMDataPacketMap.clear();
  this->pumEngine->sendSyncToMLC(sentPUMPkts);
}

void LLCStreamEngine::issuePUMPrefetchStreamDataToLLC(
    LLCDynStreamPtr stream, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &dataBlock) {

  auto vaddr = sliceId.vaddr;
  Addr paddr;
  panic_if(!stream->translateToPAddr(vaddr, paddr),
           "Failed to Translate PUMPrefetchStream.");

  auto paddrLine = ruby::makeLineAddress(paddr);
  auto destLLCBank = this->controller->mapAddressToLLCOrMem(
      paddrLine, ruby::MachineType_L2Cache);

  LLC_SLICE_DPRINTF(sliceId, "[PUMPrefetch] Send PUMPrefetchData to %s.\n",
                    destLLCBank);

  ruby::NetDest recvBanks;
  recvBanks.add(destLLCBank);
  bool isPUMPrefetch = true;
  this->pumEngine->sendPUMDataToLLC(
      sliceId, recvBanks, ruby::RubySystem::getBlockSizeBytes(), isPUMPrefetch);
  for (const auto &dstNodeId : recvBanks.getAllDest()) {
    stream->sentPUMDataPacketMap.emplace(dstNodeId, 0).first->second++;
  }
  stream->sentPUMPackets += recvBanks.count();
}

bool LLCStreamEngine::tryFinishPUMPrefetchStream(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {
  assert(dynS->hasTotalTripCount());

  dynS->doneOnePUMPrefetchSlice();

  auto tc = dynS->getTotalTripCount();

  if (dynS->getPUMPrefetchDoneSlices() >= tc) {
    LLC_SLICE_DPRINTF(sliceId, "PUM prefetch done.\n");
    ruby::MachineID mlcMachineID(ruby::MachineType_L1Cache,
                                 dynS->getDynStreamId().coreId);
    auto mlcCtrl =
        ruby::AbstractStreamAwareController::getController(mlcMachineID);
    auto mlcSE = mlcCtrl->getMLCStreamEngine();

    assert(mlcSE);

    mlcSE->notifyMLCPUMManagerPrefetchDone(dynS->sentPUMPackets);
    return true;
  }
  return false;
}

void LLCStreamEngine::sendLoopBoundRetToMLC(LLCDynStreamPtr stream,
                                            uint64_t elemIdx, bool broken) {
  auto mlcSE = stream->getMLCController()->getMLCStreamEngine();
  assert(mlcSE && "Missing MLC SE.");
  mlcSE->receiveStreamLoopBound(stream->getDynStrandId(), elemIdx, broken);
}

void LLCStreamEngine::findMigratingStreams() {
  // Scan issuing direct streams for migration target.
  auto iter = this->issuingDirStreamList.begin();
  auto end = this->issuingDirStreamList.end();
  while (iter != end) {
    const auto &dynStrandId = *iter;
    auto dynS =
        LLCDynStream::getLLCStreamPanic(dynStrandId, "Find Migrating DynS");
    if (this->canMigrateStream(dynS)) {
      this->migratingStreams.emplace_back(dynS);
      iter = this->removeIssuingDirDynS(iter);
      this->removeDynS(dynS);
    } else {
      ++iter;
    }
  }
}

void LLCStreamEngine::migrateStreams() {
  auto streamIter = this->migratingStreams.begin();
  auto streamEnd = this->migratingStreams.end();
  int migrated = 0;
  /**
   * We limit the number of inqueue migrating streams.
   */
  while (streamIter != streamEnd && migrated < this->migrateWidth &&
         this->streamMigrateMsgBuffer->getSize(curTick()) < 2) {
    auto dynS = *streamIter;

    /**
     * The only special case is if the stream is broken out.
     * So far we don't migrate it, and add it back to StreamList
     * so that it can be correctly terminated by StreamEnd.
     */
    if (dynS->isLoopBoundBrokenOut()) {
      streamIter = this->migratingStreams.erase(streamIter);
      this->streams.push_back(dynS);
      continue;
    }

    assert(this->canMigrateStream(dynS) && "Can't migrate.");
    /**
     * Check the migrate controller.
     */
    auto nextVAddrAndMachineType = dynS->peekNextAllocVAddrAndMachineType();
    auto nextVAddr = nextVAddrAndMachineType.first;
    auto nextMachineType = nextVAddrAndMachineType.second;
    Addr nextPAddr;
    if (!dynS->translateToPAddr(nextVAddr, nextPAddr)) {
      LLC_S_PANIC(dynS->getDynStrandId(), "Fault on migrating dynS.");
    }
    auto nextMachineId = this->controller->mapAddressToLLCOrMem(
        ruby::makeLineAddress(nextPAddr), nextMachineType);
    if (!this->migrateController->canMigrateTo(dynS, nextMachineId)) {
      ++streamIter;
      continue;
    }
    this->migrateStream(dynS);
    this->migrateController->startMigrateTo(dynS, nextMachineId);
    streamIter = this->migratingStreams.erase(streamIter);
    migrated++;
  }
  if (this->streams.empty() && this->migratingStreams.empty()) {
    this->seTracer.write();
  }
}

void LLCStreamEngine::migrateStream(LLCDynStream *stream) {

  // Create the migrate request.
  auto vaddrAndMachineType = stream->peekNextAllocVAddrAndMachineType();
  Addr vaddr = vaddrAndMachineType.first;
  auto machineType = vaddrAndMachineType.second;
  Addr paddr;
  panic_if(!stream->translateToPAddr(vaddr, paddr),
           "Migrating streams should have valid paddr.");
  Addr paddrLine = ruby::makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddrLine, machineType);

  LLC_S_DPRINTF(stream->getDynStrandId(),
                "Migrate to %s, InflyReq %d AdvancedMigrate %d IndirectS "
                "%d. Remain DirectStreams %llu.\n",
                addrMachineId, stream->inflyRequests,
                this->controller->isStreamAdvanceMigrateEnabled(),
                stream->getIndStreams().size(), this->streams.size());

  auto msg = std::make_shared<ruby::StreamMigrateRequestMsg>(
      this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = ruby::CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  msg->m_MessageSize = ruby::MessageSizeType_Data;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  this->removeStreamFromMulticastTable(stream);

  auto addrCtrl =
      ruby::AbstractStreamAwareController::getController(addrMachineId);
  stream->migratingStart(addrCtrl);
}

void LLCStreamEngine::migrateStreamCommit(LLCDynStream *stream, Addr paddr,
                                          ruby::MachineType machineType) {
  // Create the migrate request.
  Addr paddrLine = ruby::makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddrLine, machineType);

  LLC_S_DPRINTF_(StreamRangeSync, stream->getDynStrandId(),
                 "[Commit] Migrate to LLC%d.\n", addrMachineId.num);

  auto msg = std::make_shared<ruby::StreamMigrateRequestMsg>(
      this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = ruby::CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  // Migrating CommitHead is just a control message.
  msg->m_MessageSize = ruby::MessageSizeType_Control;
  msg->m_IsCommit = true;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));
}

ruby::MachineID LLCStreamEngine::mapPaddrToSameLevelBank(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddr, selfMachineId.type);
  return addrMachineId;
}

bool LLCStreamEngine::isPAddrHandledByMe(Addr paddr,
                                         ruby::MachineType machineType) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddr, machineType);
  return addrMachineId == selfMachineId;
}

void LLCStreamEngine::print(std::ostream &out) const {}

void LLCStreamEngine::resetStats() { this->seTracer.reset(); }

void LLCStreamEngine::receiveStreamIndirectReq(const ruby::RequestMsg &req) {

  /**
   * After supporting broadcast strands, it's possible that even the first req
   * is not mapped here. Check the paddr.
   */
  if (req.getType() == ruby::CoherenceRequestType_STREAM_FORWARD) {
    if (this->isPAddrHandledByMe(req.getaddr(), this->myMachineType())) {
      this->receiveStreamIndirectReqImpl(req);
    }
  } else {
    this->receiveStreamIndirectReqImpl(req);
  }

  /**
   * Unchain each indirect requests and call receiveStreamIndirectReqImpl().
   */
  auto chainMsg = req.getChainMsg();
  while (chainMsg) {

    auto chainReq = std::dynamic_pointer_cast<ruby::RequestMsg>(chainMsg);
    assert(chainReq && "Should be RequsetMsg.");

    const auto &chainSliceId = chainReq->m_sliceIds.singleSliceId();
    const auto &chainReqNetDest = chainReq->getDestination();
    if (chainReqNetDest.count() != 1) {
      LLC_SLICE_PANIC(chainSliceId, "[Multicast] ChainReq Invalid Dest %s.",
                      chainReqNetDest);
    }

    auto chainReqDest = chainReqNetDest.singleElement();
    if (chainReqDest == this->controller->getMachineID()) {
      /**
       * This is for us. We recursively call receiveStreamIndirectReq.
       */
      LLC_SLICE_DPRINTF_(
          LLCRubyStreamMulticast, chainSliceId,
          "[Multicast] Unchain [indirect] %s to %s PaddrLine %#x.\n",
          chainReq->m_Type, chainReqDest, chainReq->m_addr);

      // Record the Mulitcast.
      if (auto dynS = LLCDynStream::getLLCStream(
              chainSliceId.getDynStrandId().getFirstStrandId())) {
        auto &statistic = dynS->getStaticS()->statistic;
        statistic.numRemoteMulticastSlice++;
      }

      this->receiveStreamIndirectReqImpl(*chainReq);
    } else {
      /**
       * Skip this ChainReq and go to the next one.
       */
      LLC_SLICE_DPRINTF_(
          LLCRubyStreamMulticast, chainSliceId,
          "[Multicast] Ignore [indirect] %s ChainReq to %s PaddrLine %#x.\n",
          chainReq->m_Type, chainReqDest, chainReq->m_addr);
    }
    chainMsg = chainReq->getChainMsg();
  }
}

void LLCStreamEngine::receiveStreamIndirectReqImpl(
    const ruby::RequestMsg &req) {

  this->initializeTranslationBuffer();

  // Simply copy and inject the msg to L1 request in.
  const auto &sliceId = req.m_sliceIds.singleSliceId();
  assert(sliceId.isValid() && "Invalid stream slice for indirect request.");

  auto networkLatency =
      this->curCycle() - this->controller->ticksToCycles(req.getTime());
  LLC_SLICE_DPRINTF(sliceId, "Recv [ind] %s req paddrLine %#x NoC delay %s.\n",
                    ruby::CoherenceRequestType_to_string(req.m_Type),
                    req.m_addr, networkLatency);

  if (req.m_Type == ruby::CoherenceRequestType_STREAM_FORWARD) {
    // Quick path for stream forwarding.
    this->receiveStreamFwdReq(req);
    return;
  }

  if (this->tryToProcessIndirectAtomicUnlockReq(req)) {
    // Quick path for the second request to release an indirect
    // atomic.
    return;
  }

  // Record the NoC latency for the indirect request.
  // Search through all streams.
  if (auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId())) {
    auto &statistic = dynS->getStaticS()->statistic;
    statistic.remoteIndReqNoCDelay.sample(networkLatency);
    statistic.getStaticStat().remoteIndReqNoCDelay.sample(networkLatency);
  }

  auto msg = std::make_shared<ruby::RequestMsg>(req);
  Cycles latency(1);
  this->streamIssueMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                      this->controller->cyclesToTicks(latency));
  this->traceEvent(::LLVM::TDG::StreamFloatEvent::LOCAL_REQ_START);
}

void LLCStreamEngine::receivePUMConfigure(const ruby::RequestMsg &req) {
  this->pumEngine->receiveKick(req);
}

void LLCStreamEngine::receivePUMData(const ruby::RequestMsg &req) {
  this->pumEngine->receiveData(req);
}

void LLCStreamEngine::receiveStreamFwdReq(const ruby::RequestMsg &req) {
  this->processStreamFwdReq(req);
}

void LLCStreamEngine::processStreamFwdReq(const ruby::RequestMsg &req) {

  const auto &sliceId = req.m_sliceIds.singleSliceId();
  const auto &recvDynId = req.m_sendToStrandId;
  // Search through the direct streams.
  auto dynS = LLCDynStream::getLLCStream(recvDynId);
  if (!dynS) {
    // Failed to find the stream (may be terminated). Try NDC.
    this->ndcController->receiveStreamForwardRequest(req);
    LLC_SLICE_DPRINTF(sliceId, "Cannot find the direct receiver: %s.\n",
                      recvDynId);
    return;
  }
  /**
   * Sample the LLC forward latency.
   */
  auto sendCycle = this->controller->ticksToCycles(req.getTime());
  auto latency = this->curCycle() - sendCycle;
  LLC_SLICE_DPRINTF(sliceId, "[Fwd] Received by %s. Latency %llu.\n", recvDynId,
                    latency);
  if (auto sender = LLCDynStream::getLLCStream(sliceId.getDynStrandId())) {
    sender->getStaticS()->statistic.remoteForwardNoCDelay.sample(latency);
  }

  /**
   * Normally we search for the receiver in myself and my indirect
   * stream. However, there is a special case: I am the sender! This
   * is used so far to implement IndirectReductionS that dependent
   * both on the BackBaseIndirectS and BackBaseDirectS:
   *
   * BaseBaseDirectS -> BackBaseIndirectS -> IndirectReductionS.
   *  |                                              |
   *  ----------------------->>>---------------------
   *
   * In such case, we only search in my Two-Level IndirectS...
   *
   * NOTE: Now with NonMigrate stream, I can be the sender and receiver
   * at the same time. In such case, we have to call receiveStreamData().
   */
  bool foundReceiver = false;
  if (sliceId.getDynStreamId() != dynS->getDynStreamId()) {
    // Search for receiver in myself and my indirect streams.
    if (dynS->isBasedOn(sliceId.getDynStreamId())) {
      foundReceiver = true;
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        dynS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
      }
    }

    for (auto dynIS : dynS->getAllIndStreams()) {
      if (dynIS->isBasedOn(sliceId.getDynStreamId())) {
        foundReceiver = true;
        for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
             ++idx) {
          dynIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
        }
      }
    }
  } else {
    /**
     * Sender is myself.
     * 1. If I am the receiver, this is a non-migrate stream response.
     * 2. Otherwise, search for Two-Level Indirection.
     * TODO: Correctly distinguish these two cases.
     */
    if (dynS->isMigrationDisabled()) {

      foundReceiver = true;
      // We need to reconstruct the PAddrLine from SliceId.Vaddr.
      auto vaddrLine = ruby::makeLineAddress(sliceId.vaddr);
      Addr paddrLine;
      panic_if(!dynS->translateToPAddr(vaddrLine, paddrLine),
               "Failed translating addr.");

      this->receiveStreamData(paddrLine, sliceId, req.m_DataBlk,
                              req.m_streamStoreBlk);
    }
    for (auto dynIS : dynS->getIndStreams()) {
      for (auto dynIIS : dynIS->getIndStreams()) {
        if (dynIIS->isBasedOn(sliceId.getDynStreamId())) {
          foundReceiver = true;
          for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
               ++idx) {
            dynIIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
          }
        }
      }
    }
  }
  if (!foundReceiver) {
    LLC_SLICE_PANIC(sliceId, "Cannot find the receiver: %s.", recvDynId);
  }
}

bool LLCStreamEngine::tryToProcessIndirectAtomicUnlockReq(
    const ruby::RequestMsg &req) {
  if (req.m_Type != ruby::CoherenceRequestType_STREAM_UNLOCK) {
    // Not single slice id or store request.
    return false;
  }

  /**
   * This is the second request to unlock the line of indirect
   * atomic. We just send back the Ack.
   */
  if (req.m_sliceIds.sliceIds.size() != 1) {
    LLC_SLICE_PANIC(req.m_sliceIds.firstSliceId(),
                    "[Commit] Multi-Slice for IndirectAtomicUnlock.");
  }

  const auto &sliceId = req.m_sliceIds.singleSliceId();
  auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
  if (!dynS) {
    // Failed to find the DynStream.
    LLC_SLICE_PANIC(
        sliceId, "[Commit] Failed to find LLCDynS for IndirectAtomicUnlock.");
  }
  auto S = dynS->getStaticS();
  if (!(S->isAtomicComputeStream() && dynS->isIndirect() &&
        dynS->shouldIssueBeforeCommit() && dynS->shouldIssueAfterCommit())) {
    LLC_SLICE_PANIC(sliceId, "[Commit] Not IndirectAtomicStream with Unlock.");
  }
  auto elemIdx = sliceId.getStartIdx();
  assert(sliceId.getNumElements() == 1 &&
         "Multi-Element slice for IndirectAtomicStream.");
  auto elem = dynS->getElemPanic(elemIdx, "IndirectAtomicUnlock");
  if (!elem->hasFirstIndirectAtomicReqSeen()) {
    LLC_SLICE_PANIC(sliceId, "[Commit] Has not seen FirstIndirectAtomicReq.");
  }
  // Update inflyRequests.
  if (dynS->inflyRequests == 0) {
    LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
  }
  dynS->inflyRequests--;

  LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                     "[Commit] Atomic released. Remaining Elements %llu.\n",
                     dynS->idxToElementMap.size());
  Addr elemPAddr;
  panic_if(!dynS->translateToPAddr(elem->vaddr, elemPAddr),
           "Fault on vaddr of LLCStore/Atomic/UpdateStream.");
  auto elemMemSize = dynS->getMemElementSize();
  if (this->controller->isStreamAtomicLockEnabled()) {
    /**
     * For now we just delay the Ack until the line is unlocked.
     */
    this->atomicLockManager->commit(elemPAddr, elemMemSize, elem,
                                    true /* shouldAckAfterUnlock */, sliceId);
  } else {
    /**
     * Ideal case: Immediately send back Ack.
     */
    this->atomicLockManager->commit(elemPAddr, elemMemSize, elem,
                                    false /* shouldAckAfterUnlock */, sliceId);
    this->issueStreamAckToMLC(sliceId);
  }

  /**
   * No matter what, we should release elements that are
   * unlocked.
   */
  elem->setSecondIndirectAtomicReqSeen();
  while (!dynS->idxToElementMap.empty()) {
    auto elemIter = dynS->idxToElementMap.begin();
    const auto &elem = elemIter->second;
    if (!elem->isReady() || !elem->areBaseElemsReady() ||
        !elem->hasSecondIndirectAtomicReqSeen()) {
      break;
    }
    dynS->eraseElem(elemIter);
  }
  return true;
}

void LLCStreamEngine::predicateOffElem(LLCDynStreamPtr dynS,
                                       LLCStreamElementPtr elem) {
  LLC_SE_ELEM_DPRINTF_(LLCStreamPredicate, elem, "[LLCPred] Predicated Off.\n");

  /**
   * Some sanity check cause so far we only have partial support for
   * predication.
   */
  if (dynS->shouldRangeSync()) {
    LLC_ELEMENT_PANIC(elem, "PredOff RangeSync.");
  }
  if (dynS->shouldSendValueToCore()) {
    LLC_ELEMENT_PANIC(elem, "PredOff CoreNeedValue.");
  }
  if (!dynS->isIndirect()) {
    LLC_ELEMENT_PANIC(elem, "PredOff DirectS not implemented yet.");
  }
  if (dynS->getNextIssueElemIdx() > elem->idx) {
    LLC_ELEMENT_PANIC(elem, "PredOff but Issued %llu.",
                      dynS->getNextIssueElemIdx());
  }
  for (const auto &edge : dynS->configData->depEdges) {
    if (edge.type != CacheStreamConfigureData::DepEdge::Type::UsedBy) {
      LLC_ELEMENT_PANIC(elem, "PredOff with NonUsedBy DepEdge.");
    }
  }
  auto S = dynS->getStaticS();
  if (S->isStoreComputeStream() || S->isAtomicComputeStream()) {
    // Need to send back a fake ack using a single slice for this elem.
    DynStreamSliceId elemSliceId;
    elemSliceId.getDynStrandId() = dynS->getDynStrandId();
    elemSliceId.getStartIdx() = elem->idx;
    elemSliceId.getEndIdx() = elem->idx + 1;
    this->issueStreamAckToMLC(elemSliceId);
    if (dynS->isIndirect() && S->isStoreComputeStream()) {
      elem->setIndirectStoreAcked();
    }
  }
  elem->setStateToPredicatedOff();
  // Predicate all indirect element.
  for (const auto &IS : dynS->getIndStreams()) {
    auto indElem = IS->getElemPanic(elem->idx, "PredOff IndElem.");
    this->predicateOffElem(IS, indElem);
  }
  // Help keep NextIssueElemIdx correct.
  dynS->skipIssuingPredOffElems();
  // If the IndS has ready elem, add it back to IssueList.
  if (dynS->isIndirect() && dynS->hasElemReadyToIssue()) {
    LLC_SE_ELEM_DPRINTF(elem,
                        "[IndS] PredOff but add to Issue List ReadyElems %d.\n",
                        dynS->getNumElemReadyToIssue());
    this->addIssuingIndDynS(dynS);
  }
  // Try release the element in order.
  while (!dynS->idxToElementMap.empty()) {
    auto elemIter = dynS->idxToElementMap.begin();
    const auto &elem = elemIter->second;
    if (dynS->isIndirect() && S->isStoreComputeStream()) {
      if (!elem->isIndirectStoreAcked()) {
        LLC_SE_ELEM_DPRINTF(elem, "[LLCPred] Not Release: !IndStoreAck.\n");
        break;
      }
    } else {
      if (!elem->isPredicatedOff()) {
        LLC_SE_ELEM_DPRINTF(elem, "[LLCPred] Not Release: !PredOff.\n");
        break;
      }
    }
    dynS->eraseElem(elemIter);
  }
}

void LLCStreamEngine::triggerIndElem(LLCDynStreamPtr IS, uint64_t indElemIdx) {

  if (IS->hasTotalTripCount() && indElemIdx > IS->getTotalTripCount()) {
    // Ignore overflow elements.
    LLC_S_DPRINTF(IS->getDynStrandId(),
                  "[TriggerInd] Skip TripCount %ld < ElemIdx %lu.\n",
                  IS->getTotalTripCount(), indElemIdx);
    return;
  }

  /**
   * We should have the indirect element. The only exception is the vectorized
   * reduction stream.
   */
  if (!IS->idxToElementMap.count(indElemIdx)) {

    if (IS->getStaticS()->isReduction() &&
        IS->lastReducedElemIdx >= indElemIdx) {
      LLC_S_DPRINTF(
          IS->getDynStrandId(),
          "[TriggerInd] Skip ReduceS LastComputedElemIdx %lu > %lu.\n",
          IS->lastReducedElemIdx, indElemIdx);
      return;
    }

    LLC_S_PANIC(IS->getDynStrandId(), "Missing IndElem %llu.", indElemIdx);
  }

  auto &indElem = IS->idxToElementMap.at(indElemIdx);

  // Not predicated, add to readyElements.
  bool areBaseElemsReady = indElem->areBaseElemsReady();
  LLC_SE_ELEM_DPRINTF(indElem, "Check if BaseElemReady %d.\n",
                      areBaseElemsReady);
  if (!areBaseElemsReady) {
    for (const auto &baseE : indElem->baseElements) {
      LLC_SE_ELEM_DPRINTF(indElem, "BaseElems Ready %d %s%llu.\n",
                          baseE->isReady(), baseE->strandId, baseE->idx);
    }
    return;
  }

  /**
   * Check if the stream has predication.
   */
  if (IS->isPredicated()) {
    // The PredBaseElem should be in our base elem.
    bool predOn = false;
    for (const auto &baseElem : indElem->baseElements) {
      if (baseElem->strandId.dynStreamId != IS->getPredBaseStreamId()) {
        continue;
      }
      if (!baseElem->isPredValueReady()) {
        LLC_ELEMENT_PANIC(indElem, "[LLCPred] PredValue not ready: %s%lu.",
                          baseElem->strandId, baseElem->idx);
      }
      auto predValue = baseElem->getPredValue(IS->getPredId());
      LLC_SE_ELEM_DPRINTF_(LLCStreamPredicate, indElem,
                           "[LLCPred] Got Id %d = Value %d Expected %d.\n",
                           IS->getPredId(), predValue, IS->getPredValue());
      predOn = (predValue == IS->getPredValue());
      break;
    }
    if (!predOn) {
      this->predicateOffElem(IS, indElem);
      return;
    }
  }

  // BaseElems ready and not predicated off.
  if (IS->getStaticS()->isReduction() ||
      IS->getStaticS()->isPointerChaseIndVar()) {
    if (indElem->isComputationScheduled() || indElem->isComputationDone()) {
    } else {
      // Reduction now is handled as computation.
      this->pushReadyComputation(indElem);
    }
  } else {
    IS->markElemReadyToIssue(indElemIdx);
    LLC_S_DPRINTF(IS->getDynStrandId(), "[IndS] Add to Issue List Elem %lu.\n",
                  indElemIdx);
    this->addIssuingIndDynS(IS);
    indElem->setLLCSE(this);
  }
}

void LLCStreamEngine::triggerIndElems(LLCDynStreamPtr dynS,
                                      LLCStreamElementPtr elem) {
  if (dynS->getIndStreams().empty()) {
    // There is no stream dependent on my data.
    return;
  }

  auto idx = elem->idx;
  assert(elem->isReady());

  /**
   * Here we try to trigger all IndElements even if they are multi-level
   * dependence. This is to handle a corner case in pointnet2 furthest sample:
   * DirS -> ReduceS1 -> ReduceS2.
   * The Elem 1 of ReduceS2 is never triggered as Elem 0 of ReduceS1 is already
   * ready. It would be triggered by Elem 0 of DirS.
   */
  for (auto IS : dynS->getAllIndStreams()) {
    auto reuse = IS->baseStreamReuse;

    /**
     * Two possible cases (can only be one of them).
     *
     * If the indirect stream is behind one iteration, base element
     * of iteration i should trigger the indirect element of
     * iteration i + 1.
     *
     * If the IndS has reuse > 1, then we need to trigger multiple IndElems.
     */
    if (reuse > 1 && IS->isOneIterationBehind()) {
      LLC_S_PANIC(IS, "IndReuse %d > 1 && OneIterBehind.", reuse);
    }

    auto skip = 0;
    auto indElemIdxLhs =
        IS->configData->convertBaseToDepElemIdx(idx, reuse, skip);
    auto indElemIdxRhs =
        IS->configData->convertBaseToDepElemIdx(idx + 1, reuse, skip);

    LLC_SE_ELEM_DPRINTF(elem, "Trigger IndS %s Reuse %d Elems [%lu, %lu).\n",
                        IS->getDynStrandId(), reuse, indElemIdxLhs,
                        indElemIdxRhs);

    for (auto indElemIdx = indElemIdxLhs; indElemIdx < indElemIdxRhs;
         ++indElemIdx) {
      if (IS->isOneIterationBehind()) {
        indElemIdx = idx + 1;
      }
      this->triggerIndElem(IS, indElemIdx);
    }
  }
}

void LLCStreamEngine::triggerUpdate(LLCDynStreamPtr dynS,
                                    LLCStreamElementPtr elem,
                                    const DynStreamSliceId &sliceId,
                                    const ruby::DataBlock &storeValueBlock,
                                    ruby::DataBlock &loadValueBlock,
                                    uint32_t &payloadSize) {

  auto S = dynS->getStaticS();

  // Perform the operation.
  auto elemMemSize = S->getMemElementSize();
  auto elemVAddr = elem->vaddr;

  Addr elemPAddr;
  panic_if(!dynS->translateToPAddr(elemVAddr, elemPAddr),
           "Fault on vaddr of UpdateStream.");
  const auto lineSize = ruby::RubySystem::getBlockSizeBytes();

  /**
   * This is an update stream, and we have to handle multi-line
   * elements.
   * 1. Compute the store value if this is the first time, and
   * directly stores all the result.
   * 2. Send back the overlapped old value.
   * TODO: Really schedule the computation to model the latency.
   * TODO: Reload the value here to avoid aliased update stream.
   * TODO: Multi-Line Update should really be careful.
   */
  if (!elem->isComputedValueReady()) {
    auto getStreamValue = [&elem](uint64_t streamId) -> StreamValue {
      return elem->getBaseOrMyStreamValue(streamId);
    };
    auto params = convertFormalParamToParam(dynS->configData->storeFormalParams,
                                            getStreamValue);
    auto storeValue = dynS->configData->storeCallback->invoke(params);

    /**
     * ! For now just record the stats.
     */
    auto numMicroOps = S->getComputationNumMicroOps();
    // For now we don't bother add the stats to the core in my bank.
    S->recordComputationInCoreStats();
    this->controller->m_statLLCScheduledComputation++;
    this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
    this->recordComputationMicroOps(S);

    elem->setComputedValue(storeValue);
    assert(elemMemSize <= sizeof(storeValue) && "UpdateStream size overflow.");
    for (int storedSize = 0; storedSize < elemMemSize;) {
      Addr vaddr = elemVAddr + storedSize;
      Addr paddr;
      if (!dynS->translateToPAddr(vaddr, paddr)) {
        LLC_ELEMENT_PANIC(elem, "Fault on vaddr of UpdateStream.");
      }
      auto lineOffset = vaddr % lineSize;
      auto size = elemMemSize - storedSize;
      if (lineOffset + size > lineSize) {
        size = lineSize - lineOffset;
      }
      this->performStore(paddr, size, storeValue.uint8Ptr(storedSize));
      storedSize += size;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamUpdate done with value %s.\n", storeValue);
  }

  /**
   * Send back the overlap value within this line.
   */
  Addr loadBlockVAddrLine = ruby::makeLineAddress(sliceId.vaddr);
  int elementOffset = 0;
  int loadBlockOffset = 0;
  auto overlapSize = elem->computeOverlap(loadBlockVAddrLine, lineSize,
                                          loadBlockOffset, elementOffset);
  loadValueBlock.setData(elem->getUInt8Ptr(elementOffset), loadBlockOffset,
                         overlapSize);
  payloadSize = overlapSize;
}

void LLCStreamEngine::triggerAtomic(LLCDynStreamPtr dynS,
                                    LLCStreamElementPtr elem,
                                    const DynStreamSliceId &sliceId,
                                    ruby::DataBlock *loadValueBlock,
                                    uint32_t &payloadSize) {

  auto S = dynS->getStaticS();

  // Perform the operation.
  auto elemMemSize = S->getMemElementSize();
  auto elemCoreSize = S->getCoreElementSize();
  auto elemVAddr = elem->vaddr;

  // Create a single slice for this element.
  DynStreamSliceId elemSliceId;
  elemSliceId.getDynStrandId() = dynS->getDynStrandId();
  elemSliceId.getStartIdx() = elem->idx;
  elemSliceId.getEndIdx() = elem->idx + 1;

  Addr elemPAddr;
  panic_if(!dynS->translateToPAddr(elemVAddr, elemPAddr),
           "Fault on vaddr of AtomicS.");
  auto lineOffset = elemVAddr % ruby::RubySystem::getBlockSizeBytes();
  if (lineOffset + elemMemSize > ruby::RubySystem::getBlockSizeBytes()) {
    LLC_ELEMENT_PANIC(elem, "Multi-Line AtomicElem.");
  }

  // Very limited AtomicRMW support.
  auto atomicRet =
      this->performStreamAtomicOp(dynS, elem, elemPAddr, elemSliceId);
  auto loadedValue = atomicRet.first;
  bool memoryModified = atomicRet.second;
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Perform StreamAtomic, RetVal %llu.\n", loadedValue);
  if (loadValueBlock) {
    // Currently we do not support return AtomicVal to core if it spans across
    // multiple line. This can be relaxed in the future.
    if (lineOffset + elemCoreSize > ruby::RubySystem::getBlockSizeBytes()) {
      LLC_ELEMENT_PANIC(elem, "Multi-Line AtomicElem for Core.");
    }
    loadValueBlock->setData(reinterpret_cast<uint8_t *>(&loadedValue),
                            lineOffset, elemCoreSize);
  }
  payloadSize = elemCoreSize;

  /**
   * At this point the value of AtomicS is ready, we have to:
   * 1. Set the element value.
   * 2. Evaluate predication.
   * 3. Trigger indirect elements.
   */
  elem->setValue(loadedValue);
  dynS->evaluatePredication(this, elem->idx);
  this->triggerIndElems(dynS, elem);

  if (elem->hasFirstIndirectAtomicReqSeen()) {
    LLC_ELEMENT_PANIC(elem, "Perform atomic operation more than once.");
  }
  elem->setFirstIndirectAtomicReqSeen();
  this->atomicLockManager->enqueue(elemPAddr, elemMemSize, elem,
                                   memoryModified);
  if (!(dynS->shouldIssueBeforeCommit() && dynS->shouldIssueAfterCommit())) {
    // This AtomicStream just takes one request, we can immediately
    // commit it.
    this->atomicLockManager->commit(elemPAddr, elemMemSize, elem);
  }
}

LLCStreamSlicePtr LLCStreamEngine::allocateSlice(LLCDynStreamPtr dynS) {
  auto slice = dynS->allocNextSlice(this);
  this->allocatedSlices.push_back(slice);
  return slice;
}

LLCStreamSlicePtr
LLCStreamEngine::tryGetSlice(const DynStreamSliceId &sliceId) {
  for (auto &slice : this->allocatedSlices) {
    const auto &id = slice->getSliceId();
    /**
     * We have additional check for the vaddr in case for multi-line
     * elements.
     */
    if (id == sliceId && id.vaddr == sliceId.vaddr) {
      return slice;
    }
  }
  return nullptr;
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::tryGetSliceIter(const DynStreamSliceId &sliceId) {

  auto iter = this->allocatedSlices.begin();
  for (; iter != this->allocatedSlices.end(); ++iter) {
    const auto &slice = *iter;
    const auto &id = slice->getSliceId();
    /**
     * We have additional check for the vaddr in case for multi-line
     * elements.
     */
    if (id == sliceId && id.vaddr == sliceId.vaddr) {
      break;
    }
  }
  return iter;
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::releaseSlice(SliceList::iterator sliceIter) {
  const auto &slice = *sliceIter;
  LLC_SLICE_DPRINTF(slice->getSliceId(), "Released.\n");
  slice->released();
  const auto &sliceId = slice->getSliceId();
  if (auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId())) {
    while (!dynS->idxToElementMap.empty()) {
      auto elemIter = dynS->idxToElementMap.begin();
      auto &elem = elemIter->second;
      // StoreComputeStream is never ready.
      if ((elem->isReady() || dynS->getStaticS()->isStoreComputeStream()) &&
          elem->areSlicesReleased()) {
        if (!elem->areBaseElemsReady()) {
          LLC_ELEMENT_PANIC(
              elem, "Released when Ready %d ValueBaseReady %d Slices %d.",
              elem->isReady(), elem->areBaseElemsReady(), elem->getNumSlices());
        }
        /**
         * We avoid releasing the element if it is the only two left
         * in idxToElementMap and it is known not the last one. This
         * is to avoid a bug when there are multi-line elements, the
         * next slice is not initialized yet, thus the element has
         * not seen all the slices and may falsely return true for
         * areSlicesReleased().
         * TODO: Handle this multi-line elements more elegantly.
         * TODO: I don't think this applies to IndS.
         */
        if (dynS->isIndirect() || dynS->idxToElementMap.size() > 2 ||
            (dynS->hasTotalTripCount() &&
             elem->idx + 2 >= dynS->getTotalTripCount())) {
          dynS->eraseElem(elemIter);
          continue;
        }
      }
      if (elem->isPredicatedOff()) {
        dynS->eraseElem(elemIter);
        continue;
      }
      break;
    }
  }
  return this->allocatedSlices.erase(sliceIter);
}

void LLCStreamEngine::processSlices() {
  auto iter = this->allocatedSlices.begin();
  auto end = this->allocatedSlices.end();
  while (iter != end) {
    iter = this->processSlice(iter);
  }
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::processSlice(SliceList::iterator sliceIter) {
  auto &slice = *sliceIter;
  auto dynS = LLCDynStream::getLLCStream(slice->getSliceId().getDynStrandId());
  if (!dynS) {
    // Jesus, the LLCStream is already released.
    switch (slice->getState()) {
    default:
      LLC_SLICE_PANIC(slice->getSliceId(),
                      "LLCStream released, but slice not.");
    case LLCStreamSlice::State::ALLOCATED:
    case LLCStreamSlice::State::RESPONDED:
    case LLCStreamSlice::State::FAULTED:
      return this->releaseSlice(sliceIter);
    case LLCStreamSlice::State::ISSUED:
      // We are still waiting for the response.
      return ++sliceIter;
    }
  }
  switch (slice->getState()) {
  default:
    LLC_SLICE_PANIC(slice->getSliceId(), "Invalid state.");
  case LLCStreamSlice::State::ALLOCATED:
  case LLCStreamSlice::State::ISSUED:
    // We are still waiting for the response.
    return ++sliceIter;
  case LLCStreamSlice::State::FAULTED:
    return this->releaseSlice(sliceIter);
  case LLCStreamSlice::State::RESPONDED:
    break;
  }
  /**
   * The slice is already responded, see if we can process it.
   * So far we need to process the slice for these cases:
   * 1. AtomicComputeStream/UpdateStream.
   * This is where the write request is generated, and is done after
   * all elements are committed in the core (if RangeSync enabled).
   * 2. LoadComputeStream.
   * This is where we schedule the computation for LoadComputeStream,
   * and send back the result to core if core needs the value. This
   * does not need to wait for commitment.
   * 3. We also need to evaluate the LoopBound, specially when the slice
   * contains multiple elements.
   */

  const auto &sliceId = slice->getSliceId();
  auto S = dynS->getStaticS();
  /**
   * Check the LoopBound before we release the slice.
   */
  if (!dynS->isSliceDoneForLoopBound(sliceId)) {
    // We still need this. Check if we should try to evaluate LoopBound.
    for (auto elemIdx = sliceId.getStartIdx(); elemIdx < sliceId.getEndIdx();
         ++elemIdx) {
      auto elem = dynS->getElemPanic(elemIdx, "Check elem for LoopBound.");
      if (elem->isLoopBoundDone()) {
        continue;
      }
      // This slice contains the last element byte.
      assert(elem->isReady() && "Elem should be ready for LoopBound.");
      dynS->evaluateLoopBound(this, elemIdx);
      assert(elem->isLoopBoundDone() && "LoopBound should make progress.");
    }
    return ++sliceIter;
  }
  /**
   * For LoadComputeStream, we schedule computation if the element is
   * value ready. If all element's LoadComputeValue is ready, we send
   * back to core. Also, we have to wait until the LoadComputeValue
   * sent back to core before releasing the slice.
   */
  if (S->isLoadComputeStream()) {
    if (slice->isLoadComputeValueSent()) {
      // We have computed and sent this slice. See if we can release it.
    } else {
      this->processLoadComputeSlice(dynS, slice);
      if (!slice->isLoadComputeValueSent()) {
        // We are not done with it. Move to next one.
        return ++sliceIter;
      }
    }
  }
  /**
   * If this stream require RangeSync, we have to check that all
   * elements are committed in the core. One exception is for
   * IndirectLoadComputeStream, which we should release immediately.
   */
  if (dynS->shouldRangeSync() &&
      !(S->isLoadComputeStream() && dynS->isIndirect())) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElemPanic(idx, "Check element committed for update.");
      if (!element->hasCoreCommitted()) {
        // We are still waiting for the core to commit.
        return ++sliceIter;
      }
    }
  }
  if (S->isAtomicComputeStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElemPanic(idx, "Check base elements ready for update.");
      // LLC_SLICE_DPRINTF(
      //     sliceId, "Process for element %llu, Ready %d, BaseReady
      //     %d.\n", element->idx, element->isReady(),
      //     element->areBaseElementsReady());
      if (!element->areBaseElemsReady()) {
        // We are still waiting for base elements.
        return ++sliceIter;
      }
      /**
       * Update slice also require the element to be ready.
       * Although this has responded, a multi-slice element may still
       * not be ready.
       */
      if (S->isUpdateStream() && !element->isReady()) {
        LLC_SE_ELEM_DPRINTF(element, "[Update] Slice blocked by me.\n");
        return ++sliceIter;
      }
    }
    // We can finally process it.
    this->processDirectAtomicSlice(dynS, sliceId);

  } else if (S->isUpdateStream()) {
    /**
     * DirectUpdateStream requires special handling now.
     * 1. If processed -- check if we can post-process it.
     * 2. Otherwise, process it and then wait for the computation done.
     */
    if (slice->isProcessed()) {
      if (!this->tryPostProcessDirectUpdateSlice(dynS, slice)) {
        return ++sliceIter;
      } else {
        // Fall through to be finally released.
      }
    } else {
      this->tryProcessDirectUpdateSlice(dynS, slice);
      return ++sliceIter;
    }
  }

  /**
   * We are done with this slice.
   * If this is a StoreStream with RangeSync, we send back the Ack
   * here. NOTE: For DirectStoreComputeStream with RangeSync, the
   * StreamDone message really completes the whole workflow. For
   * simplicity, here we send back Ack ideally.
   */
  if (dynS->shouldRangeSync() && S->isStoreComputeStream()) {
    bool forceIdea = false;
    if (!dynS->isIndirect()) {
      forceIdea = true;
    }
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
  return this->releaseSlice(sliceIter);
}

void LLCStreamEngine::tryStartComputeLoadComputeSlice(LLCDynStreamPtr dynS,
                                                      LLCStreamSlicePtr slice) {
  const auto &sliceId = slice->getSliceId();
  for (auto elemIdx = sliceId.getStartIdx(); elemIdx < sliceId.getEndIdx();
       ++elemIdx) {
    auto elem = dynS->getElemPanic(elemIdx, "StartComputeLoadComputeSlice");
    if (!elem->isReady() || !elem->areBaseElemsReady()) {
      continue;
    }
    if (elem->isComputationScheduled()) {
      continue;
    }
    if (elem->isComputedValueReady()) {
      continue;
    }
    this->pushReadyComputation(elem, true /* tryVectorize */);
  }
}

void LLCStreamEngine::processLoadComputeSlice(LLCDynStreamPtr dynS,
                                              LLCStreamSlicePtr slice) {
  this->tryStartComputeLoadComputeSlice(dynS, slice);

  const auto &sliceId = slice->getSliceId();
  bool allLoadComputeValueReady = true;
  for (auto elemIdx = sliceId.getStartIdx(); elemIdx < sliceId.getEndIdx();
       ++elemIdx) {
    auto elem = dynS->getElemPanic(elemIdx, "ProcessLoadComputeSlice");
    if (!elem->isComputedValueReady()) {
      allLoadComputeValueReady = false;
    }
  }
  if (!allLoadComputeValueReady) {
    return;
  }

  // Check if need to send back the LoadComputeValue back to core.
  auto S = dynS->getStaticS();
  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  auto sliceVAddrLine = ruby::makeLineAddress(sliceId.vaddr);
  Addr paddrLine;
  panic_if(!dynS->translateToPAddr(sliceVAddrLine, paddrLine),
           "Failed to translate SliceVAddrLine.");
  ruby::DataBlock loadValueBlock;
  int payloadSize = 0;
  for (auto elemIdx = sliceId.getStartIdx(); elemIdx < sliceId.getEndIdx();
       ++elemIdx) {
    auto elem = dynS->getElemPanic(elemIdx, "ProcessLoadComputeSlice");
    const auto &loadComputeValue = elem->getComputedValue();

    int sliceOffset;
    int elemOffset;
    int overlapSize = elem->computeLoadComputeOverlap(
        sliceVAddrLine, ruby::RubySystem::getBlockSizeBytes(), sliceOffset,
        elemOffset);
    if (overlapSize == 0) {
      continue;
    }
    payloadSize += S->getCoreElementSize();

    /**
     * Copy the value from LoadComputeValue to LoadValueBlock.
     * For simplicity we just copy MemElementSize, but the real data
     * size should be CoreElementSize. But this is OK as long as the
     * user only uses the first CoreElementSize bytes' data.
     */
    assert(elemOffset < 64 && "What");
    auto valuePtr = loadComputeValue.uint8Ptr(elemOffset);
    loadValueBlock.setData(valuePtr, sliceOffset, overlapSize);
  }

  // TotalOverlapSize should never exceed the line size.
  if (payloadSize > ruby::RubySystem::getBlockSizeBytes()) {
    payloadSize = ruby::RubySystem::getBlockSizeBytes();
  }

  if (coreNeedValue) {

    /**
     * For RemoteNestConfig we send back the data in idea message.
     */
    bool forceIdea = false;
    if (dynS->configData->hasDepRemoteNestRegion) {
      forceIdea = true;
    }

    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, ruby::RubySystem::getBlockSizeBytes()),
        ruby::RubySystem::getBlockSizeBytes(), payloadSize /* payloadSize */,
        0 /* Line offset */, forceIdea);
    S->statistic.numLLCSentSlice++;
    S->se->numLLCSentSlice++;
    LLC_SLICE_DPRINTF(sliceId,
                      "Send LoadComputeValue to MLC: PAddrLine %#x "
                      "Data %s PayloadSize %d.\n",
                      paddrLine, loadValueBlock, payloadSize);
  } else {
    LLC_SLICE_DPRINTF(sliceId,
                      "Not send LoadComputeValue to MLC: PAddrLine %#x Data %s "
                      "PayloadSize %d.\n",
                      paddrLine, loadValueBlock, payloadSize);
  }

  /**
   * Send the data to receiver stream.
   */
  for (const auto &edge : dynS->sendToEdges) {
    LLC_SLICE_DPRINTF(
        sliceId, "Send LoadComputeValue to RecvS: %s Data %s PayloadSize %d.\n",
        edge.data->dynamicId, loadValueBlock, payloadSize);
    this->issueStreamDataToLLC(dynS, sliceId, loadValueBlock, edge,
                               payloadSize);
  }
  slice->setLoadComputeValueSent();
}

void LLCStreamEngine::processDirectAtomicSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  auto S = dynS->getStaticS();
  assert(S->isAtomicComputeStream() && S->isDirectMemStream() &&
         "Not DirectAtomicComputeStream.");
  bool coreNeedValue = dynS->shouldSendValueToCore();

  auto numMicroOps = S->getComputationNumMicroOps();

  // The final value return to the core.
  ruby::DataBlock *loadValueBlock = nullptr;
  if (coreNeedValue) {
    loadValueBlock = new ruby::DataBlock();
  }
  uint32_t totalPayloadSize = 0;
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto elem = dynS->getElemPanic(idx, "Process slice of AtomicS");
    LLC_SLICE_DPRINTF(sliceId, "TriggerAtomic for elem %llu vaddr %#x.\n",
                      elem->idx, elem->vaddr);
    if (!elem->isReady()) {
      // Not ready yet. Break.
      LLC_SLICE_PANIC(sliceId, "Elem %llu not ready when updating.", idx);
    }
    if (!elem->areBaseElemsReady()) {
      // We are still waiting for base elements.
      LLC_SLICE_PANIC(sliceId, "Elem %llu has unready base elem when updating.",
                      idx);
    }
    uint32_t payloadSize = 0;
    this->triggerAtomic(dynS, elem, sliceId, loadValueBlock, payloadSize);
    totalPayloadSize += payloadSize;

    /**
     * IndirectAtomics are modelled by ComputeEngine, thus we record
     * DirectAtomicStats here.
     * For now we don't bother add the stats to the core in my bank.
     */
    S->recordComputationInCoreStats();
    this->controller->m_statLLCPerformedAtomics++;
    this->controller->m_statLLCScheduledComputation++;
    this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
    this->recordComputationMicroOps(S);
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = ruby::makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock->getData(0, ruby::RubySystem::getBlockSizeBytes()),
        ruby::RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, ruby::RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, *loadValueBlock);
    delete loadValueBlock;
  } else {
    this->issueStreamAckToMLC(sliceId);
  }
}

void LLCStreamEngine::processIndirectAtomicSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  assert(dynS->getStaticS()->isAtomicComputeStream() &&
         !dynS->getStaticS()->isDirectMemStream() &&
         "Not IndirectAtomicComputeStream.");
  /**
   * Speical case for the second request for IndirectAtomicStream
   * with core usage. We just need to send back an Ack.
   */
  auto elemIdx = sliceId.getStartIdx();
  auto elem = dynS->getElemPanic(elemIdx,
                                 "Check IndirectAtomicElement second request.");
  if (elem->hasFirstIndirectAtomicReqSeen()) {
    // This is the second time, should already be handled in
    // receiveStreamIndirectReq().
    LLC_SLICE_PANIC(sliceId, "[Commit] Atomic should be release when "
                             "receiving the second request.");
  }

  LLC_SLICE_DPRINTF(sliceId,
                    "[IndirectAtomic] Schedule computation for vaddr %#x.\n",
                    elem->vaddr);
  /**
   * We are still waiting for BaseElements. However, the element itself is not
   * ready, and will be ready once atomic op completed.
   */
  if (!elem->areBaseElemsReady()) {
    LLC_SLICE_PANIC(sliceId, "BaseElem not ready when process atomic.");
  }
  if (elem->isReady()) {
    LLC_SLICE_PANIC(sliceId, "Elem ready before atomic op.");
  }

  /**
   * Push ready computation.
   */
  elem->indirectAtomicSliceId = sliceId;
  this->pushReadyComputation(elem);
}

void LLCStreamEngine::postProcessIndirectAtomicSlice(
    LLCDynStreamPtr dynS, const LLCStreamElementPtr &elem) {

  const auto &sliceId = elem->indirectAtomicSliceId;
  assert(sliceId.isValid() && "Invalid IndirectAtomic slice id.");

  // The final value return to the core.
  bool coreNeedValue = dynS->shouldSendValueToCore();

  ruby::DataBlock *loadValueBlock = nullptr;
  if (coreNeedValue) {
    loadValueBlock = new ruby::DataBlock();
  }

  uint32_t totalPayloadSize = 0;

  uint32_t payloadSize = 0;
  this->triggerAtomic(dynS, elem, sliceId, loadValueBlock, payloadSize);
  totalPayloadSize += payloadSize;

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = ruby::makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock->getData(0, ruby::RubySystem::getBlockSizeBytes()),
        ruby::RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, ruby::RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "[IndAtomic] Send Data to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, *loadValueBlock);
    delete loadValueBlock;
  } else {
    this->issueStreamAckToMLC(sliceId);
  }

  /**
   * Try to release element if we don't need to issue after commit.
   */
  if (!dynS->shouldIssueAfterCommit()) {
    while (!dynS->idxToElementMap.empty()) {
      auto elemIter = dynS->idxToElementMap.begin();
      const auto &elem = elemIter->second;
      if (!elem->isComputationDone() && !elem->isPredicatedOff()) {
        LLC_SE_ELEM_DPRINTF(
            elem, "[IndirectAtomic] Not Release: !CmpDone && !PredOff.\n");
        break;
      }
      dynS->eraseElem(elemIter);
    }
  }
}

void LLCStreamEngine::processIndirectUpdateSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const ruby::DataBlock &storeValueBlock) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  assert(dynS->getStaticS()->isUpdateStream() &&
         !dynS->getStaticS()->isDirectMemStream() &&
         "Not IndirectUpdateStream.");
  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  // The final value return to the core.
  ruby::DataBlock loadValueBlock;
  uint32_t totalPayloadSize = 0;
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto element = dynS->getElemPanic(idx, "Process slice of IndUpdateS");
    LLC_SLICE_DPRINTF(sliceId, "TriggerIndUpdate for elem %llu vaddr %#x.\n",
                      element->idx, element->vaddr);
    if (!element->isReady()) {
      // Not ready yet. Break.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu not ready while we are triggering update.",
                      idx);
    }
    if (!element->areBaseElemsReady()) {
      // We are still waiting for base elements.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu has base element not ready when updating.",
                      idx);
    }
    uint32_t payloadSize = 0;
    this->triggerUpdate(dynS, element, sliceId, storeValueBlock, loadValueBlock,
                        payloadSize);
    totalPayloadSize += payloadSize;
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = ruby::makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, ruby::RubySystem::getBlockSizeBytes()),
        ruby::RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, ruby::RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  } else {
    bool forceIdea = dynS->isNextIdeaAck();
    dynS->ackedOneSlice();
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
}

bool LLCStreamEngine::tryProcessDirectUpdateSlice(LLCDynStreamPtr dynS,
                                                  LLCStreamSlicePtr slice) {
  const auto &sliceId = slice->getSliceId();

  if (dynS->configData->isPUMPrefetch) {
    slice->setProcessed();
    return true;
  }

  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto elem =
        dynS->getElemPanic(idx, "Check base elements ready for update.");
    if (!elem->areBaseElemsReady()) {
      // We are still waiting for base elements.
      return false;
    }
    /**
     * Update slice also require the element to be ready.
     * Although this has responded, a multi-slice element may still
     * not be ready.
     */
    if (!elem->isReady()) {
      LLC_SE_ELEM_DPRINTF(elem, "[Update] Slice blocked by me.\n");
      return false;
    }
  }

  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto elem = dynS->getElemPanic(idx, "Process UpdateStream");
    LLC_SLICE_DPRINTF(sliceId, "TriggerDirectUpdate for elem %llu vaddr %#x.\n",
                      elem->idx, elem->vaddr);
    if (!elem->isComputedValueReady() && !elem->isComputationScheduled()) {
      this->pushReadyComputation(elem, true /* TryVectorize */);
    }
  }

  slice->setProcessed();
  return true;
}

bool LLCStreamEngine::tryPostProcessDirectUpdateSlice(LLCDynStreamPtr dynS,
                                                      LLCStreamSlicePtr slice) {
  /**
   * We hato to check that all elements are computed.
   */
  if (dynS->configData->isPUMPrefetch) {
    return true;
  }
  const auto &sliceId = slice->getSliceId();
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto element = dynS->getElemPanic(idx, "Process UpdateStream");
    LLC_SLICE_DPRINTF(sliceId,
                      "TryPostProcess for UpdateElem %llu vaddr %#x.\n",
                      element->idx, element->vaddr);
    if (!element->isComputationDone()) {
      return false;
    }
  }
  this->postProcessDirectUpdateSlice(dynS, sliceId);
  return true;
}

void LLCStreamEngine::postProcessDirectUpdateSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {

    /**
     * Construct the returning value from elements.
     */
    ruby::DataBlock loadValueBlock;
    uint32_t totalPayloadSize = 0;
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element = dynS->getElemPanic(idx, "PostProcess UpdateStream");
      LLC_SLICE_DPRINTF(sliceId, "PostDirectUpdate for elem %llu vaddr %#x.\n",
                        element->idx, element->vaddr);
      if (!element->isReady()) {
        // Not ready yet. Break.
        LLC_SLICE_PANIC(
            sliceId,
            "Element %llu not ready while we are post-processing update.", idx);
      }

      /**
       * Send back the overlap value within this line.
       */
      const auto lineSize = ruby::RubySystem::getBlockSizeBytes();
      Addr loadBlockVAddrLine = ruby::makeLineAddress(sliceId.vaddr);
      int elementOffset = 0;
      int loadBlockOffset = 0;
      auto overlapSize = element->computeOverlap(
          loadBlockVAddrLine, lineSize, loadBlockOffset, elementOffset);
      loadValueBlock.setData(element->getUInt8Ptr(elementOffset),
                             loadBlockOffset, overlapSize);
      totalPayloadSize += overlapSize;
    }

    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = ruby::makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, ruby::RubySystem::getBlockSizeBytes()),
        ruby::RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, ruby::RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  } else {
    bool forceIdea = dynS->isNextIdeaAck();
    dynS->ackedOneSlice();
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
}

void LLCStreamEngine::performStore(Addr paddr, int size, const uint8_t *value) {
  auto rubySystem = this->controller->params().ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support store stream without BackingStore.");
  assert((paddr % ruby::RubySystem::getBlockSizeBytes()) + size <=
             ruby::RubySystem::getBlockSizeBytes() &&
         "Can not store to multi-line elements.");
  RequestPtr req =
      std::make_shared<Request>(paddr, size, 0 /* Flags */, 0 /* MasterId */);
  PacketPtr pkt = Packet::createWrite(req);
  pkt->dataStaticConst(value);
  rubySystem->getPhysMem()->functionalAccess(pkt);
  delete pkt;
}

PacketPtr
LLCStreamEngine::createAtomicPacket(Addr vaddr, Addr paddr, int size,
                                    std::unique_ptr<StreamAtomicOp> atomicOp) {
  /**
   * Create the packet.
   */
  RequestorID requestorId = 0;
  Addr pc = 0;
  int contextId = 0;

  Request::Flags flags;
  flags.set(Request::ATOMIC_RETURN_OP);
  RequestPtr req = std::make_shared<Request>(
      vaddr, size, flags, requestorId, pc, contextId, std::move(atomicOp));
  req->setPaddr(paddr);
  PacketPtr pkt = Packet::createWrite(req);
  // Fake some data.
  uint8_t *pkt_data = new uint8_t[req->getSize()];
  pkt->dataDynamic(pkt_data);
  return pkt;
}

std::pair<uint64_t, bool>
LLCStreamEngine::performStreamAtomicOp(LLCDynStreamPtr dynS,
                                       LLCStreamElementPtr elem, Addr elemPAddr,
                                       const DynStreamSliceId &sliceId) {
  assert(sliceId.getNumElements() == 1 &&
         "Can not support multi-element atomic op.");
  auto S = dynS->getStaticS();
  auto elemSize = S->getMemElementSize();

  auto rubySystem = this->controller->params().ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support atomicrmw stream without BackingStore.");
  assert(elemSize <= 8 && "At most 8 byte data.");
  assert((elemPAddr % ruby::RubySystem::getBlockSizeBytes()) + elemSize <=
             ruby::RubySystem::getBlockSizeBytes() &&
         "Can not atomicrmw to multi-line elements.");

  /**
   * Create the atomic op.
   */
  const auto &formalParams = dynS->configData->storeFormalParams;
  FIFOEntryIdx entryIdx(
      sliceId.getDynStreamId(),
      LLVMDynamicInst::INVALID_SEQ_NUM /* Fake ConfigSeqNum */);
  entryIdx.entryIdx = sliceId.getStartIdx();
  auto getBaseStreamValue = [elem](uint64_t baseStreamId) -> StreamValue {
    return elem->getBaseStreamValue(baseStreamId);
  };
  auto atomicOp =
      S->setupAtomicOp(entryIdx, elemSize, formalParams, getBaseStreamValue);

  /**
   * Create the packet.
   */
  auto pkt = this->createAtomicPacket(elem->vaddr, elemPAddr, elemSize,
                                      std::move(atomicOp));
  /**
   * Send to backing store to perform atomic op.
   */
  rubySystem->getPhysMem()->functionalAccess(pkt);
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Functional accessed pkt, isWrite %d, vaddr "
                     "%#x, paddr %#x, size %d.\n",
                     pkt->isWrite(), pkt->req->getVaddr(), pkt->getAddr(),
                     pkt->getSize());

  // Get the loaded value.
  uint64_t loadedValue = 0;
  bool memoryModified = false;
  {
    auto atomicOp = dynamic_cast<StreamAtomicOp *>(pkt->getAtomicOp());
    loadedValue = atomicOp->getLoadedValue().front();
    memoryModified = atomicOp->modifiedMemory();
  }

  // Don't forget to release the packet.
  delete pkt;

  return std::make_pair(loadedValue, memoryModified);
}

void LLCStreamEngine::tryVectorizeElem(LLCStreamElementPtr &elem,
                                       bool tryVectorize) {

  if (!this->controller->myParams->enable_stream_vectorize) {
    return;
  }
  if (elem->size > 32) {
    return;
  }
  if (!tryVectorize && !elem->S->isReduction()) {
    // Apply reduction when required or on ReduceStream.
    return;
  }

  /**
   * If we enabled vectorization, and this is not the first Element in
   * this slice, we mark the element's computation vectorized, so that it
   * is treated as fake computation that does not consume any resources.
   */
  bool shouldVectorized = false;
  if (elem->S->isReduction()) {
    /**
     * Hack: For ReductionStream, each slice has only one element, thus here
     * we approximate by counting how many elements per cache line.
     */
    auto elemsPerLine = ruby::RubySystem::getBlockSizeBytes() / elem->size;
    if (elem->idx % elemsPerLine != 0) {
      shouldVectorized = true;
    }
  } else if (elem->idx != elem->getSliceAt(elem->getNumSlices() - 1)
                              ->getSliceId()
                              .getStartIdx()) {
    shouldVectorized = true;
  }

  if (shouldVectorized) {
    LLC_SE_ELEM_DPRINTF(elem, "[PushReadyCmp] Vectorized.\n");
    elem->vectorizedComputation();
  }
}

void LLCStreamEngine::pushReadyComputation(LLCStreamElementPtr &elem,
                                           bool tryVectorize) {
  LLC_SE_ELEM_DPRINTF(elem, "[PushReadyCmp] #Ready %d #Infly %d TryVec %d.\n",
                      this->readyComputations.size(),
                      this->inflyComputations.size(), tryVectorize);
  assert(elem->areBaseElemsReady() && "Element is not ready yet.");
  if (elem->S->isComputationNop()) {
    // Nop computation is directly skipped.
    LLC_SE_ELEM_DPRINTF(elem, "Skip nop.\n");
    elem->vectorizedComputation();
    this->skipComputation(elem);
    return;
  }
  if (!elem->isNDCElement) {
    auto dynS = LLCDynStream::getLLCStream(elem->strandId);
    if (!dynS) {
      LLC_SE_ELEM_DPRINTF(elem, "Skip computation as Stream is released.\n");
      return;
    }
    if (!dynS->hasComputation()) {
      LLC_ELEMENT_PANIC(elem, "Stream has no computation.");
    }

    this->tryVectorizeElem(elem, tryVectorize);

    if (!elem->isComputationVectorized()) {
      dynS->incompleteComputations++;
    }

    const auto seMachineID = this->controller->getMachineID();
    auto floatMachineType = dynS->getFloatMachineTypeAtElem(elem->idx);
    if (seMachineID.getType() != floatMachineType) {
      LLC_ELEMENT_PANIC(elem,
                        "[PushReadyCmp] Offload %s != SE ruby::MachineType %s.",
                        floatMachineType, seMachineID);
    }
  }
  if (elem->isComputationVectorized()) {
    this->skipComputation(elem);
  } else {
    elem->scheduledComputation(this->curCycle());
    this->readyComputations.emplace_back(elem);
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::skipComputation(LLCStreamElementPtr &elem) {
  assert(elem->isComputationVectorized() && "Skip Compute Vectorized Elem.");
  assert(!elem->isNDCElement && "Skip NDC Elem.");
  elem->scheduledComputation(this->curCycle());

  auto dynS = LLCDynStream::getLLCStream(elem->strandId);
  assert(dynS && "No DynS for SkipComputation");
  assert(!dynS->isIndirectReduction() &&
         "IndReduction should never be skipped.");

  LLC_SE_ELEM_DPRINTF(elem, "Skip computation. Vectorized %d.\n",
                      elem->isComputationVectorized());
  StreamValue result = dynS->computeElemValue(elem);
  dynS->completeComputation(this, elem, result);
}

void LLCStreamEngine::pushInflyComputation(LLCStreamElementPtr &elem,
                                           const StreamValue &result,
                                           Cycles &latency) {
  assert(
      this->numInflyRealCmps <
          this->controller->myParams->llc_stream_engine_max_infly_computation &&
      "Too many infly results.");
  assert(latency < 1024 && "Latency too long.");

  if (!elem->isComputationVectorized()) {
    // This is a real computation.
    auto S = elem->S;
    // For now we don't bother add the stats to the core in my bank.
    S->recordComputationInCoreStats();

    int numMicroOps = S->getComputationNumMicroOps();
    auto &statistic = S->statistic;
    this->controller->m_statLLCScheduledComputation++;
    this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
    this->recordComputationMicroOps(S);
    statistic.numLLCComputation++;
    statistic.numLLCComputationComputeLatency += latency;
    statistic.numLLCComputationWaitLatency +=
        this->curCycle() - elem->getComputationScheduledCycle();

    this->traceEvent(::LLVM::TDG::StreamFloatEvent::CMP_START);

    this->numInflyRealCmps++;
  }

  Cycles readyCycle = this->curCycle() + latency;
  for (auto iter = this->inflyComputations.rbegin(),
            end = this->inflyComputations.rend();
       iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      this->inflyComputations.emplace(iter.base(), elem, result, readyCycle);
      return;
    }
  }
  this->inflyComputations.emplace_front(elem, result, readyCycle);
}

void LLCStreamEngine::recordComputationMicroOps(Stream *S) {
  auto microOps = S->getComputationNumMicroOps();
  auto category = S->getComputationCategory();

#define record_micro_ops(Addr, Compute)                                        \
  if (category.first == Stream::ComputationType::Compute &&                    \
      category.second == Stream::ComputationAddressPattern::Addr) {            \
    this->controller->m_statLLCScheduled##Addr##Compute##MicroOps += microOps; \
    return;                                                                    \
  }
  record_micro_ops(Affine, LoadCompute);
  record_micro_ops(Affine, StoreCompute);
  record_micro_ops(Affine, AtomicCompute);
  record_micro_ops(Affine, Update);
  record_micro_ops(Affine, Reduce);
  record_micro_ops(Indirect, LoadCompute);
  record_micro_ops(Indirect, StoreCompute);
  record_micro_ops(Indirect, AtomicCompute);
  record_micro_ops(Indirect, Update);
  record_micro_ops(Indirect, Reduce);
  record_micro_ops(PointerChase, LoadCompute);
  record_micro_ops(PointerChase, StoreCompute);
  record_micro_ops(PointerChase, AtomicCompute);
  record_micro_ops(PointerChase, Update);
  record_micro_ops(PointerChase, Reduce);
  record_micro_ops(MultiAffine, LoadCompute);
  record_micro_ops(MultiAffine, StoreCompute);
  record_micro_ops(MultiAffine, AtomicCompute);
  record_micro_ops(MultiAffine, Update);
  record_micro_ops(MultiAffine, Reduce);
#undef record_micro_ops
}

void LLCStreamEngine::startComputation() {
  int startedComputation = 0;
  const int computationWidth =
      this->controller->getLLCStreamEngineComputeWidth();
  const int maxInflyComputation =
      this->controller->myParams->llc_stream_engine_max_infly_computation;
  while (startedComputation < computationWidth &&
         !this->readyComputations.empty() &&
         this->numInflyRealCmps < maxInflyComputation) {
    auto &elem = this->readyComputations.front();
    auto S = elem->S;

    Cycles latency = S->getEstimatedComputationLatency();
    if (auto llcDynS = LLCDynStream::getLLCStream(elem->strandId)) {
      if (llcDynS->configData->overrideComputeLatency > 0) {
        latency = Cycles(llcDynS->configData->overrideComputeLatency);
      }
    }

    if (!this->controller->myParams->has_scalar_alu || S->isSIMDComputation()) {
      /**
       * Here we charge extra latency for accessing the core.
       * 1. If this is SIMD operation.
       * 2. If we disable scalar ALU in the stream engine.
       */
      latency += Cycles(this->controller->myParams->llc_access_core_simd_delay);
    }

    auto forceZeroLat =
        this->controller->isLLCStreamEngineZeroComputeLatencyEnabled();
    if (forceZeroLat) {
      latency = Cycles(0);
    }
    /**
     * For IndirectReductionStream, we separate out charging the
     * latency from the real computation. Here we charge the latency,
     * but the real computation is left in completeComputation().
     */
    StreamValue result;

    if (elem->isNDCElement) {
      /**
       * StreamNDC elements are handled by LLCStreamNDCController.
       */
      assert(!elem->isComputationVectorized() && "NDC cannot be vectorized.");
      if (!this->ndcController->computeStreamElementValue(elem, result)) {
        LLC_SE_ELEM_DPRINTF(elem,
                            "Discard NDC computation as stream is released.\n");
        this->readyComputations.pop_front();
        continue;
      }
    } else {
      /**
       * Normal Stream Computing.
       */
      auto dynS = LLCDynStream::getLLCStream(elem->strandId);
      if (!dynS) {
        LLC_SE_ELEM_DPRINTF(elem,
                            "Discard computation as stream is released.\n");
        this->readyComputations.pop_front();
        continue;
      }

      if (dynS->isIndirectReduction()) {
        LLC_SE_ELEM_DPRINTF(
            elem, "[IndReduce] Start fake cmp. Lat %llu (ZeroLat %d).\n",
            latency, forceZeroLat);
        result.fill(0);
      } else {
        LLC_SE_ELEM_DPRINTF(
            elem, "Start computation. Lat %llu (ZeroLat %d) Vectorized %d.\n",
            latency, forceZeroLat, elem->isComputationVectorized());
        result = dynS->computeElemValue(elem);
      }
    }
    this->pushInflyComputation(elem, result, latency);

    this->readyComputations.pop_front();

    /**
     * VectorizedElem does not count as StartedComputation.
     */
    if (!elem->isComputationVectorized()) {
      startedComputation++;
    }
  }
}

void LLCStreamEngine::completeComputation() {
  // We don't charge complete width.
  auto curCycle = this->curCycle();
  while (!this->inflyComputations.empty()) {
    auto &computation = this->inflyComputations.front();
    auto &elem = computation.elem;
    if (computation.readyCycle > curCycle) {
      break;
    }
    LLC_SE_ELEM_DPRINTF(elem, "Complete computation.\n");
    if (elem->isNDCElement) {
      this->ndcController->completeComputation(elem, computation.result);
    } else {
      auto dynS = LLCDynStream::getLLCStream(elem->strandId);
      if (dynS) {
        dynS->completeComputation(this, elem, computation.result);
      } else {
        LLC_SE_ELEM_DPRINTF(
            elem, "Discard computation result as stream is released.\n");
      }
    }
    if (!elem->isComputationVectorized()) {
      // This is not a fake Computation.
      this->traceEvent(::LLVM::TDG::StreamFloatEvent::CMP_DONE);

      this->numInflyRealCmps--;
    }
    this->inflyComputations.pop_front();
  }
}

void LLCStreamEngine::incrementIssueSlice(StreamStatistic &statistic) {
  if (this->myMachineType() == ruby::MachineType_Directory) {
    statistic.numMemIssueSlice++;
  } else {
    statistic.numLLCIssueSlice++;
  }
}

Cycles LLCStreamEngine::lastSampleCycle = Cycles(0);
int LLCStreamEngine::totalSamples = 0;

void LLCStreamEngine::sampleLLCStreams() {
  const Cycles sampleInterval = Cycles(100);
  if (curCycle() < LLCStreamEngine::lastSampleCycle + sampleInterval) {
    return;
  }
  for (const auto &e : LLCDynStream::getGlobalLLCDynStreamMap()) {
    e.second->sample();
  }
  LLCStreamEngine::totalSamples++;
  LLCStreamEngine::lastSampleCycle = curCycle();
  LLC_SE_DPRINTF_(LLCStreamSample, "[Sample] %d at Cycle %lu.\n",
                  LLCStreamEngine::totalSamples,
                  LLCStreamEngine::lastSampleCycle);
}

void LLCStreamEngine::traceEvent(
    Cycles cycle, ::LLVM::TDG::StreamFloatEvent::StreamFloatEventType event) {
  this->seTracer.traceEvent(cycle, this->controller->getMachineID(), event);
}

void LLCStreamEngine::traceEvent(
    ::LLVM::TDG::StreamFloatEvent::StreamFloatEventType event) {
  this->traceEvent(this->curCycle(), event);
}
} // namespace gem5
