
#include "LLCStreamEngine.hh"
#include "MLCStreamEngine.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

// Generated by slicc.
#include "mem/ruby/protocol/StreamMigrateRequestMsg.hh"
#include "mem/simple_mem.hh"

#include "cpu/gem_forge/accelerator/stream/stream_atomic_op.hh"
#include "cpu/gem_forge/accelerator/stream/stream_engine.hh"
#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/LLCRubyStreamBase.hh"
#include "debug/LLCRubyStreamLife.hh"
#include "debug/LLCRubyStreamMulticast.hh"
#include "debug/LLCRubyStreamNotIssue.hh"
#include "debug/LLCRubyStreamReduce.hh"
#include "debug/LLCRubyStreamStore.hh"
#define DEBUG_TYPE LLCRubyStreamBase
#include "../stream_log.hh"

#define LLCSE_DPRINTF(format, args...)                                         \
  DPRINTF(LLCRubyStreamBase, "[LLC_SE%d]: " format,                            \
          this->controller->getMachineID().num, ##args)

LLCStreamEngine::LLCStreamEngine(AbstractStreamAwareController *_controller,
                                 MessageBuffer *_streamMigrateMsgBuffer,
                                 MessageBuffer *_streamIssueMsgBuffer,
                                 MessageBuffer *_streamIndirectIssueMsgBuffer,
                                 MessageBuffer *_streamResponseMsgBuffer)
    : Consumer(_controller), controller(_controller),
      streamMigrateMsgBuffer(_streamMigrateMsgBuffer),
      streamIssueMsgBuffer(_streamIssueMsgBuffer),
      streamIndirectIssueMsgBuffer(_streamIndirectIssueMsgBuffer),
      streamResponseMsgBuffer(_streamResponseMsgBuffer),
      issueWidth(_controller->getLLCStreamEngineIssueWidth()),
      migrateWidth(_controller->getLLCStreamEngineMigrateWidth()),
      maxInflyRequests(8),
      maxInflyRequestsPerStream(_controller->getLLCStreamMaxInflyRequest()),
      maxInqueueRequests(2), translationBuffer(nullptr) {
  this->controller->registerLLCStreamEngine(this);
}

LLCStreamEngine::~LLCStreamEngine() {
  this->streams.clear();
}

int LLCStreamEngine::curLLCBank() const {
  return this->controller->getMachineID().num;
}

void LLCStreamEngine::receiveStreamConfigure(PacketPtr pkt) {

  // Initialize the translation buffer.
  this->initializeTranslationBuffer();

  auto streamConfigureData = *(pkt->getPtr<CacheStreamConfigureDataPtr>());
  LLCSE_DPRINTF("Received Pkt %#x, StreamConfigure %#x, initVAddr "
                "%#x, "
                "initPAddr %#x.\n",
                pkt, streamConfigureData, streamConfigureData->initVAddr,
                streamConfigureData->initPAddr);

  // Create the stream.
  auto S = LLCDynamicStream::getLLCStreamPanic(streamConfigureData->dynamicId);
  LLC_S_DPRINTF_(
      LLCRubyStreamLife, S->getDynamicStreamId(),
      "Configure DirectStream InitAllocatedSlice %d TotalTripCount %lld.\n",
      streamConfigureData->initAllocatedIdx, S->getTotalTripCount());
  S->configuredLLC(this->controller);

  // Check if we have indirect streams.
  for (const auto &edge : streamConfigureData->depEdges) {
    if (edge.type == CacheStreamConfigureData::DepEdge::Type::UsedBy) {
      auto &ISConfig = edge.data;
      // Let's create an indirect stream.
      auto IS = LLCDynamicStream::getLLCStreamPanic(ISConfig->dynamicId);
      LLC_S_DPRINTF_(
          LLCRubyStreamLife, IS->getDynamicStreamId(),
          "Configure IndirectStream MemElementSize %d TotalTripCount %lld.\n",
          IS->getMemElementSize(), IS->getTotalTripCount());
      IS->configuredLLC(this->controller);
    }
  }

  // Release memory.
  *(pkt->getPtr<CacheStreamConfigureDataPtr>()) = nullptr;
  delete pkt;

  S->traceEvent(::LLVM::TDG::StreamFloatEvent::CONFIG);
  // Let's check if StreamEnd packet has arrived earlier.
  if (this->pendingStreamEndMsgs.count(S->getDynamicStreamId())) {
    S->terminate();
  } else {
    this->streams.emplace_back(S);
    this->addStreamToMulticastTable(S);
    // Let's schedule a wakeup event.
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::receiveStreamEnd(PacketPtr pkt) {
  auto endStreamDynamicId = *(pkt->getPtr<DynamicStreamId *>());
  LLC_S_DPRINTF_(LLCRubyStreamLife, *endStreamDynamicId,
                 "Received StreamEnd.\n");
  // Search for this stream.
  for (auto streamIter = this->streams.begin(), streamEnd = this->streams.end();
       streamIter != streamEnd; ++streamIter) {
    auto &S = *streamIter;
    if (S->getDynamicStreamId() == (*endStreamDynamicId)) {
      // Found it.
      // ? Can we just sliently release it?
      this->removeStreamFromMulticastTable(S);
      S->terminate();
      this->streams.erase(streamIter);
      // Don't forgot to release the memory.
      delete endStreamDynamicId;
      delete pkt;
      return;
    }
  }
  /**
   * ? No need to search in migratingStreams?
   * For migrating streams, the end message should be sent to the destination
   * llcBank.
   */

  /**
   * If not found, it is similar case as stream flow control message.
   * We are waiting for the stream to migrate here.
   * Add the message to the pending
   */
  this->pendingStreamEndMsgs.insert(*endStreamDynamicId);

  // Don't forgot to release the memory.
  delete endStreamDynamicId;
  delete pkt;
}

void LLCStreamEngine::receiveStreamMigrate(LLCDynamicStreamPtr stream) {

  this->initializeTranslationBuffer();

  // Sanity check.
  Addr vaddr = stream->peekVAddr();
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Paddr should always be valid to migrate a stream.");
  Addr paddrLine = makeLineAddress(paddr);
  assert(this->isPAddrHandledByMe(paddrLine) &&
         "Stream migrated to wrong LLC bank.\n");

  if (!this->controller->isStreamAdvanceMigrateEnabled()) {
    if (stream->hasIndirectDependent()) {
      // This is only enforced when there is dependent streams.
      assert(stream->inflyRequests == 0 &&
             "Stream migrated with inflyRequests.");
    }
    assert(stream->readyIndirectElements.empty() &&
           "Stream migrated with readyIndirectElements.");
  }

  LLC_S_DPRINTF(stream->getDynamicStreamId(), "Received migrate.\n");

  stream->migratingDone(this->controller);

  // Check for if the stream is already ended.
  if (this->pendingStreamEndMsgs.count(stream->getDynamicStreamId())) {
    stream->terminate();
    return;
  }

  this->streams.emplace_back(stream);
  this->addStreamToMulticastTable(stream);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamFlow(const DynamicStreamSliceId &sliceId) {
  // Simply append it to the list.
  LLC_SLICE_DPRINTF(sliceId, "Received stream flow [%lu, +%lu).\n",
                    sliceId.lhsElementIdx, sliceId.getNumElements());
  this->pendingStreamFlowControlMsgs.push_back(sliceId);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamElementDataVec(
    Cycles delayCycle, const DynamicStreamSliceIdVec &sliceIds,
    const DataBlock &dataBlock, const DataBlock &storeValueBlock) {
  auto readyCycle = this->controller->curCycle() + delayCycle;
  for (const auto &sliceId : sliceIds.sliceIds) {
    this->enqueueIncomingElementDataMsg(readyCycle, sliceId, dataBlock,
                                        storeValueBlock);
  }
  this->scheduleEvent(Cycles(delayCycle));
}

void LLCStreamEngine::enqueueIncomingElementDataMsg(
    Cycles readyCycle, const DynamicStreamSliceId &sliceId,
    const DataBlock &dataBlock, const DataBlock &storeValueBlock) {
  auto iter = this->incomingElementDataQueue.rbegin();
  for (auto end = this->incomingElementDataQueue.rend(); iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      break;
    }
  }
  this->incomingElementDataQueue.emplace(iter.base(), readyCycle, sliceId,
                                         dataBlock, storeValueBlock);
  // Some sanity check.
  if (this->incomingElementDataQueue.size() > 100) {
    LLC_SLICE_PANIC(sliceId, "IncomingElementDataQueue overflow.");
  }
}

void LLCStreamEngine::drainIncomingElementDataMsg() {
  auto curCycle = this->controller->curCycle();
  while (!this->incomingElementDataQueue.empty()) {
    auto &msg = this->incomingElementDataQueue.front();
    if (msg.readyCycle <= curCycle) {
      this->receiveStreamElementData(msg.sliceId, msg.dataBlock,
                                     msg.storeValueBlock);
      this->incomingElementDataQueue.pop_front();
    } else {
      break;
    }
  }
}

void LLCStreamEngine::receiveStreamElementData(
    const DynamicStreamSliceId &sliceId, const DataBlock &dataBlock,
    const DataBlock &storeValueBlock) {
  // Search through the direct streams.
  LLCDynamicStream *stream = nullptr;
  for (auto S : this->streams) {
    if (S->getDynamicStreamId() == sliceId.streamId) {
      stream = S;
      break;
    }
  }
  /**
   * Since we notify the stream engine for all stream data,
   * it is possible that we don't find the stream if it is not direct stream.
   * In such case we look up the global map.
   * TODO: Really encode this in the message.
   */
  if (!stream) {
    // Try to look up the global map.
    stream = LLCDynamicStream::getLLCStream(sliceId.streamId);
  }
  if (!stream) {
    return;
  }
  // Update inflyRequests.
  stream->inflyRequests--;
  if (stream->inflyRequests < 0) {
    LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
  }

  auto S = stream->getStaticStream();
  bool needIndirect =
      !(stream->indirectStreams.empty() && stream->predicatedStreams.empty());
  bool needUpdate = S->isUpdateStream() || S->isAtomicStream();
  bool needSendTo = !(stream->sendToConfigs.empty());

  LLC_SLICE_DPRINTF(sliceId,
                    "Received ElementData, InflyRequests %d, NeedIndirect %d, "
                    "NeedUpdate %d NeedSendTo %d StoreBlock %s.\n",
                    stream->inflyRequests, needIndirect, needUpdate, needSendTo,
                    storeValueBlock);

  if (needSendTo) {
    assert(!needUpdate && !needIndirect && "Cannot support this case for now.");
    for (const auto &recvConfig : stream->sendToConfigs) {
      this->issueStreamDataToLLC(stream, sliceId, dataBlock, recvConfig);
    }
    return;
  }

  /**
   * If this is a StoreStream, just store the slice and send back ack.
   */
  if (S->isStoreStream()) {
    Addr paddr;
    if (!stream->translateToPAddr(sliceId.vaddr, paddr)) {
      LLC_SLICE_PANIC(
          sliceId, "Failed to translate StoreStream slice vaddr %#x to paddr.",
          sliceId.vaddr);
    }
    auto lineOffset = paddr % RubySystem::getBlockSizeBytes();
    LLC_SLICE_DPRINTF_(
        LLCRubyStreamStore, sliceId,
        "StreamStore done with vaddr %#x paddr %#x size %d offset %d value %s, "
        "send back StreamAck.\n",
        sliceId.vaddr, paddr, sliceId.getSize(), lineOffset, storeValueBlock);
    this->performStore(paddr, sliceId.getSize(),
                       storeValueBlock.getData(lineOffset, sliceId.getSize()));
    this->issueStreamAckToMLC(sliceId);
    return;
  }
  /**
   * There is a bug when constructing MultiLine Indirect Stream Element,
   * as the slice.vaddr is no longer the element vaddr. I don't have a
   * good solution. So avoid that case.
   */
  if (!needIndirect && !needUpdate) {
    return;
  }

  /**
   * Finally decide if we need to send back data or ack.
   * 1. Update/Atomic: If core issuing, then need Data, otherwise Ack.
   * 2. Load: Data is already sent by cache controller.
   * We perform this here to make sure traffic between MLC and LLC are correctly
   * sliced.
   */
  bool coreNeedAck = false;
  bool coreNeedValue = false;
  auto dynS = S->getDynamicStream(stream->getDynamicStreamId());
  if (S->isAtomicStream() || S->isUpdateStream()) {
    if (dynS && dynS->shouldCoreSEIssue()) {
      coreNeedValue = true;
    } else {
      coreNeedAck = true;
    }
  }

  /**
   * 1. Construct all the element data, except for store stream.
   * 2. Process each ready element for indirect/update/atomic/store.
   * 3. Release ready element.
   */
  for (auto idx = sliceId.lhsElementIdx; idx < sliceId.rhsElementIdx; ++idx) {
    this->extractElementDataFromSlice(stream, sliceId, idx, dataBlock);
  }

  /**
   * Normally we have to process the element in order, and send back data to MLC
   * in slice granularity. However, since response may come back out of order,
   * and we may lost SlicId. Ideally we should reassemble elements into slice,
   * However as a hack for now, we simply process the element out-of-order and
   * assert element is ready (no reduction, multi-line elements, etc.).
   */
  DataBlock loadValueBlock;
  if (coreNeedValue) {
    for (auto idx = sliceId.lhsElementIdx; idx < sliceId.rhsElementIdx; ++idx) {
      if (!stream->idxToElementMap.at(idx)) {
        LLC_SLICE_PANIC(sliceId, "Element %llu not allocated yet.", idx);
      }
      auto &element = stream->idxToElementMap.at(idx);
      LLC_SLICE_DPRINTF(sliceId, "Process for element %llu, Ready %d.\n",
                        element->idx, element->isReady());
      if (!element->isReady()) {
        // Not ready yet. Break.
        LLC_SLICE_PANIC(sliceId,
                        "Element %llu not ready, but core need value.\n");
      }

      this->processStreamDataForIndirectStreams(stream, element);
      this->processStreamDataForUpdate(stream, element, storeValueBlock,
                                       loadValueBlock);
    }
  } else {
    for (auto &idxElement : stream->idxToElementMap) {
      auto &element = idxElement.second;
      LLC_SLICE_DPRINTF(sliceId, "Process for element %llu, Ready %d.\n",
                        element->idx, element->isReady());
      if (!element->isReady()) {
        // Not ready yet. Break.
        break;
      }

      this->processStreamDataForIndirectStreams(stream, element);
      this->processStreamDataForUpdate(stream, element, storeValueBlock,
                                       loadValueBlock);
    }
  }

  // Now we can release any ready element, as they have already been processed
  // for indirect streams.
  while (!stream->idxToElementMap.empty()) {
    auto elementIter = stream->idxToElementMap.begin();
    if (!elementIter->second->isReady()) {
      break;
    }
    stream->eraseElement(elementIter);
  }

  if (coreNeedValue) {
    Addr paddr = 0;
    assert(stream->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(), 0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  }
  if (coreNeedAck) {
    this->issueStreamAckToMLC(sliceId);
  }
  return;
}

bool LLCStreamEngine::canMigrateStream(LLCDynamicStream *stream) const {
  /**
   * In this implementation, the LLC stream will aggressively
   * migrate to the next element bank, even the credit has only been allocated
   * to the previous element. Therefore, we do not need to check if the next
   * element is allocated.
   */
  auto nextVAddr = stream->peekVAddr();
  Addr nextPAddr;
  if (!stream->translateToPAddr(nextVAddr, nextPAddr)) {
    // If the address is faulted, we stay here.
    return false;
  }
  // Check if it is still on this bank.
  if (this->isPAddrHandledByMe(nextPAddr)) {
    // Still here.
    return false;
  }
  // Only migrate if we enabled advance migrate.
  if (!this->controller->isStreamAdvanceMigrateEnabled()) {
    if (stream->hasIndirectDependent() && stream->inflyRequests > 0) {
      // We are still waiting data for indirect usages:
      // 1. Indirect streams.
      // 2. Update request.
      // 3. Pointer chasing.
      LLC_S_DPRINTF(stream->getDynamicStreamId(),
                    "Delayed migration for inflyRequests %llu.\n",
                    stream->inflyRequests);
      return false;
    }
    if (!stream->readyIndirectElements.empty()) {
      // We are still waiting for some indirect streams to be issued.
      LLC_S_DPRINTF(stream->getDynamicStreamId(),
                    "Delayed migration for readyIndirectElements %llu.\n",
                    stream->readyIndirectElements.size());
      return false;
    }
    if (stream->incompleteComputations != 0) {
      // We are still waiting for some computation to be done.
      LLC_S_DPRINTF(stream->getDynamicStreamId(),
                    "Delayed migration for incomplete computation %llu.\n",
                    stream->incompleteComputations);
      return false;
    }
    /**
     * ! A hack to delay migrate if there is waitingPredicatedElements for any
     * ! indirect stream.
     */
    for (auto IS : stream->indirectStreams) {
      if (!IS->waitingPredicatedElements.empty()) {
        return false;
      }
      if (IS->getStaticStream()->isReduction()) {
        // We wait for the reduction element to be done.
        if (!IS->idxToElementMap.empty()) {
          const auto &element = IS->idxToElementMap.begin()->second;
          /**
           * ! Due to the current hack implementation, an element may already be
           * ! allocated for the next bank. Our way to hack this is check if the
           * ! base is already ready. If not, then they are for next
           * ! bank.
           */
          if (!element->isReady()) {
            for (const auto &baseE : element->baseElements) {
              if (baseE->dynStreamId == stream->getDynamicStreamId()) {
                if (baseE->isReady()) {
                  // The base element is ready, which means this is from this
                  // bank. If it's not ready, then we should have inflyRequest.
                  LLC_S_DPRINTF(
                      IS->getDynamicStreamId(),
                      "Delayed migration for reduction for idx %llu.\n",
                      element->idx);
                  return false;
                }
              }
            }
          }
        }
      }
    }
  }
  return true;
}

void LLCStreamEngine::wakeup() {

  // Sanity check.
  if (this->streams.size() >= 1000) {
    panic("Too many LLCStream.\n");
  }

  // Drain incoming element data.
  this->drainIncomingElementDataMsg();

  this->processStreamFlowControlMsg();
  this->issueStreams();
  this->migrateStreams();
  this->startComputation();
  this->completeComputation();

  // So we limit the issue rate in issueStreams.
  while (!this->requestQueue.empty()) {
    const auto &req = this->requestQueue.front();
    if (!req.translationDone) {
      break;
    }
    this->issueStreamRequestToLLCBank(req);
    this->requestQueue.pop_front();
  }

  // Try drain one StreamForward messages.
  if (!this->pendingStreamForwardMsgs.empty()) {
    if (this->tryProcessStreamForwardRequest(
            this->pendingStreamForwardMsgs.front())) {
      this->pendingStreamForwardMsgs.pop_front();
    }
  }

  if (!this->streams.empty() || !this->migratingStreams.empty() ||
      !this->requestQueue.empty() || !this->pendingStreamForwardMsgs.empty() ||
      !this->incomingElementDataQueue.empty()) {
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::initializeTranslationBuffer() {
  if (!this->translationBuffer) {
    this->translationBuffer =
        m5::make_unique<StreamTranslationBuffer<RequestQueueIter>>(
            this->controller->getCPUDelegator()->getDataTLB(),
            [this](PacketPtr pkt, ThreadContext *tc, RequestQueueIter reqIter)
                -> void { this->translationCallback(pkt, tc, reqIter); },
            true /* AccessLastLevelTLBOnly */
        );
  }
}

bool LLCStreamEngine::canMergeAsMulticast(LLCDynamicStreamPtr dynSA,
                                          LLCDynamicStreamPtr dynSB) const {
  /**
   * Streams are considered possible to merged into one multicast stream iff:
   * 1. They are from cores within the same multicast group.
   * 2. They both have linear address generation function.
   * 3. They have same dynamic parameters for address generation.
   * 4. They have the same request type.
   */
  const auto &dynSAId = dynSA->getDynamicStreamId();
  const auto &dynSBId = dynSB->getDynamicStreamId();
  if (dynSAId.coreId == dynSBId.coreId) {
    // Ignore streams from the same core.
    return false;
  }
  if (dynSA->getStaticStream()->isAtomicComputeStream() ||
      dynSB->getStaticStream()->isAtomicComputeStream()) {
    // Should never multicast atomic streams.
    return false;
  }
  auto multicastGroupIdA =
      this->controller->getMulticastGroupId(dynSAId.coreId);
  auto multicastGroupIdB =
      this->controller->getMulticastGroupId(dynSBId.coreId);
  if (multicastGroupIdA != multicastGroupIdB) {
    // They are not from the same multicast group.
    return false;
  }
  if (dynSA->getStaticId() != dynSA->getStaticId()) {
    return false;
  }
  auto linearAddrGenA = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSA->configData->addrGenCallback);
  auto linearAddrGenB = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSB->configData->addrGenCallback);
  if (!linearAddrGenA || !linearAddrGenB) {
    return false;
  }
  const auto &formalParamsA = dynSA->configData->addrGenFormalParams;
  const auto &formalParamsB = dynSB->configData->addrGenFormalParams;
  if (formalParamsA.size() != formalParamsB.size()) {
    return false;
  }
  for (auto i = 0; i < formalParamsA.size(); ++i) {
    const auto &paramA = formalParamsA.at(i);
    const auto &paramB = formalParamsB.at(i);
    if (!paramA.isInvariant || !paramB.isInvariant) {
      // One of the parameters rely on stream.
      return false;
    }
    if (paramA.invariant != paramB.invariant) {
      return false;
    }
  }
  if (this->getDirectStreamReqType(dynSA) !=
      this->getDirectStreamReqType(dynSB)) {
    return false;
  }
  return true;
}

void LLCStreamEngine::addStreamToMulticastTable(LLCDynamicStreamPtr dynS) {
  bool hasIndirectDependent = dynS->hasIndirectDependent();
  LLC_S_DPRINTF_(
      LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
      "Add to MulticastTable, HasIndirectDependent %d DepEdges %d.\n",
      hasIndirectDependent, dynS->configData->depEdges.size());
  /**
   * Currently we do not try to multicast streams with indirect dependence.
   * This includes streams with SendTo dependence.
   */
  // We only try to merge into multicast if it has no indirect dependent.
  if (!hasIndirectDependent && dynS->configData->depEdges.empty()) {
    for (auto &entry : this->multicastStreamMap) {
      auto dynSRoot = entry.first;
      auto &group = entry.second;
      auto canMerge = this->canMergeAsMulticast(dynS, dynSRoot);
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynamicStreamId(),
                     "Check CanMergeAsMulticast %d.\n", canMerge);
      if (canMerge) {
        // Found the entry.
        group.push_back(dynS);
        dynS->setMulticastGroupLeader(dynSRoot);
        this->sortMulticastGroup(group);
        LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynamicStreamId(),
                       "Merged into MulticastGroup.\n");
        return;
      }
    }
  }
  // Not found.
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                 "New MulticastGroup.\n");
  this->multicastStreamMap
      .emplace(std::piecewise_construct, std::forward_as_tuple(dynS),
               std::forward_as_tuple())
      .first->second.push_back(dynS);
  dynS->setMulticastGroupLeader(dynS);
}

void LLCStreamEngine::removeStreamFromMulticastTable(LLCDynamicStreamPtr dynS) {
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                 "Remove from MulticastTable.\n");
  auto multicastGroupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(multicastGroupLeader);
  assert(mapIter != this->multicastStreamMap.end() &&
         "Failed to find multicast group.");
  // First we remove dynS from this group.
  auto &group = mapIter->second;
  bool erased = false;
  for (auto iter = group.begin(), end = group.end(); iter != end; ++iter) {
    if ((*iter) == dynS) {
      group.erase(iter);
      erased = true;
      break;
    }
  }
  assert(erased && "Failed to erase from MulticastGroup.");
  // Clear the multicast leader for dynS.
  dynS->setMulticastGroupLeader(nullptr);
  if (mapIter->first == dynS) {
    if (!group.empty()) {
      // If this is the leader and the group is not empty after removing,
      // we reinsert this group with a new leader.
      auto newLeader = group.front();
      for (auto &S : group) {
        S->setMulticastGroupLeader(newLeader);
      }
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, newLeader->getDynamicStreamId(),
                     "Select as NewLeader.\n");
      this->multicastStreamMap.emplace(newLeader, group);
    }
    // We can remove the group from the table now.
    assert(this->multicastStreamMap.erase(dynS) == 1 &&
           "Failed to remove the group");
  }
}

bool LLCStreamEngine::hasMergedAsMulticast(LLCDynamicStreamPtr dynS) const {
  return this->getMulticastGroup(dynS).size() > 1;
}

LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynamicStreamPtr dynS) {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

const LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynamicStreamPtr dynS) const {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

bool LLCStreamEngine::canIssueByMulticastPolicy(
    LLCDynamicStreamPtr dynS) const {
  /**
   * There are some policies to tune if we want to delay a stream from
   * issuing to have more multicast oppotunties. Here are the policies:
   * ----- Most Relaxed (Optimize for Latency) ------
   * - Do nothing. Always return ture.
   * - The first stream with NextSliceAllocated in the MulticastGroup.
   * - The stream must be the first one in the MulticastGroup.
   * ---- Most Constranit (Optimize for Traffic) ----
   */

  const auto &group = this->getMulticastGroup(dynS);

  const auto policy = this->controller->getStreamMulticastIssuePolicy();
  switch (policy) {
  case AbstractStreamAwareController::MulticastIssuePolicy::Any:
    return true;
  case AbstractStreamAwareController::MulticastIssuePolicy::FirstAllocated:
    for (const auto &S : group) {
      if (!S->isNextSliceAllocated()) {
        continue;
      }
      // This is the first available stream.
      return S == dynS;
    }
    // Should never happen.
    assert(false && "DynS not found in MulticastGroup.");
  case AbstractStreamAwareController::MulticastIssuePolicy::First:
    return group.front() == dynS;
  default:
    return true;
  }
}

void LLCStreamEngine::sortMulticastGroup(StreamVec &group) const {
  auto comparator = [this](const LLCDynamicStreamPtr &SA,
                           const LLCDynamicStreamPtr &SB) -> bool {
    auto sliceIdxA = SA->getNextSliceIdx();
    auto sliceIdxB = SB->getNextSliceIdx();
    if (sliceIdxA != sliceIdxB) {
      return sliceIdxA < sliceIdxB;
    }
    /**
     * When the next sliceId is the same, it's interesting how we break
     * the tie.
     * 1. If we considered streams with next slice not allocated "smaller",
     *    we are more frequently blocked and this achieves maximum save of
     *    the traffic, as it exposes more multicast opportunity.
     * 2. Otherwise, we try to issue ready streams with smaller sliceId as
     *    soon as possible. This reduces the multicast opportunity, but may
     *    help the latency.
     */
    if (SA->isNextSliceAllocated() != SB->isNextSliceAllocated()) {
      return !SA->isNextSliceAllocated(); // Option 1
      // return SA->isNextSliceAllocated(); // Option 2
    }
    // Break the tie with core id.
    return SA->getDynamicStreamId().coreId < SB->getDynamicStreamId().coreId;
  };
  std::sort(group.begin(), group.end(), comparator);
  if (Debug::LLCRubyStreamMulticast) {
    DPRINTF(LLCRubyStreamMulticast, "Sorted MulticastGroup:---\n");
    for (auto &dynS : group) {
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                     "NextSliceIdx %lu, Allocated %d.\n",
                     dynS->getNextSliceIdx(), dynS->isNextSliceAllocated());
    }
    DPRINTF(LLCRubyStreamMulticast, "---\n");
  }
}

void LLCStreamEngine::generateMulticastRequest(RequestQueueIter reqIter,
                                               LLCDynamicStreamPtr targetDynS) {
  assert(this->controller->isStreamMulticastEnabled());
  auto &group = this->getMulticastGroup(targetDynS);

  const auto &targetSliceId = reqIter->sliceId;
  auto targetSliceIdx = targetDynS->getNextSliceIdx();
  assert(targetSliceIdx > 0 &&
         "DynS should have positive NextSliceIdx as it generated reqIter.");
  LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, targetSliceId,
                     "Generate MulticastRequest.\n");
  // Start to scan, skip dynS.
  for (auto idx = 0; idx < group.size(); ++idx) {
    auto dynS = group.at(idx);
    if (dynS == targetDynS) {
      // We just issued.
      continue;
    }
    if (!dynS->isNextSliceAllocated()) {
      // Not allocated, skip this one.
      continue;
    }
    if (dynS->getNextSliceIdx() + 1 < targetSliceIdx) {
      // This is behind stream, skip it.
      continue;
    }
    if (dynS->getNextSliceIdx() + 1 > targetSliceIdx) {
      // This is future stream, we are done.
      break;
    }
    // Found a multicast stream candidate.
    auto sliceId = dynS->consumeNextSlice();
    // Sanity check for multicast slices.
    if (sliceId.vaddr != targetSliceId.vaddr) {
      LLC_SLICE_PANIC(sliceId, "Mismatch VAddr %#x for Multicast Slice %#x.",
                      sliceId.vaddr, targetSliceId.vaddr);
    }
    if (sliceId.getSize() != targetSliceId.getSize()) {
      LLC_SLICE_PANIC(sliceId, "Mismatch Size %d for Multicast Slice %d.",
                      sliceId.getSize(), targetSliceId.getSize());
    }

    auto SS = dynS->getStaticStream();
    SS->statistic.numLLCIssueSlice++;

    // Register the waiting indirect elements.
    if (!dynS->indirectStreams.empty()) {
      for (auto idx = sliceId.lhsElementIdx; idx < sliceId.rhsElementIdx;
           ++idx) {
        dynS->allocateElement(idx, dynS->slicedStream.getElementVAddr(idx));
      }
    }

    // Add this to the request.
    auto reqType = this->getDirectStreamReqType(dynS);
    if (reqType != reqIter->requestType) {
      LLC_SLICE_PANIC(
          sliceId,
          "Mismatch RequestType for Multicast Slice, Target %s, Ours %s.",
          reqIter->requestType, reqType);
    }
    if (reqType == CoherenceRequestType_GETU) {
      SS->statistic.numLLCSentSlice++;
      SS->se->numLLCSentSlice++;
      SS->statistic.numLLCMulticastSlice++;
      SS->statistic.numLLCCanMulticastSlice++;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast Issue.\n");
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    if (hasIndirectDependent) {
      LLC_SLICE_PANIC(sliceId, "Multicast Issue with IndirectDependent.\n");
    }
    dynS->prevIssuedCycle = this->controller->curCycle();
    dynS->updateIssueClearCycle();
    // Track infly requests.
    dynS->inflyRequests++;

    reqIter->multicastSliceIds.push_back(sliceId);
  }

  if (!reqIter->multicastSliceIds.empty()) {
    targetDynS->getStaticStream()->statistic.numLLCMulticastSlice++;
  }

  // Finally we want to make sure we are sorted.
  this->sortMulticastGroup(group);
}

void LLCStreamEngine::processStreamFlowControlMsg() {
  auto iter = this->pendingStreamFlowControlMsgs.begin();
  auto end = this->pendingStreamFlowControlMsgs.end();
  while (iter != end) {
    const auto &msg = *iter;
    bool processed = false;
    for (auto stream : this->streams) {
      if (stream->getDynamicStreamId() == msg.streamId &&
          msg.lhsElementIdx == stream->allocatedSliceIdx) {
        // We found it.
        // Update the idx.
        LLC_S_DPRINTF(stream->getDynamicStreamId(), "Add credit %lu -> %lu.\n",
                      msg.lhsElementIdx, msg.rhsElementIdx);
        stream->addCredit(msg.getNumElements());
        // Maybe we want to resort the Multicast group.
        if (this->controller->isStreamMulticastEnabled() &&
            this->hasMergedAsMulticast(stream)) {
          this->sortMulticastGroup(this->getMulticastGroup(stream));
        }
        processed = true;
        break;
      }
    }
    if (processed) {
      iter = this->pendingStreamFlowControlMsgs.erase(iter);
    } else {
      // LLCSE_DPRINTF("Failed to process stream credit %s [%lu, %lu).\n",
      //               msg.streamId.name.c_str(), msg.lhsElementIdx,
      //               msg.rhsElementIdx);
      ++iter;
    }
  }
}

void LLCStreamEngine::issueStreams() {

  /**
   * Enforce thresholds for issue stream requests here.
   * 1. If there are many requests in the queue, there is no need to inject
   * more packets to block the queue.
   * 2. As a sanity check, we limit the total number of infly direct requests.
   */

  if (this->streamIssueMsgBuffer->getSize(this->controller->clockEdge()) >=
      this->maxInqueueRequests) {
    return;
  }

  auto streamIter = this->streams.begin();
  auto streamEnd = this->streams.end();
  for (int i = 0, issuedStreams = 0, nStreams = this->streams.size();
       i < nStreams && issuedStreams < this->issueWidth; ++i) {
    auto curStream = streamIter;
    // Move to the next one.
    ++streamIter;
    bool issued = this->issueStream(*curStream);
    if (issued) {
      issuedStreams++;
      // Push the stream back to the end.
      this->streams.splice(streamEnd, this->streams, curStream);
    }
  }

  // Scan all streams for migration target.
  streamIter = this->streams.begin();
  streamEnd = this->streams.end();
  while (streamIter != streamEnd) {
    auto stream = *streamIter;
    if (this->canMigrateStream(stream)) {
      this->migratingStreams.emplace_back(stream);
      streamIter = this->streams.erase(streamIter);
    } else {
      ++streamIter;
    }
  }
}

bool LLCStreamEngine::issueStream(LLCDynamicStream *stream) {

  /**
   * Prioritize indirect elements.
   */
  auto S = stream->getStaticStream();
  auto &statistic = S->statistic;
  bool issuedIndirect = this->issueStreamIndirect(stream);
  if (issuedIndirect) {
    // We successfully issued an indirect element of this stream.
    // NOTE: Indirect stream issue is not counted in ClearIssueCycle.
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::IndirectPriority);
    return true;
  }

  if (!stream->isNextSliceAllocated()) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, stream->getDynamicStreamId(),
                   "Not issue: NextSliceNotAllocated.\n");
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::NextSliceNotAllocated);
    return false;
  }

  /**
   * If we enabled Multicast and this is not the lowest stream in
   * the multicast group, i.e. lagging the most behind, then we do
   * not issue it as we are waiting for behind streams to catch up
   * and explore multicast opportunity.
   */
  if (this->controller->isStreamMulticastEnabled()) {
    if (!this->canIssueByMulticastPolicy(stream)) {
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MulticastPolicy);
      return false;
    }
  }

  /**
   * Check if we have reached issue limit for this stream. Only do this for
   * streams with core user.
   */
  const auto curCycle = this->controller->curCycle();
  if (stream->shouldUpdateIssueClearCycle()) {
    if (curCycle < stream->prevIssuedCycle + stream->issueClearCycle) {
      // We can not issue yet.
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, stream->getDynamicStreamId(),
                     "Not issue: IssueClearCycle %s Current %s.\n",
                     stream->issueClearCycle,
                     curCycle - stream->prevIssuedCycle);
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::IssueClearCycle);
      return false;
    }
  }

  // Enforce the per stream maxInflyRequests constraint.
  if (stream->inflyRequests == this->maxInflyRequestsPerStream) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, stream->getDynamicStreamId(),
                   "Not issue: MaxInflyRequests %d.\n",
                   this->maxInflyRequestsPerStream);
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
    return false;
  }

  /**
   * Allocate the element on Atomic and StoreStream.
   * Additional check on StoreStream, which should have StoreValue ready.
   */
  if (S->isStoreComputeStream() || S->isAtomicComputeStream()) {
    const auto &nextSliceId = stream->peekSlice();
    for (auto idx = nextSliceId.lhsElementIdx; idx < nextSliceId.rhsElementIdx;
         ++idx) {
      stream->allocateElement(idx, stream->slicedStream.getElementVAddr(idx));
      auto &element = stream->idxToElementMap.at(idx);
      if (S->isStoreComputeStream() && !element->isReady()) {
        // Simply schedule the computation.
        if (element->areBaseElementsReady() &&
            !element->isComputationScheduled()) {
          this->pushReadyComputation(element);
        }
        LLC_SLICE_DPRINTF(
            nextSliceId,
            "StoreValue from element %llu not ready, delay issuing.\n", idx);
        return false;
      }
    }
  }

  /**
   * After this point, try to issue base stream element.
   */

  // Get the first element.
  Addr vaddr = stream->peekVAddr();
  Addr paddr;
  if (stream->translateToPAddr(vaddr, paddr)) {

    /**
     * ! The paddr is valid. We issue request to the LLC.
     */
    Addr vaddrLine = makeLineAddress(vaddr);
    Addr paddrLine = makeLineAddress(paddr);

    /**
     * Due to the waiting indirect element, a stream may not be migrated
     * immediately after the stream engine found the next element is not
     * handled here. In such case, we simply give up and return false.
     */
    if (!this->isPAddrHandledByMe(paddr)) {
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::PendingMigrate);
      return false;
    }

    auto sliceId = stream->consumeNextSlice();
    statistic.numLLCIssueSlice++;

    // Register the waiting indirect elements.
    if (!stream->indirectStreams.empty()) {
      for (auto idx = sliceId.lhsElementIdx; idx < sliceId.rhsElementIdx;
           ++idx) {
        stream->allocateElement(idx, stream->slicedStream.getElementVAddr(idx));
      }
    }

    // Push to the request queue.
    auto reqType = this->getDirectStreamReqType(stream);
    if (reqType == CoherenceRequestType_GETU) {
      statistic.numLLCSentSlice++;
      S->se->numLLCSentSlice++;
      if (this->hasMergedAsMulticast(stream)) {
        statistic.numLLCCanMulticastSlice++;
      }
    }
    auto requestIter = this->enqueueRequest(S->getCPUDelegator(), sliceId,
                                            vaddrLine, paddrLine, reqType);

    if (S->isStoreStream()) {
      /**
       * For StoreStream, we build the stored data by extracting overlap
       * region from elements. Notice that we can release any older elements,
       * as later we perform the store in slice granularity, not element
       * granularity. Thus element is not used anymore.
       */
      for (auto idx = sliceId.lhsElementIdx; idx < sliceId.rhsElementIdx;
           ++idx) {
        assert(stream->idxToElementMap.count(idx) &&
               "Missing element for StoreStream.");
        const auto &element = stream->idxToElementMap.at(idx);
        assert(element->isReady() && "StoreElement is not ready.");

        // Compute the overlap and set the data.
        int elementOffset;
        int sliceOffset;
        int overlapSize = element->computeOverlap(
            sliceId.vaddr, sliceId.getSize(), sliceOffset, elementOffset);
        requestIter->dataBlock.setData(element->getUInt8Ptr(elementOffset),
                                       sliceOffset, overlapSize);
        requestIter->storeSize = overlapSize;
        LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                           "Get StoreValue from element %llu, line [%#x, +%d), "
                           "elementOffset %#x.\n",
                           element->idx, sliceId.vaddr + sliceOffset,
                           overlapSize, elementOffset);
      }
      while (stream->idxToElementMap.begin()->first < sliceId.lhsElementIdx) {
        stream->eraseElement(stream->idxToElementMap.begin());
      }
    }

    // Check if we track inflyRequests.
    bool hasIndirectDependent = stream->hasIndirectDependent();
    stream->inflyRequests++;
    LLC_SLICE_DPRINTF(sliceId, "Issue, InflyRequests + 1 = %d.\n",
                      stream->inflyRequests);

    stream->prevIssuedCycle = curCycle;
    stream->updateIssueClearCycle();

    /**
     * Try to handle multicast for streams:
     * 1. Has multicast group.
     * 2. No indirect dependent (can be relaxed later).
     */
    if (!hasIndirectDependent && this->controller->isStreamMulticastEnabled()) {
      this->generateMulticastRequest(requestIter, stream);
    }
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::Issued);
    return true;

  } else {

    /**
     * ! The paddr is not valid. We ignore this slice.
     */
    auto sliceId = stream->consumeNextSlice();
    LLC_SLICE_DPRINTF(sliceId, "Discard due to fault.\n");

    assert(stream->indirectStreams.empty() &&
           "Faulted stream with indirect streams.");
    statistic.numLLCFaultSlice++;

    // This is also considered issued.
    stream->prevIssuedCycle = curCycle;
    stream->updateIssueClearCycle();
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::Issued);
    return true;
  }
}

CoherenceRequestType
LLCStreamEngine::getDirectStreamReqType(LLCDynamicStream *stream) const {
  auto reqType = CoherenceRequestType_GETH;
  auto SS = stream->getStaticStream();
  switch (SS->getStreamType()) {
  case ::LLVM::TDG::StreamInfo_Type_AT:
  case ::LLVM::TDG::StreamInfo_Type_ST:
    reqType = CoherenceRequestType_STREAM_STORE;
    break;
  case ::LLVM::TDG::StreamInfo_Type_LD: {
    if (SS->isUpdateStream()) {
      reqType = CoherenceRequestType_STREAM_STORE;
    } else {
      if (auto dynS = SS->getDynamicStream(stream->getDynamicStreamId())) {
        if (dynS->shouldCoreSEIssue()) {
          // We have to send back the data.
          reqType = CoherenceRequestType_GETU;
        }
      } else {
        // The dynamic stream is already released, we don't really care.
      }
    }
    break;
  }
  default:
    panic("Invalid offloaded stream type.\n");
  }
  return reqType;
}

bool LLCStreamEngine::issueStreamIndirect(LLCDynamicStream *stream) {
  if (stream->readyIndirectElements.empty()) {
    // There is no ready indirect element to be issued.
    return false;
  }

  // Try to issue one with lowest element index.
  auto firstIndirectIter = stream->readyIndirectElements.begin();
  auto idx = firstIndirectIter->first;
  auto dynIS = firstIndirectIter->second;

  // Enforce the per stream maxInflyRequests constraint.
  if (dynIS->inflyRequests == this->maxInflyRequestsPerStream) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynIS->getDynamicStreamId(),
                   "Not issue: MaxInflyRequests %d.\n",
                   this->maxInflyRequestsPerStream);
    dynIS->getStaticStream()->statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
    return false;
  }

  this->generateIndirectStreamRequest(dynIS, idx);
  // Don't forget to release the indirect element.
  stream->readyIndirectElements.erase(firstIndirectIter);

  return true;
}

void LLCStreamEngine::generateIndirectStreamRequest(LLCDynamicStream *dynIS,
                                                    uint64_t elementIdx) {
  auto dynBS = dynIS->baseStream;
  assert(dynBS &&
         "GenerateIndirectStreamRequest can only handle indirect stream.");
  DynamicStreamSliceId sliceId;
  sliceId.streamId = dynIS->getDynamicStreamId();
  sliceId.lhsElementIdx = elementIdx;
  sliceId.rhsElementIdx = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  LLC_SLICE_DPRINTF(sliceId, "Issue indirect.\n");

  auto IS = dynIS->getStaticStream();
  const auto &indirectConfig = dynIS->configData;
  auto elementIter = dynIS->idxToElementMap.find(elementIdx);
  assert(elementIter != dynIS->idxToElementMap.end() &&
         "Missing indirect element");
  auto element = elementIter->second;
  /**
   * In old implementation, we release indirect stream element here. However,
   * our new implementation require that element is not released until we
   * finished processing it. This is the case for UpdateStream and AtomicStream,
   * whose element is released in receiveStreamElementData.
   */
  if (!IS->isUpdateStream() && !IS->isAtomicComputeStream()) {
    dynIS->eraseElement(elementIter);
  }
  if (IS->isReduction()) {
    LLC_S_PANIC(dynIS->getDynamicStreamId(),
                "Reduction is no longer handled here.");
    return;
  }

  // Compute the address.
  auto getBaseStreamValue = [&element](uint64_t baseStreamId) -> StreamValue {
    return element->getBaseStreamValue(baseStreamId);
  };
  Addr elementVAddr =
      indirectConfig->addrGenCallback
          ->genAddr(elementIdx, indirectConfig->addrGenFormalParams,
                    getBaseStreamValue)
          .front();
  LLC_SLICE_DPRINTF(sliceId, "Generate indirect vaddr %#x, size %d.\n",
                    elementVAddr, elementSize);

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto ISType = IS->getStreamType();
  if (ISType == ::LLVM::TDG::StreamInfo_Type_ST ||
      ISType == ::LLVM::TDG::StreamInfo_Type_AT) {
    // This is a store/atomic, we need to issue STREAM_STORE request.
    assert(elementSize <= sizeof(uint64_t) && "Oversized merged store stream.");
    if (dynIS->hasTotalTripCount()) {
      assert(elementIdx < dynIS->getTotalTripCount() &&
             "Try to store beyond TotalTripCount.");
    }

    int lineOffset = elementVAddr % blockBytes;
    assert(lineOffset + elementSize <= blockBytes &&
           "Multi-line merged store stream.");

    sliceId.vaddr = elementVAddr;
    sliceId.size = elementSize;
    Addr elementPAddr;
    if (dynIS->translateToPAddr(elementVAddr, elementPAddr)) {
      IS->statistic.numLLCIssueSlice++;
      auto vaddrLine = makeLineAddress(elementVAddr);
      auto paddrLine = makeLineAddress(elementPAddr);
      /**
       * Compute the store value.
       * If this is a MergededPedicatedStream, it is a constant value.
       * If this is a MergededLoadStoreDepStream, it is computed use the
       * StoreCallback.
       * TODO: These should be merged together.
       */
      uint64_t storeValue = 0;
      if (IS->isMergedPredicated()) {
        // TODO: This is no longer supported.
        panic("MergedPredicated is not supported for now.");
        // storeValue = indirectConfig->constUpdateValue;
      } else if (IS->isMergedLoadStoreDepStream()) {
        // Compute the value.
        auto params = convertFormalParamToParam(
            indirectConfig->storeFormalParams, getBaseStreamValue);
        storeValue = indirectConfig->storeCallback->invoke(params).front();
      } else {
        assert("Unknow merged stream type.");
      }

      // Push to the request queue.
      LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                         "StreamStore -> RequestQueue, StoreValue %lu.\n",
                         storeValue);
      bool isIdeaStore = false;
      int storeSize = sliceId.size;
      if (this->controller->isStreamIdeaStoreEnabled()) {
        isIdeaStore = true;
      } else if (this->controller->isStreamCompactStoreEnabled()) {
        /**
         * Check if we can compact.
         * This is just an approximation, as the request is sending
         * out immediately.
         * TODO: Implement a realistic compact scheme.
         */
        if (dynIS->prevStorePAddrLine == paddrLine) {
          // We can compact.
          isIdeaStore = true;
        } else {
          // As an overhead, we set StoreSize to 64 due to compaction.
          if (IS->isDirectMemStream()) {
            storeSize = RubySystem::getBlockSizeBytes();
          }
        }
      }

      dynIS->prevStorePAddrLine = paddrLine;
      dynIS->prevStoreCycle = this->controller->curCycle();
      if (isIdeaStore) {
        this->performStore(elementPAddr, elementSize,
                           reinterpret_cast<uint8_t *>(&storeValue));
        LLC_SLICE_DPRINTF_(
            LLCRubyStreamStore, sliceId,
            "Ideal StreamStore done with value %llu, send back StreamAck.\n",
            storeValue);

        const bool forceIdeaAck = true;
        this->issueStreamAckToMLC(sliceId, forceIdeaAck);
        if (!this->requestQueue.empty()) {
          this->scheduleEvent(Cycles(1));
        }
      } else {
        auto reqIter =
            this->enqueueRequest(IS->getCPUDelegator(), sliceId, vaddrLine,
                                 paddrLine, CoherenceRequestType_STREAM_STORE);
        dynIS->inflyRequests++;
        auto lineOffset = sliceId.vaddr % RubySystem::getBlockSizeBytes();
        reqIter->dataBlock.setData(reinterpret_cast<uint8_t *>(&storeValue),
                                   lineOffset, sliceId.size);
        reqIter->storeSize = storeSize;
      }

    } else {
      panic("Faulted merged store stream.");
    }
    return;
  }

  /**
   * Finally normal indirect load stream.
   * Handle coalesced multi-line element.
   */
  auto reqType =
      IS->hasCoreUser() ? CoherenceRequestType_GETU : CoherenceRequestType_GETH;
  assert(!dynIS->isPseudoOffload() &&
         "Indirect stream should never be PseudoOffload.");
  auto totalSliceSize = 0;
  while (totalSliceSize < elementSize) {
    Addr curSliceVAddr = elementVAddr + totalSliceSize;
    // Make sure the slice is contained within one line.
    int lineOffset = curSliceVAddr % blockBytes;
    auto curSliceSize = std::min(elementSize - totalSliceSize,
                                 static_cast<int>(blockBytes) - lineOffset);
    // Here we set the slice vaddr and size.
    sliceId.vaddr = curSliceVAddr;
    sliceId.size = curSliceSize;
    Addr curSlicePAddr;
    if (dynIS->translateToPAddr(curSliceVAddr, curSlicePAddr)) {
      Addr curSliceVAddrLine = makeLineAddress(curSliceVAddr);
      Addr curSlicePAddrLine = makeLineAddress(curSlicePAddr);
      IS->statistic.numLLCIssueSlice++;
      if (reqType == CoherenceRequestType_GETU) {
        IS->statistic.numLLCSentSlice++;
        IS->se->numLLCSentSlice++;
      }

      // Push to the request queue.
      this->enqueueRequest(IS->getCPUDelegator(), sliceId, curSliceVAddrLine,
                           curSlicePAddrLine, reqType);
      dynIS->inflyRequests++;
    } else {
      // For faulted slices, we simply ignore it.
      LLC_SLICE_DPRINTF(sliceId, "Discard due to fault, vaddr %#x.\n",
                        sliceId.vaddr);
      dynIS->getStaticStream()->statistic.numLLCFaultSlice++;
    }

    totalSliceSize += curSliceSize;
  }

  return;
}

LLCStreamEngine::RequestQueueIter LLCStreamEngine::enqueueRequest(
    GemForgeCPUDelegator *cpuDelegator, const DynamicStreamSliceId &sliceId,
    Addr vaddrLine, Addr paddrLine, CoherenceRequestType type) {
  this->requestQueue.emplace_back(sliceId, paddrLine, type);
  auto requestQueueIter = std::prev(this->requestQueue.end());
  // To match with TLB interface, we first create a fake packet.
  auto tc = cpuDelegator->getSingleThreadContext();
  RequestPtr req = std::make_shared<Request>(paddrLine, sliceId.getSize(), 0,
                                             cpuDelegator->dataMasterId());
  // Set the vaddrLine as this is what we want to translate.
  req->setVirt(vaddrLine);
  // Simply always read request, since this is a fake request.
  auto pkt = Packet::createRead(req);
  // Do not allocate data for this fake packet.
  uint8_t *pktData = nullptr;
  pkt->dataStatic(pktData);
  // Start the translation.
  LLC_SLICE_DPRINTF(sliceId, "Enqueue %s Req: Start Translation.\n",
                    CoherenceRequestType_to_string(type));
  this->translationBuffer->addTranslation(pkt, tc, requestQueueIter);
  // Since this generates a request, we schedule a wakeup.
  this->scheduleEvent(Cycles(1));
  return requestQueueIter;
}

void LLCStreamEngine::translationCallback(PacketPtr pkt, ThreadContext *tc,
                                          RequestQueueIter reqIter) {
  assert(!reqIter->translationDone && "Translation already done.");
  reqIter->translationDone = true;
  LLC_SLICE_DPRINTF(reqIter->sliceId, "Translated %s Req.\n",
                    CoherenceRequestType_to_string(reqIter->requestType));
  // Remember to release the pkt.
  delete pkt;
}

void LLCStreamEngine::issueStreamRequestToLLCBank(const LLCStreamRequest &req) {
  const auto &sliceId = req.sliceId;
  const auto paddrLine = req.paddrLine;
  auto selfMachineId = this->controller->getMachineID();
  auto destMachineId = selfMachineId;
  bool handledHere = this->isPAddrHandledByMe(req.paddrLine);
  if (handledHere) {
    LLC_SLICE_DPRINTF(
        sliceId, "Issue [local] %s request vaddr %#x paddrLine %#x value %s.\n",
        CoherenceRequestType_to_string(req.requestType), sliceId.vaddr,
        paddrLine, req.dataBlock);
  } else {
    destMachineId = this->mapPaddrToLLCBank(paddrLine);
    LLC_SLICE_DPRINTF(sliceId, "Issue [remote] %s request to LLC%d value %s.\n",
                      CoherenceRequestType_to_string(req.requestType),
                      destMachineId.num, req.dataBlock);
  }

  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = req.requestType;
  msg->m_XXNewRewquestor.add(
      MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                sliceId.streamId.coreId));
  msg->m_Destination.add(destMachineId);
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_sliceIds.add(sliceId);

  // We need to set hold the store value.
  if (req.requestType == CoherenceRequestType_STREAM_STORE) {
    msg->m_streamStoreBlk = req.dataBlock;
    if (req.storeSize > 8) {
      // We model this as a whole cache line put back.
      msg->m_MessageSize = MessageSizeType_Response_Data;
    }
  } else if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
    msg->m_DataBlk = req.dataBlock;
    msg->m_sendToStreamId = req.forwardToStreamId;
    // So far we always model this as a whole cache put back.
    msg->m_MessageSize = MessageSizeType_Response_Data;
  }

  if (Debug::LLCRubyStreamMulticast && !req.multicastSliceIds.empty()) {
    std::stringstream ss;
    for (const auto &multicastSliceId : req.multicastSliceIds) {
      auto mlcMachineID =
          MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                    multicastSliceId.streamId.coreId);
      ss << ' ' << mlcMachineID;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast to %s.\n",
                       ss.str());
  }

  for (const auto &multicastSliceId : req.multicastSliceIds) {
    // TODO: We should really also pass on the sliceId.
    auto mlcMachineID =
        MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                  multicastSliceId.streamId.coreId);
    msg->m_XXNewRewquestor.add(mlcMachineID);
    msg->m_sliceIds.add(multicastSliceId);
  }

  if (handledHere) {
    // Quick path for StreamForward to myself.
    if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
      this->receiveStreamForwardRequest(*msg);
      return;
    }
    Cycles latency(1);
    this->streamIssueMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
  } else {
    Cycles latency(1);
    this->streamIndirectIssueMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
  }
}

LLCStreamEngine::ResponseMsgPtr LLCStreamEngine::createStreamMsgToMLC(
    const DynamicStreamSliceId &sliceId, CoherenceResponseType type,
    Addr paddrLine, const uint8_t *data, int size, int lineOffset) {
  auto selfMachineId = this->controller->getMachineID();
  MachineID mlcMachineId(static_cast<MachineType>(selfMachineId.type - 1),
                         sliceId.streamId.coreId);

  auto msg = std::make_shared<ResponseMsg>(this->controller->clockEdge());
  // For StreamAck, we do not care about the address?
  msg->m_addr = paddrLine;
  msg->m_Type = type;
  msg->m_Sender = selfMachineId;
  msg->m_Destination.add(mlcMachineId);
  msg->m_MessageSize = MessageSizeType_Response_Control;
  msg->m_sliceIds.add(sliceId);
  // Try to copy data.
  if (data) {
    assert(lineOffset + size <= RubySystem::getBlockSizeBytes());
    msg->m_DataBlk.setData(data, lineOffset, size);
    msg->m_MessageSize = this->controller->getMessageSizeType(size);
  }
  return msg;
}

void LLCStreamEngine::issueStreamMsgToMLC(ResponseMsgPtr msg, bool forceIdea) {

  auto mlcMachineId = msg->m_Destination.singleElement();
  const auto &sliceId = msg->m_sliceIds.singleSliceId();

  if (this->controller->isStreamIdeaAckEnabled() || forceIdea) {
    auto mlcController =
        AbstractStreamAwareController::getController(mlcMachineId);
    auto mlcSE = mlcController->getMLCStreamEngine();
    // StreamAck is also disguised as StreamData.
    mlcSE->receiveStreamData(*msg);
    LLC_SLICE_DPRINTF(sliceId, "Send ideal %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  } else {
    /**
     * This should match with LLC controller l2_response_latency.
     * TODO: Really get this value from the controller.
     */
    Cycles latency(2);
    this->streamResponseMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
    LLC_SLICE_DPRINTF(sliceId, "Send %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  }
}

void LLCStreamEngine::issueStreamAckToMLC(const DynamicStreamSliceId &sliceId,
                                          bool forceIdea) {

  // For StreamAck, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_ACK, paddrLine, nullptr, 0, 0);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToMLC(const DynamicStreamSliceId &sliceId,
                                           Addr paddrLine, const uint8_t *data,
                                           int size, int lineOffset,
                                           bool forceIdea) {
  auto msg =
      this->createStreamMsgToMLC(sliceId, CoherenceResponseType_DATA_EXCLUSIVE,
                                 paddrLine, data, size, lineOffset);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToLLC(
    LLCDynamicStreamPtr stream, const DynamicStreamSliceId &sliceId,
    const DataBlock &dataBlock, const CacheStreamConfigureDataPtr &recvConfig) {
  /**
   * Unlike sending data to MLC, we have to calculate the virtual address of the
   * receiving stream and translate that.
   * Also, we can only handle the simpliest case so far: no spliting, and no
   * multi-line receiver element.
   */
  auto elementIdx = sliceId.lhsElementIdx;
  auto recvElementVAddr =
      recvConfig->addrGenCallback
          ->genAddr(elementIdx, recvConfig->addrGenFormalParams,
                    getStreamValueFail)
          .front();
  auto recvElementVAddrEnd = recvElementVAddr + recvConfig->elementSize;
  // Check that receiver does not across lines.
  for (auto idx = sliceId.lhsElementIdx + 1; idx < sliceId.rhsElementIdx;
       ++idx) {
    auto vaddr =
        recvConfig->addrGenCallback
            ->genAddr(idx, recvConfig->addrGenFormalParams, getStreamValueFail)
            .front();
    auto vaddrEnd = vaddr + recvConfig->elementSize;
    recvElementVAddr = std::min(recvElementVAddr, vaddr);
    recvElementVAddrEnd = std::max(recvElementVAddrEnd, vaddrEnd);
  }
  auto recvElementVAddrLine = makeLineAddress(recvElementVAddr);
  auto recvElementVAddrEndLine = makeLineAddress(recvElementVAddr);
  if (recvElementVAddrLine != recvElementVAddrEndLine) {
    LLC_SLICE_PANIC(sliceId, "Multiline StreamForward Receiver: %s.",
                    recvConfig->dynamicId);
  }
  Addr recvElementPAddrLine;
  if (stream->translateToPAddr(recvElementVAddrLine, recvElementPAddrLine)) {
    // Now we enqueue the translation request.
    auto reqIter = this->enqueueRequest(
        recvConfig->stream->getCPUDelegator(), sliceId, recvElementVAddrLine,
        recvElementPAddrLine, CoherenceRequestType_STREAM_FORWARD);
    // Remember the receiver dynamic id and forwarded data block.
    reqIter->forwardToStreamId = recvConfig->dynamicId;
    reqIter->dataBlock = dataBlock;
  } else {
    LLC_SLICE_PANIC(sliceId, "Translation fault on the ReceiverStream: %s.",
                    recvConfig->dynamicId);
  }
}

void LLCStreamEngine::migrateStreams() {
  auto streamIter = this->migratingStreams.begin();
  auto streamEnd = this->migratingStreams.end();
  int migrated = 0;
  while (streamIter != streamEnd && migrated < this->migrateWidth) {
    auto stream = *streamIter;
    assert(this->canMigrateStream(stream) && "Can't migrate stream.");
    this->migrateStream(stream);
    streamIter = this->migratingStreams.erase(streamIter);
    migrated++;
  }
}

void LLCStreamEngine::migrateStream(LLCDynamicStream *stream) {

  // Create the migrate request.
  Addr vaddr = stream->peekVAddr();
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Migrating streams should have valid paddr.");
  Addr paddrLine = makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLC(paddrLine, selfMachineId.type);

  LLC_S_DPRINTF(
      stream->getDynamicStreamId(),
      "Migrate to LLC%d, InflyReq %d AdvancedMigration %d IndirectS %d.\n",
      addrMachineId.num, stream->inflyRequests,
      this->controller->isStreamAdvanceMigrateEnabled(),
      stream->indirectStreams.size());

  auto msg =
      std::make_shared<StreamMigrateRequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  msg->m_MessageSize = MessageSizeType_Data;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  this->removeStreamFromMulticastTable(stream);

  stream->migratingStart();
}

MachineID LLCStreamEngine::mapPaddrToLLCBank(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLC(paddr, selfMachineId.type);
  return addrMachineId;
}

bool LLCStreamEngine::isPAddrHandledByMe(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLC(paddr, selfMachineId.type);
  return addrMachineId == selfMachineId;
}

void LLCStreamEngine::print(std::ostream &out) const {}

void LLCStreamEngine::receiveStreamIndirectRequest(const RequestMsg &req) {

  this->initializeTranslationBuffer();

  // Simply copy and inject the msg to L1 request in.
  const auto &sliceId = req.m_sliceIds.singleSliceId();
  assert(sliceId.isValid() && "Invalid stream slice for indirect request.");

  LLC_SLICE_DPRINTF(
      sliceId, "Receive [indirect] %s request paddrLine %#x delay cycle %s.\n",
      CoherenceRequestType_to_string(req.m_Type), req.m_addr,
      this->controller->curCycle() -
          this->controller->ticksToCycles(req.getTime()));

  if (req.m_Type == CoherenceRequestType_STREAM_FORWARD) {
    // Quick pass for stream forwarding.
    this->receiveStreamForwardRequest(req);
    return;
  }

  auto msg = std::make_shared<RequestMsg>(req);
  Cycles latency(1);
  this->streamIssueMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                      this->controller->cyclesToTicks(latency));
}

void LLCStreamEngine::receiveStreamForwardRequest(const RequestMsg &req) {
  if (this->tryProcessStreamForwardRequest(req)) {
    return;
  }
  this->pendingStreamForwardMsgs.emplace_back(req);
  if (this->pendingStreamForwardMsgs.size() > 100) {
    LLCSE_DPRINTF("Too many pending StreamForward messages: %llu.\n",
                  this->pendingStreamForwardMsgs.size());
  }
  // Schedule a wake up.
  this->scheduleEvent(Cycles(1));
}

bool LLCStreamEngine::tryProcessStreamForwardRequest(const RequestMsg &req) {

  const auto &sliceId = req.m_sliceIds.singleSliceId();
  const auto &recvDynId = req.m_sendToStreamId;
  // Search through the direct streams.
  LLCDynamicStream *directS = nullptr;
  for (auto S : this->streams) {
    if (S->getDynamicStreamId() == recvDynId) {
      directS = S;
      break;
    }
  }
  if (!directS) {
    // Last Effort.
    directS = LLCDynamicStream::getLLCStream(recvDynId);
  }
  if (!directS) {
    LLC_SLICE_DPRINTF(sliceId, "Cannot find the direct receiver: %s.",
                      recvDynId);
    return false;
  }
  // Search for the real receiver.
  LLCDynamicStreamPtr recvS = nullptr;
  if (directS->isBasedOn(sliceId.streamId)) {
    recvS = directS;
  } else {
    for (auto S : directS->indirectStreams) {
      if (S->isBasedOn(sliceId.streamId)) {
        // Found it.
        recvS = S;
        break;
      }
    }
  }
  if (!recvS) {
    LLC_SLICE_PANIC(sliceId, "Cannot find the receiver: %s.", recvDynId);
  }
  // Fill in the elements.
  for (auto idx = sliceId.lhsElementIdx; idx < sliceId.rhsElementIdx; ++idx) {
    recvS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
  }
  return true;
}

void LLCStreamEngine::processStreamDataForIndirectStreams(
    LLCDynamicStreamPtr stream, LLCStreamElementPtr element) {
  if (stream->indirectStreams.empty() && stream->predicatedStreams.empty()) {
    // There is no stream dependent on my data.
    return;
  }

  auto idx = element->idx;
  assert(element->isReady());

  // First we handle any indirect element.
  for (auto IS : stream->indirectStreams) {

    /**
     * If the indirect stream is behind one iteration, base element of
     * iteration i should trigger the indirect element of iteration i + 1.
     * Also we should be careful to not overflow the boundary.
     */
    auto indirectElementIdx = idx;
    if (IS->isOneIterationBehind()) {
      indirectElementIdx = idx + 1;
    }
    auto indirectTripCount = IS->configData->totalTripCount;
    if (indirectTripCount != -1 && indirectElementIdx > indirectTripCount) {
      // Ignore overflow elements.
      continue;
    }

    // We should have the element.
    if (!IS->idxToElementMap.count(indirectElementIdx)) {
      LLC_S_PANIC(IS->getDynamicStreamId(), "Missing IndirectElement.");
    }

    auto &indirectElement = IS->idxToElementMap.at(indirectElementIdx);

    /**
     * Check if the stream has predication.
     */
    if (IS->isPredicated()) {
      assert(!IS->isOneIterationBehind() && "How to handle this?");
      // Push the element to the predicate list.
      // We add the element to the predicateElements.
      IS->predicateStream->waitingPredicatedElements
          .emplace(std::piecewise_construct, std::forward_as_tuple(idx),
                   std::forward_as_tuple())
          .first->second.emplace_back(IS, element);
    } else {
      // Not predicated, add to readyElements.
      assert(stream->baseStream == nullptr);
      LLC_S_DPRINTF(IS->getDynamicStreamId(),
                    "Check if element %llu BaseElementsReady %d.\n",
                    indirectElement->idx,
                    indirectElement->areBaseElementsReady());
      if (indirectElement->areBaseElementsReady()) {
        if (IS->getStaticStream()->isReduction()) {
          // Reduction now is handled as computation.
          this->pushReadyComputation(indirectElement);
        } else {
          stream->readyIndirectElements.emplace(
              std::piecewise_construct,
              std::forward_as_tuple(indirectElementIdx),
              std::forward_as_tuple(IS));
        }
      } else {
        for (const auto &baseE : indirectElement->baseElements) {
          LLC_S_DPRINTF(IS->getDynamicStreamId(),
                        "BaseElements Ready %d %s %llu.\n", baseE->isReady(),
                        baseE->dynStreamId, baseE->idx);
        }
      }
    }
  }

  // Now we handle any predication.
  if (stream->configData->predCallback) {
    GetStreamValueFunc getStreamValue =
        [&element, stream](uint64_t streamId) -> StreamValue {
      assert(streamId == stream->getStaticId() &&
             "Mismatch stream id for predication.");
      StreamValue v;
      v.front() = element->getUInt64();
      return v;
    };
    auto params = convertFormalParamToParam(
        stream->configData->predFormalParams, getStreamValue);
    bool predicatedTrue =
        stream->configData->predCallback->invoke(params).front() & 0x1;
    auto predicatedIter = stream->waitingPredicatedElements.find(idx);
    if (predicatedIter != stream->waitingPredicatedElements.end()) {
      for (auto &predEntry : predicatedIter->second) {
        auto dynPredS = predEntry.first;
        auto predS = dynPredS->getStaticStream();
        auto &predBaseElement = predEntry.second;
        LLC_S_DPRINTF(stream->getDynamicStreamId(), "Predicate %d %d: %s.\n",
                      predicatedTrue, dynPredS->isPredicatedTrue(),
                      dynPredS->getDynamicStreamId());
        if (dynPredS->isPredicatedTrue() == predicatedTrue) {
          predS->statistic.numLLCPredYSlice++;
          // Predicated match, add to ready list.
          if (stream->baseStream) {
            /**
             * The predication is from an indirect stream, this is for
             * pattern: if (a[b[i]]) c[xx]; Since this is an indirect
             * stream, it is likely that we are in a remote LLC bank where
             * a[b[i]] is sitting. We would like to directly generate the
             * address and inject to the requestQueue here.
             */
            this->generateIndirectStreamRequest(dynPredS, idx);
          } else {
            /**
             * The predication is from a direct stream, this is for pattern:
             * if (a[i]) b[i];
             * There is no data dependence between these two streams.
             * In such case we add to readyIndirectElements and waiting to
             * be issued.
             */
            stream->readyIndirectElements.emplace(
                std::piecewise_construct, std::forward_as_tuple(idx),
                std::forward_as_tuple(dynPredS));
          }
        } else {
          // This element is predicated off.
          predS->statistic.numLLCPredNSlice++;
          if (predS->isMerged() && predS->isStoreStream()) {
            /**
             * This is a predicated off merged store, we have to send
             * STREAM_ACK. We still have to set the vaddr as the MLC
             * requires it to match.
             */
            auto dynBS = dynPredS->baseStream;
            assert(dynBS && "MergedStore stream should have base stream.");
            DynamicStreamSliceId sliceId;
            sliceId.streamId = dynPredS->getDynamicStreamId();
            sliceId.lhsElementIdx = idx;
            sliceId.rhsElementIdx = idx + 1;
            auto getBaseStreamValue =
                [&predBaseElement,
                 dynBS](uint64_t baseStreamId) -> StreamValue {
              assert(baseStreamId == dynBS->getStaticId() &&
                     "Invalid baseStreamId.");
              assert(predBaseElement->isReady());
              assert(predBaseElement->size <= 8);
              StreamValue v;
              v.front() = predBaseElement->getUInt64();
              return v;
            };
            auto &predConfig = dynPredS->configData;
            Addr elementVAddr =
                predConfig->addrGenCallback
                    ->genAddr(idx, predConfig->addrGenFormalParams,
                              getBaseStreamValue)
                    .front();
            sliceId.vaddr = elementVAddr;
            sliceId.size = dynPredS->getMemElementSize();
            LLC_SLICE_DPRINTF_(
                LLCRubyStreamStore, sliceId,
                "StreamStore predicated off, send back StreamAck.\n");
            this->issueStreamAckToMLC(sliceId);
          }
        }
      }
      stream->waitingPredicatedElements.erase(predicatedIter);
    }

  } else {
    assert(stream->waitingPredicatedElements.empty() &&
           "No predCallback for predicated elements.");
  }
}

void LLCStreamEngine::processStreamDataForUpdate(
    LLCDynamicStreamPtr stream, LLCStreamElementPtr element,
    const DataBlock &storeValueBlock, DataBlock &loadValueBlock) {

  auto S = stream->getStaticStream();
  if (!(S->isUpdateStream() || S->isAtomicStream())) {
    // There is no update operation.
    return;
  }

  // Perform the operation.
  auto elementMemSize = S->getMemElementSize();
  auto elementCoreSize = S->getCoreElementSize();
  assert(elementCoreSize <= elementMemSize &&
         "CoreElementSize should not exceed MemElementSize.");
  auto elementVAddr = element->vaddr;

  // Create a single slice.
  DynamicStreamSliceId sliceId;
  sliceId.streamId = stream->getDynamicStreamId();
  sliceId.lhsElementIdx = element->idx;
  sliceId.rhsElementIdx = element->idx + 1;

  Addr elementPAddr;
  assert(stream->translateToPAddr(elementVAddr, elementPAddr) &&
         "Fault on vaddr of LLCStore/Atomic/UpdateStream.");
  auto lineOffset = elementVAddr % RubySystem::getBlockSizeBytes();

  if (S->isAtomicStream()) {
    // Very limited AtomicRMW support.
    auto loadedValue = this->performStreamAtomicOp(elementVAddr, elementPAddr,
                                                   stream, sliceId);
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "Perform StreamAtomic, RetValue %llu.\n", loadedValue);
    loadValueBlock.setData(reinterpret_cast<uint8_t *>(&loadedValue),
                           lineOffset, elementCoreSize);
  } else {
    // This is an update stream.
    StreamValue elementValue;
    elementValue.front() = element->getUInt64ByStreamId(stream->getStaticId());
    auto params = convertFormalParamToParam(
        stream->configData->storeFormalParams,
        GetSingleStreamValue(stream->getStaticId(), elementValue));
    auto storeValue = stream->configData->storeCallback->invoke(params);
    assert(elementMemSize <= sizeof(storeValue) &&
           "UpdateStream size overflow.");
    this->performStore(elementPAddr, elementMemSize,
                       reinterpret_cast<uint8_t *>(&storeValue));
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamUpdate done with value %llu.\n",
                       storeValue.front());
  }
}

void LLCStreamEngine::extractElementDataFromSlice(
    LLCDynamicStreamPtr stream, const DynamicStreamSliceId &sliceId,
    uint64_t elementIdx, const DataBlock &dataBlock) {
  // Get the LLCStreamElement.
  if (!stream->idxToElementMap.count(elementIdx)) {
    LLC_S_PANIC(stream->getDynamicStreamId(),
                "Should already allocated the element");
  }
  auto &element = stream->idxToElementMap.at(elementIdx);
  element->extractElementDataFromSlice(
      stream->getStaticStream()->getCPUDelegator(), sliceId, dataBlock);
}

void LLCStreamEngine::updateElementData(LLCDynamicStreamPtr stream,
                                        uint64_t elementIdx,
                                        uint64_t updateValue) {
  // TODO: Handle multi-line element.
  auto elementVAddr = stream->slicedStream.getElementVAddr(elementIdx);
  auto elementSize = stream->getMemElementSize();
  auto elementLineOffset = elementVAddr % RubySystem::getBlockSizeBytes();
  assert(elementLineOffset + elementSize <= RubySystem::getBlockSizeBytes() &&
         "Cannot support multi-line element with indirect streams yet.");
  assert(elementSize <= sizeof(uint64_t) && "At most 8 byte element size.");

  Addr elementPAddr;
  assert(stream->translateToPAddr(elementVAddr, elementPAddr) &&
         "Failed to translate address for accessing backing storage.");
  /**
   * ! The ruby system uses the BackingStore. However, we can not
   * update it here, as then the RubySequencer will read the updated
   * value for the StreamEngine. So we perform the update in StreamEngine
   * when this element is released.
   *
   * However, if we know this stream has no core user, the core stream
   * engine will not try to get the data. Then we perform the update here.
   */
  if (!stream->getStaticStream()->hasCoreUser() && !stream->isPseudoOffload()) {
    this->performStore(elementPAddr, elementSize,
                       reinterpret_cast<uint8_t *>(&updateValue));
  }
}

void LLCStreamEngine::performStore(Addr paddr, int size, const uint8_t *value) {
  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support store stream without BackingStore.");
  assert((paddr % RubySystem::getBlockSizeBytes()) + size <=
             RubySystem::getBlockSizeBytes() &&
         "Can not store to multi-line elements.");
  RequestPtr req =
      std::make_shared<Request>(paddr, size, 0 /* Flags */, 0 /* MasterId */);
  PacketPtr pkt = Packet::createWrite(req);
  pkt->dataStaticConst(value);
  rubySystem->getPhysMem()->functionalAccess(pkt);
  delete pkt;
}

uint64_t
LLCStreamEngine::performStreamAtomicOp(Addr elementVAddr, Addr elementPAddr,
                                       LLCDynamicStreamPtr stream,
                                       const DynamicStreamSliceId &sliceId) {
  assert(sliceId.getNumElements() == 1 &&
         "Can not support multi-element atomic op.");
  auto S = stream->getStaticStream();
  auto elementSize = S->getMemElementSize();

  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support atomicrmw stream without BackingStore.");
  assert(elementSize <= 8 && "At most 8 byte data.");
  assert((elementPAddr % RubySystem::getBlockSizeBytes()) + elementSize <=
             RubySystem::getBlockSizeBytes() &&
         "Can not atomicrmw to multi-line elements.");

  /**
   * Create the atomic op.
   */
  const auto &formalParams = stream->configData->storeFormalParams;
  FIFOEntryIdx entryIdx(
      sliceId.streamId,
      LLVMDynamicInst::INVALID_SEQ_NUM /* Fake ConfigSeqNum */);
  entryIdx.entryIdx = sliceId.lhsElementIdx;
  auto atomicOp = S->setupAtomicOp(entryIdx, elementSize, formalParams);

  /**
   * Create the packet.
   */
  MasterID masterId = 0;
  Addr pc = 0;
  int contextId = 0;

  Request::Flags flags;
  flags.set(Request::ATOMIC_RETURN_OP);
  RequestPtr req =
      std::make_shared<Request>(elementVAddr, elementSize, flags, masterId, pc,
                                contextId, std::move(atomicOp));
  req->setPaddr(elementPAddr);
  PacketPtr pkt = Packet::createWrite(req);
  // Fake some data.
  uint8_t *pkt_data = new uint8_t[req->getSize()];
  pkt->dataDynamic(pkt_data);

  /**
   * Send to backing store to perform atomic op.
   */
  rubySystem->getPhysMem()->functionalAccess(pkt);
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Functional accessed pkt, isWrite %d.\n", pkt->isWrite());

  // Get the loaded value.
  uint64_t loadedValue = 0;
  {
    auto atomicOp = dynamic_cast<StreamAtomicOp *>(pkt->getAtomicOp());
    loadedValue = atomicOp->getLoadedValue().front();
  }

  // Don't forget to release the packet.
  delete pkt;

  return loadedValue;
}

void LLCStreamEngine::pushReadyComputation(LLCStreamElementPtr &element) {
  LLC_ELEMENT_DPRINTF(element, "Push computation.\n");
  assert(element->areBaseElementsReady() && "Element is not ready yet.");
  auto dynS = LLCDynamicStream::getLLCStreamPanic(element->dynStreamId);
  dynS->incompleteComputations++;
  this->readyComputations.emplace_back(element);
  element->scheduledComputation();
}

void LLCStreamEngine::pushInflyComputation(LLCStreamElementPtr &element,
                                           const StreamValue &result,
                                           Cycles &latency) {
  assert(this->inflyComputations.size() < 100 && "Too many infly results.");
  assert(latency < 100 && "Latency too long.");
  Cycles readyCycle = this->controller->curCycle() + latency;
  for (auto iter = this->inflyComputations.rbegin(),
            end = this->inflyComputations.rend();
       iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      this->inflyComputations.emplace(iter.base(), element, result, readyCycle);
      return;
    }
  }
  this->inflyComputations.emplace_front(element, result, readyCycle);
}

void LLCStreamEngine::startComputation() {
  int startedComputation = 0;
  const int computationWidth =
      this->controller->getLLCStreamEngineComputeWidth();
  while (startedComputation < computationWidth &&
         !this->readyComputations.empty()) {
    auto &element = this->readyComputations.front();
    auto dynS = LLCDynamicStream::getLLCStreamPanic(element->dynStreamId);
    Cycles latency(0);
    auto result = dynS->computeStreamElementValue(element, latency);
    auto forceZeroLat =
        this->controller->isLLCStreamEngineZeroComputeLatencyEnabled();
    if (forceZeroLat) {
      latency = Cycles(0);
    }
    LLC_ELEMENT_DPRINTF(
        element, "Start computation. Charge Latency %llu (ZeroLat %d).\n",
        latency, forceZeroLat);
    this->pushInflyComputation(element, result, latency);

    this->readyComputations.pop_front();
    startedComputation++;
  }
}

void LLCStreamEngine::completeComputation() {
  // We don't charge complete width.
  auto curCycle = this->controller->curCycle();
  while (!this->inflyComputations.empty()) {
    auto &computation = this->inflyComputations.front();
    auto &element = computation.element;
    if (computation.readyCycle > curCycle) {
      LLC_ELEMENT_DPRINTF(
          element,
          "Cannot complete computation, readyCycle %llu, curCycle %llu.\n",
          computation.readyCycle, curCycle);
      break;
    }
    LLC_ELEMENT_DPRINTF(element, "Complete computation.\n");
    auto dynS = LLCDynamicStream::getLLCStreamPanic(element->dynStreamId);
    dynS->completeComputation(this, element, computation.result);
    this->inflyComputations.pop_front();
  }
}