
#include "LLCStreamEngine.hh"
#include "LLCStreamCommitController.hh"
#include "LLCStreamRangeBuilder.hh"
#include "MLCStreamEngine.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

// Generated by slicc.
#include "mem/ruby/protocol/StreamMigrateRequestMsg.hh"
#include "mem/simple_mem.hh"

#include "cpu/gem_forge/accelerator/stream/stream_atomic_op.hh"
#include "cpu/gem_forge/accelerator/stream/stream_engine.hh"
#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/LLCRubyStreamBase.hh"
#include "debug/LLCRubyStreamLife.hh"
#include "debug/LLCRubyStreamMulticast.hh"
#include "debug/LLCRubyStreamNotIssue.hh"
#include "debug/LLCRubyStreamReduce.hh"
#include "debug/LLCRubyStreamStore.hh"
#include "debug/StreamRangeSync.hh"
#define DEBUG_TYPE LLCRubyStreamBase
#include "../stream_log.hh"

#define LLCSE_DPRINTF(format, args...)                                         \
  DPRINTF(LLCRubyStreamBase, "[LLC_SE%d]: " format,                            \
          this->controller->getMachineID().num, ##args)

LLCStreamEngine::LLCStreamEngine(AbstractStreamAwareController *_controller,
                                 MessageBuffer *_streamMigrateMsgBuffer,
                                 MessageBuffer *_streamIssueMsgBuffer,
                                 MessageBuffer *_streamIndirectIssueMsgBuffer,
                                 MessageBuffer *_streamResponseMsgBuffer)
    : Consumer(_controller), controller(_controller),
      streamMigrateMsgBuffer(_streamMigrateMsgBuffer),
      streamIssueMsgBuffer(_streamIssueMsgBuffer),
      streamIndirectIssueMsgBuffer(_streamIndirectIssueMsgBuffer),
      streamResponseMsgBuffer(_streamResponseMsgBuffer),
      issueWidth(_controller->getLLCStreamEngineIssueWidth()),
      migrateWidth(_controller->getLLCStreamEngineMigrateWidth()),
      maxInflyRequests(8),
      maxInflyRequestsPerStream(_controller->getLLCStreamMaxInflyRequest()),
      maxInqueueRequests(2), translationBuffer(nullptr) {
  this->controller->registerLLCStreamEngine(this);
  this->commitController = m5::make_unique<LLCStreamCommitController>(this);
}

LLCStreamEngine::~LLCStreamEngine() { this->streams.clear(); }

int LLCStreamEngine::curLLCBank() const {
  return this->controller->getMachineID().num;
}

void LLCStreamEngine::receiveStreamConfigure(PacketPtr pkt) {

  // Initialize the translation buffer.
  this->initializeTranslationBuffer();

  auto streamConfigureData = *(pkt->getPtr<CacheStreamConfigureDataPtr>());
  LLCSE_DPRINTF("Received Pkt %#x, StreamConfigure %#x, initVAddr "
                "%#x, "
                "initPAddr %#x.\n",
                pkt, streamConfigureData, streamConfigureData->initVAddr,
                streamConfigureData->initPAddr);

  // Create the stream.
  auto S = LLCDynamicStream::getLLCStreamPanic(streamConfigureData->dynamicId);
  LLC_S_DPRINTF_(
      LLCRubyStreamLife, S->getDynamicStreamId(),
      "Configure DirectStream InitAllocatedSlice %d TotalTripCount %lld.\n",
      streamConfigureData->initCreditedIdx, S->getTotalTripCount());
  S->configuredLLC(this->controller);

  // Remember the stream to the CommitController if we have that.
  if (S->shouldRangeSync()) {
    this->commitController->registerStream(S);
  }

  // Check if we have indirect streams.
  for (const auto &edge : streamConfigureData->depEdges) {
    if (edge.type == CacheStreamConfigureData::DepEdge::Type::UsedBy) {
      auto &ISConfig = edge.data;
      // Let's create an indirect stream.
      auto IS = LLCDynamicStream::getLLCStreamPanic(ISConfig->dynamicId);
      LLC_S_DPRINTF_(
          LLCRubyStreamLife, IS->getDynamicStreamId(),
          "Configure IndirectStream MemElementSize %d TotalTripCount %lld.\n",
          IS->getMemElementSize(), IS->getTotalTripCount());
      IS->configuredLLC(this->controller);
    }
  }

  // Release memory.
  *(pkt->getPtr<CacheStreamConfigureDataPtr>()) = nullptr;
  delete pkt;

  S->traceEvent(::LLVM::TDG::StreamFloatEvent::CONFIG);
  // Let's check if StreamEnd packet has arrived earlier.
  if (this->pendingStreamEndMsgs.count(S->getDynamicStreamId())) {
    S->terminate();
  } else {
    this->streams.emplace_back(S);
    this->addStreamToMulticastTable(S);
    // Let's schedule a wakeup event.
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::receiveStreamEnd(PacketPtr pkt) {
  auto endStreamDynamicId = *(pkt->getPtr<DynamicStreamId *>());
  LLC_S_DPRINTF_(LLCRubyStreamLife, *endStreamDynamicId,
                 "Received StreamEnd.\n");
  // Search for this stream.
  for (auto streamIter = this->streams.begin(), streamEnd = this->streams.end();
       streamIter != streamEnd; ++streamIter) {
    auto &S = *streamIter;
    if (S->getDynamicStreamId() == (*endStreamDynamicId)) {
      // Found it.
      // ? Can we just sliently release it?
      this->removeStreamFromMulticastTable(S);
      S->terminate();
      this->streams.erase(streamIter);
      // Don't forgot to release the memory.
      delete endStreamDynamicId;
      delete pkt;
      return;
    }
  }
  /**
   * ? No need to search in migratingStreams?
   * For migrating streams, the end message should be sent to the destination
   * llcBank.
   */

  /**
   * If not found, it is similar case as stream flow control message.
   * We are waiting for the stream to migrate here.
   * Add the message to the pending
   */
  this->pendingStreamEndMsgs.insert(*endStreamDynamicId);

  // Don't forgot to release the memory.
  delete endStreamDynamicId;
  delete pkt;
}

void LLCStreamEngine::receiveStreamMigrate(LLCDynamicStreamPtr stream,
                                           bool isCommit) {

  this->initializeTranslationBuffer();

  /**
   * Handle the case for commit migration.
   */
  if (isCommit) {
    LLC_S_DPRINTF_(StreamRangeSync, stream->getDynamicStreamId(),
                   "[Commit] Received migrate.\n");
    this->commitController->registerStream(stream);
    this->scheduleEvent(Cycles(1));
    return;
  }

  // Sanity check.
  Addr vaddr = stream->peekNextAllocVAddr();
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Paddr should always be valid to migrate a stream.");
  Addr paddrLine = makeLineAddress(paddr);
  assert(this->isPAddrHandledByMe(paddrLine) &&
         "Stream migrated to wrong LLC bank.\n");

  if (!this->controller->isStreamAdvanceMigrateEnabled()) {
    if (stream->hasIndirectDependent()) {
      // This is only enforced when there is dependent streams.
      assert(stream->inflyRequests == 0 &&
             "Stream migrated with inflyRequests.");
    }
    assert(!stream->hasIndirectElementReadyToIssue() &&
           "Stream migrated with readyIndirectElements.");
  }

  LLC_S_DPRINTF(stream->getDynamicStreamId(), "Received migrate.\n");

  stream->migratingDone(this->controller);

  // Check for if the stream is already ended.
  if (this->pendingStreamEndMsgs.count(stream->getDynamicStreamId())) {
    stream->terminate();
    return;
  }

  this->streams.emplace_back(stream);
  this->addStreamToMulticastTable(stream);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamFlow(const DynamicStreamSliceId &sliceId) {
  // Simply append it to the list.
  LLC_SLICE_DPRINTF(sliceId, "Received stream flow [%lu, +%lu).\n",
                    sliceId.getStartIdx(), sliceId.getNumElements());
  this->pendingStreamFlowControlMsgs.push_back(sliceId);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamCommit(const DynamicStreamSliceId &sliceId) {
  LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                     "Received stream commit [%llu, %llu).\n",
                     sliceId.getStartIdx(), sliceId.getEndIdx());
  auto dynS = LLCDynamicStream::getLLCStream(sliceId.elementRange.streamId);
  if (!dynS) {
    // The stream is already released.
    return;
  }
  dynS->addCommitMessage(sliceId);
}

void LLCStreamEngine::receiveStreamDataVec(
    Cycles delayCycle, Addr paddrLine, const DynamicStreamSliceIdVec &sliceIds,
    const DataBlock &dataBlock, const DataBlock &storeValueBlock) {
  auto readyCycle = this->controller->curCycle() + delayCycle;

  /**
   * Notice that we replace the data block here if we are using
   * back storage.
   */
  DataBlock loadValueBlock = dataBlock;
  auto rubySystem = this->controller->params()->ruby_system;
  if (rubySystem->getAccessBackingStore()) {
    // Get the data from backing store.
    RequestPtr req =
        std::make_shared<Request>(paddrLine, rubySystem->getBlockSizeBytes(),
                                  0 /* Flags */, 0 /* MasterId */);
    PacketPtr pkt = Packet::createRead(req);
    pkt->dataStatic(loadValueBlock.getDataMod(0 /* offset */));
    rubySystem->getPhysMem()->functionalAccess(pkt);
    delete pkt;
  }

  for (const auto &sliceId : sliceIds.sliceIds) {
    this->enqueueIncomingStreamDataMsg(readyCycle, sliceId, loadValueBlock,
                                       storeValueBlock);
  }
  this->scheduleEvent(Cycles(delayCycle));
}

void LLCStreamEngine::enqueueIncomingStreamDataMsg(
    Cycles readyCycle, const DynamicStreamSliceId &sliceId,
    const DataBlock &dataBlock, const DataBlock &storeValueBlock) {
  auto iter = this->incomingStreamDataQueue.rbegin();
  for (auto end = this->incomingStreamDataQueue.rend(); iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      break;
    }
  }
  this->incomingStreamDataQueue.emplace(iter.base(), readyCycle, sliceId,
                                        dataBlock, storeValueBlock);
  // Some sanity check.
  if (this->incomingStreamDataQueue.size() > 100) {
    LLC_SLICE_PANIC(sliceId, "IncomingElementDataQueue overflow.");
  }
}

void LLCStreamEngine::drainIncomingStreamDataMsg() {
  auto curCycle = this->controller->curCycle();
  while (!this->incomingStreamDataQueue.empty()) {
    auto &msg = this->incomingStreamDataQueue.front();
    if (msg.readyCycle <= curCycle) {
      this->receiveStreamData(msg.sliceId, msg.dataBlock, msg.storeValueBlock);
      this->incomingStreamDataQueue.pop_front();
    } else {
      break;
    }
  }
}

void LLCStreamEngine::receiveStreamData(const DynamicStreamSliceId &sliceId,
                                        const DataBlock &dataBlock,
                                        const DataBlock &storeValueBlock) {
  /**
   * Since we notify the stream engine for all stream data,
   * it is possible that we don't find the stream if it is not direct stream.
   * Thus we just look up the global map.
   */
  auto dynS = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId());
  if (!dynS) {
    return;
  }
  // Update inflyRequests.
  if (dynS->inflyRequests == 0) {
    LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
  }
  dynS->inflyRequests--;

  auto S = dynS->getStaticStream();
  bool needIndirect =
      !(dynS->getIndStreams().empty() && dynS->predicatedStreams.empty());
  bool needUpdate = S->isUpdateStream() || S->isAtomicStream();
  bool needSendTo = !(dynS->sendToConfigs.empty());

  LLC_SLICE_DPRINTF(sliceId,
                    "Received StreamData, InflyRequests %d, NeedIndirect %d, "
                    "NeedUpdate %d NeedSendTo %d StoreBlock %s.\n",
                    dynS->inflyRequests, needIndirect, needUpdate, needSendTo,
                    storeValueBlock);

  // Construct all the element data (except for StoreStream).
  if (!S->isStoreComputeStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element = dynS->getElementPanic(idx, "RecvElementData");
      if (element->hasFirstIndirectAtomicReqSeen()) {
        // This is just the second request for IndirectAtomic.
        // No need to extract data.
        continue;
      }
      if (element->isReady()) {
        LLC_SLICE_PANIC(sliceId, "Elements already ready.");
      }
      element->extractElementDataFromSlice(
          dynS->getStaticStream()->getCPUDelegator(), sliceId, dataBlock);
    }
  }

  /**
   * For DirectStream, we should have the slice in our AllocatedSlice.
   */
  LLCStreamSlicePtr slice = nullptr;
  if (!dynS->isIndirect()) {
    slice = this->tryGetSlice(sliceId);
    if (!slice) {
      LLC_SLICE_PANIC(
          sliceId, "Failed to get slice when receiving data for DirectStream.");
    }
    slice->responded(dataBlock, storeValueBlock);
  }

  /**
   * There are many things to do here.
   * 1. Slice - For StoreStream, perform the store and send back Ack.
   * 2. Slice - For SendTo dependence, send the slice to the receiver.
   * 3. Element - Trigger indirect elements if the base is ready (in order).
   * 4. Element - Trigger update operations (out-of-order).
   * 5. Element - Release ready elements in order.
   */

  if (S->isStoreStream()) {
    this->receiveStoreStreamData(dynS, sliceId, storeValueBlock);
  }

  /**
   * Normally we could just send the data to the receiver stream.
   * However, for LoadComputeStream, we should send after the value is computed.
   */
  if (!dynS->sendToConfigs.empty() && !S->isLoadComputeStream()) {
    for (const auto &recvConfig : dynS->sendToConfigs) {
      this->issueStreamDataToLLC(
          dynS, sliceId, dataBlock, recvConfig,
          RubySystem::getBlockSizeBytes() /* PayloadSize */);
    }
  }

  if (!dynS->getIndStreams().empty()) {
    for (auto &idxElement : dynS->idxToElementMap) {
      auto &element = idxElement.second;
      LLC_SLICE_DPRINTF(sliceId, "Process for element %llu, Ready %d.\n",
                        element->idx, element->isReady());
      if (element->hasIndirectTriggered()) {
        continue;
      }
      if (!element->isReady()) {
        // Not ready yet. Break.
        break;
      }
      this->triggerIndirectElement(dynS, element);
      element->setIndirectTriggered();
    }
  }

  /**
   * The following logic is only for IndirectStream.
   * For DirectStream, these cases are handled in processSlice().
   */
  if (!dynS->isIndirect()) {
    return;
  }

  if (S->isAtomicComputeStream() || S->isUpdateStream()) {
    this->processAtomicOrUpdateSlice(dynS, sliceId, storeValueBlock);
  }

  if (S->isLoadComputeStream()) {
    /**
     * We register a slice here, directly advance to RESPONDED state,
     * and schedule the computation to merge the code path for DirectStream.
     */
    if (sliceId.getNumElements() != 1) {
      LLC_SLICE_PANIC(
          sliceId,
          "IndirectLoadComputeStream with more than one element per slice.");
    }
    auto element = dynS->getElementPanic(
        sliceId.getStartIdx(),
        "ReceiveStreamData for IndirectLoadComputeStream");
    auto slice = std::make_shared<LLCStreamSlice>(sliceId);
    slice->allocate(this);
    slice->issue();
    slice->responded(dataBlock, storeValueBlock);
    this->allocatedSlices.push_back(slice);
    element->addSlice(slice);
    this->processLoadComputeSlice(dynS, slice);
  }

  /**
   * Here we release the indirect element, with a few exceptions:
   * 1. DirectStream element released after all slices are released.
   * 2. IndirectStream that will issue after commit, e.g. AtomicStream,
   * will be released when the final request is handled.
   * 3. IndirectLoadComputeStream is released in releaseSlice().
   */
  if (!dynS->shouldIssueAfterCommit() && !S->isLoadComputeStream()) {
    while (!dynS->idxToElementMap.empty()) {
      auto elementIter = dynS->idxToElementMap.begin();
      const auto &element = elementIter->second;
      if (!element->isReady() || !element->areBaseElementsReady()) {
        break;
      }
      dynS->eraseElement(elementIter);
    }
  }

  return;
}

void LLCStreamEngine::receiveStoreStreamData(
    LLCDynamicStreamPtr dynS, const DynamicStreamSliceId &sliceId,
    const DataBlock &storeValueBlock) {
  /**
   * We received the response for the StoreStream, we now perform the store.
   * And issue Ack back here if this is DirectStream and no range sync.
   *
   * Although we really should perform the store after the core committed,
   * here I store and only delay sending back the Ack in releaseSlice.
   * So far this only works with DirectStream.
   *
   * NOTE: We have to construct the overlap instead of storing the whole line.
   */
  Addr paddr;
  if (!dynS->translateToPAddr(sliceId.vaddr, paddr)) {
    LLC_SLICE_PANIC(sliceId,
                    "Failed to translate StoreStream slice vaddr %#x to paddr.",
                    sliceId.vaddr);
  }
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    assert(dynS->idxToElementMap.count(idx) &&
           "Missing element for StoreStream.");
    auto element = dynS->getElementPanic(idx, "ReceiveStoreStreamData");

    // Compute the overlap and set the data.
    int elementOffset;
    int sliceOffset;
    int overlapSize = element->computeOverlap(sliceId.vaddr, sliceId.getSize(),
                                              sliceOffset, elementOffset);
    auto storeValue = storeValueBlock.getData(sliceOffset, overlapSize);
    LLC_SLICE_DPRINTF_(
        LLCRubyStreamStore, sliceId,
        "StreamStore done with Element %llu, Slice vaddr %#x paddr %#x, "
        "SliceOffset %d OverlapSize %d Value %s.\n",
        idx, sliceId.vaddr, paddr, sliceOffset, overlapSize,
        GemForgeUtils::dataToString(storeValue, overlapSize));
    this->performStore(paddr + sliceOffset, overlapSize, storeValue);
  }
  if (!dynS->shouldRangeSync() && !dynS->isIndirect()) {
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore send back StreamAck.\n");
    this->issueStreamAckToMLC(sliceId);
  }
}

bool LLCStreamEngine::canMigrateStream(LLCDynamicStream *stream) const {
  /**
   * In this implementation, the LLC stream will aggressively
   * migrate to the next element bank, even the credit has only been allocated
   * to the previous element. Therefore, we do not need to check if the next
   * element is allocated.
   */
  auto nextVAddr = stream->peekNextAllocVAddr();
  Addr nextPAddr;
  if (!stream->translateToPAddr(nextVAddr, nextPAddr)) {
    // If the address is faulted, we stay here.
    return false;
  }
  // Check if it is still on this bank.
  if (this->isPAddrHandledByMe(nextPAddr)) {
    // Still here.
    return false;
  }
  // Only migrate if we enabled advance migrate.
  if (!this->controller->isStreamAdvanceMigrateEnabled()) {
    if (stream->hasIndirectDependent() && stream->inflyRequests > 0) {
      // We are still waiting data for indirect usages:
      // 1. Indirect streams.
      // 2. Update request.
      // 3. Pointer chasing.
      LLC_S_DPRINTF(stream->getDynamicStreamId(),
                    "Delayed migration for inflyRequests %llu.\n",
                    stream->inflyRequests);
      return false;
    }
    if (stream->hasIndirectElementReadyToIssue()) {
      // We are still waiting for some indirect streams to be issued.
      LLC_S_DPRINTF(stream->getDynamicStreamId(),
                    "Delayed migration for readyIndirectElements %llu.\n",
                    stream->getNumIndirectElementReadyToIssue());
      return false;
    }
    /**
     * ! A hack to delay migrate if there is waitingPredicatedElements for any
     * ! indirect stream.
     */
    for (auto IS : stream->getIndStreams()) {
      if (!IS->waitingPredicatedElements.empty()) {
        return false;
      }
      if (IS->getStaticStream()->isReduction()) {
        // We wait for the reduction element to be done.
        if (!IS->idxToElementMap.empty()) {
          const auto &element = IS->idxToElementMap.begin()->second;
          /**
           * ! Due to the current hack implementation, an element may already be
           * ! allocated for the next bank. Our way to hack this is check if the
           * ! base is already ready. If not, then they are for next
           * ! bank.
           */
          if (!element->isReady()) {
            for (const auto &baseE : element->baseElements) {
              if (baseE->dynStreamId == stream->getDynamicStreamId()) {
                if (baseE->isReady()) {
                  // The base element is ready, which means this is from this
                  // bank. If it's not ready, then we should have inflyRequest.
                  LLC_S_DPRINTF(
                      IS->getDynamicStreamId(),
                      "Delayed migration for reduction for idx %llu.\n",
                      element->idx);
                  return false;
                }
              }
            }
          }
        }
      }
    }
  }
  return true;
}

void LLCStreamEngine::wakeup() {

  // Sanity check.
  if (this->streams.size() >= 1000) {
    panic("Too many LLCStream.\n");
  }

  // Drain incoming element data.
  this->drainIncomingStreamDataMsg();

  this->processStreamFlowControlMsg();
  this->issueStreams();
  this->issueStreamRangesToMLC();
  this->findMigratingStreams();
  this->migrateStreams();
  this->startComputation();
  this->completeComputation();
  this->processSlices();
  this->commitController->commit();

  // So we limit the issue rate in issueStreams.
  while (!this->requestQueue.empty()) {
    const auto &req = this->requestQueue.front();
    if (!req.translationDone) {
      break;
    }
    this->issueStreamRequestToLLCBank(req);
    this->requestQueue.pop_front();
  }

  if (!this->streams.empty() || !this->migratingStreams.empty() ||
      !this->requestQueue.empty() || !this->incomingStreamDataQueue.empty() ||
      !this->allocatedSlices.empty() || !this->readyComputations.empty() ||
      !this->inflyComputations.empty() ||
      this->commitController->hasStreamToCommit()) {
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::initializeTranslationBuffer() {
  if (!this->translationBuffer) {
    this->translationBuffer =
        m5::make_unique<StreamTranslationBuffer<RequestQueueIter>>(
            this->controller->getCPUDelegator()->getDataTLB(),
            [this](PacketPtr pkt, ThreadContext *tc, RequestQueueIter reqIter)
                -> void { this->translationCallback(pkt, tc, reqIter); },
            true /* AccessLastLevelTLBOnly */
        );
  }
}

bool LLCStreamEngine::canMergeAsMulticast(LLCDynamicStreamPtr dynSA,
                                          LLCDynamicStreamPtr dynSB) const {
  /**
   * Streams are considered possible to merged into one multicast stream iff:
   * 1. They are from cores within the same multicast group.
   * 2. They both have linear address generation function.
   * 3. They have same dynamic parameters for address generation.
   * 4. They have the same request type.
   */
  const auto &dynSAId = dynSA->getDynamicStreamId();
  const auto &dynSBId = dynSB->getDynamicStreamId();
  if (dynSAId.coreId == dynSBId.coreId) {
    // Ignore streams from the same core.
    return false;
  }
  if (dynSA->getStaticStream()->isAtomicComputeStream() ||
      dynSB->getStaticStream()->isAtomicComputeStream()) {
    // Should never multicast atomic streams.
    return false;
  }
  auto multicastGroupIdA =
      this->controller->getMulticastGroupId(dynSAId.coreId);
  auto multicastGroupIdB =
      this->controller->getMulticastGroupId(dynSBId.coreId);
  if (multicastGroupIdA != multicastGroupIdB) {
    // They are not from the same multicast group.
    return false;
  }
  if (dynSA->getStaticId() != dynSA->getStaticId()) {
    return false;
  }
  auto linearAddrGenA = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSA->configData->addrGenCallback);
  auto linearAddrGenB = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSB->configData->addrGenCallback);
  if (!linearAddrGenA || !linearAddrGenB) {
    return false;
  }
  const auto &formalParamsA = dynSA->configData->addrGenFormalParams;
  const auto &formalParamsB = dynSB->configData->addrGenFormalParams;
  if (formalParamsA.size() != formalParamsB.size()) {
    return false;
  }
  for (auto i = 0; i < formalParamsA.size(); ++i) {
    const auto &paramA = formalParamsA.at(i);
    const auto &paramB = formalParamsB.at(i);
    if (!paramA.isInvariant || !paramB.isInvariant) {
      // One of the parameters rely on stream.
      return false;
    }
    if (paramA.invariant != paramB.invariant) {
      return false;
    }
  }
  if (this->getDirectStreamReqType(dynSA) !=
      this->getDirectStreamReqType(dynSB)) {
    return false;
  }
  return true;
}

void LLCStreamEngine::addStreamToMulticastTable(LLCDynamicStreamPtr dynS) {
  bool hasIndirectDependent = dynS->hasIndirectDependent();
  LLC_S_DPRINTF_(
      LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
      "Add to MulticastTable, HasIndirectDependent %d DepEdges %d.\n",
      hasIndirectDependent, dynS->configData->depEdges.size());
  /**
   * Currently we do not try to multicast streams with indirect dependence.
   * This includes streams with SendTo dependence.
   */
  // We only try to merge into multicast if it has no indirect dependent.
  if (!hasIndirectDependent && dynS->configData->depEdges.empty()) {
    for (auto &entry : this->multicastStreamMap) {
      auto dynSRoot = entry.first;
      auto &group = entry.second;
      auto canMerge = this->canMergeAsMulticast(dynS, dynSRoot);
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynamicStreamId(),
                     "Check CanMergeAsMulticast %d.\n", canMerge);
      if (canMerge) {
        // Found the entry.
        group.push_back(dynS);
        dynS->setMulticastGroupLeader(dynSRoot);
        this->sortMulticastGroup(group);
        LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynamicStreamId(),
                       "Merged into MulticastGroup.\n");
        return;
      }
    }
  }
  // Not found.
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                 "New MulticastGroup.\n");
  this->multicastStreamMap
      .emplace(std::piecewise_construct, std::forward_as_tuple(dynS),
               std::forward_as_tuple())
      .first->second.push_back(dynS);
  dynS->setMulticastGroupLeader(dynS);
}

void LLCStreamEngine::removeStreamFromMulticastTable(LLCDynamicStreamPtr dynS) {
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                 "Remove from MulticastTable.\n");
  auto multicastGroupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(multicastGroupLeader);
  assert(mapIter != this->multicastStreamMap.end() &&
         "Failed to find multicast group.");
  // First we remove dynS from this group.
  auto &group = mapIter->second;
  bool erased = false;
  for (auto iter = group.begin(), end = group.end(); iter != end; ++iter) {
    if ((*iter) == dynS) {
      group.erase(iter);
      erased = true;
      break;
    }
  }
  assert(erased && "Failed to erase from MulticastGroup.");
  // Clear the multicast leader for dynS.
  dynS->setMulticastGroupLeader(nullptr);
  if (mapIter->first == dynS) {
    if (!group.empty()) {
      // If this is the leader and the group is not empty after removing,
      // we reinsert this group with a new leader.
      auto newLeader = group.front();
      for (auto &S : group) {
        S->setMulticastGroupLeader(newLeader);
      }
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, newLeader->getDynamicStreamId(),
                     "Select as NewLeader.\n");
      this->multicastStreamMap.emplace(newLeader, group);
    }
    // We can remove the group from the table now.
    assert(this->multicastStreamMap.erase(dynS) == 1 &&
           "Failed to remove the group");
  }
}

bool LLCStreamEngine::hasMergedAsMulticast(LLCDynamicStreamPtr dynS) const {
  return this->getMulticastGroup(dynS).size() > 1;
}

LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynamicStreamPtr dynS) {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

const LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynamicStreamPtr dynS) const {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

bool LLCStreamEngine::canIssueByMulticastPolicy(
    LLCDynamicStreamPtr dynS) const {
  /**
   * There are some policies to tune if we want to delay a stream from
   * issuing to have more multicast oppotunties. Here are the policies:
   * ----- Most Relaxed (Optimize for Latency) ------
   * - Do nothing. Always return ture.
   * - The first stream with NextSliceAllocated in the MulticastGroup.
   * - The stream must be the first one in the MulticastGroup.
   * ---- Most Constranit (Optimize for Traffic) ----
   */

  const auto &group = this->getMulticastGroup(dynS);

  const auto policy = this->controller->getStreamMulticastIssuePolicy();
  switch (policy) {
  case AbstractStreamAwareController::MulticastIssuePolicy::Any:
    return true;
  case AbstractStreamAwareController::MulticastIssuePolicy::FirstAllocated:
    for (const auto &S : group) {
      if (!S->isNextSliceCredited()) {
        continue;
      }
      // This is the first available stream.
      return S == dynS;
    }
    // Should never happen.
    assert(false && "DynS not found in MulticastGroup.");
  case AbstractStreamAwareController::MulticastIssuePolicy::First:
    return group.front() == dynS;
  default:
    return true;
  }
}

void LLCStreamEngine::sortMulticastGroup(StreamVec &group) const {
  auto comparator = [this](const LLCDynamicStreamPtr &SA,
                           const LLCDynamicStreamPtr &SB) -> bool {
    auto sliceIdxA = SA->getNextAllocSliceIdx();
    auto sliceIdxB = SB->getNextAllocSliceIdx();
    if (sliceIdxA != sliceIdxB) {
      return sliceIdxA < sliceIdxB;
    }
    /**
     * When the next sliceId is the same, it's interesting how we break
     * the tie.
     * 1. If we considered streams with next slice not allocated "smaller",
     *    we are more frequently blocked and this achieves maximum save of
     *    the traffic, as it exposes more multicast opportunity.
     * 2. Otherwise, we try to issue ready streams with smaller sliceId as
     *    soon as possible. This reduces the multicast opportunity, but may
     *    help the latency.
     */
    if (SA->isNextSliceCredited() != SB->isNextSliceCredited()) {
      return !SA->isNextSliceCredited(); // Option 1
      // return SA->isNextSliceCredited(); // Option 2
    }
    // Break the tie with core id.
    return SA->getDynamicStreamId().coreId < SB->getDynamicStreamId().coreId;
  };
  std::sort(group.begin(), group.end(), comparator);
  if (Debug::LLCRubyStreamMulticast) {
    DPRINTF(LLCRubyStreamMulticast, "Sorted MulticastGroup:---\n");
    for (auto &dynS : group) {
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynamicStreamId(),
                     "NextAllocSliceIdx %lu, Allocated %d.\n",
                     dynS->getNextAllocSliceIdx(), dynS->isNextSliceCredited());
    }
    DPRINTF(LLCRubyStreamMulticast, "---\n");
  }
}

void LLCStreamEngine::generateMulticastRequest(RequestQueueIter reqIter,
                                               LLCDynamicStreamPtr targetDynS) {
  assert(this->controller->isStreamMulticastEnabled());
  auto &group = this->getMulticastGroup(targetDynS);

  const auto &targetSliceId = reqIter->sliceId;
  auto targetSliceIdx = targetDynS->getNextAllocSliceIdx();
  assert(targetSliceIdx > 0 &&
         "DynS should have positive NextSliceIdx as it generated reqIter.");
  LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, targetSliceId,
                     "Generate MulticastRequest.\n");
  // Start to scan, skip dynS.
  for (auto idx = 0; idx < group.size(); ++idx) {
    auto dynS = group.at(idx);
    if (dynS == targetDynS) {
      // We just issued.
      continue;
    }
    if (!dynS->isNextSliceCredited()) {
      // Not allocated, skip this one.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 < targetSliceIdx) {
      // This is behind stream, skip it.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 > targetSliceIdx) {
      // This is future stream, we are done.
      break;
    }
    // Found a multicast stream candidate.
    auto slice = this->allocateSlice(dynS);
    slice->issue();
    const auto &sliceId = slice->getSliceId();
    // Sanity check for multicast slices.
    if (sliceId.vaddr != targetSliceId.vaddr) {
      LLC_SLICE_PANIC(sliceId, "Mismatch VAddr %#x for Multicast Slice %#x.",
                      sliceId.vaddr, targetSliceId.vaddr);
    }
    if (sliceId.getSize() != targetSliceId.getSize()) {
      LLC_SLICE_PANIC(sliceId, "Mismatch Size %d for Multicast Slice %d.",
                      sliceId.getSize(), targetSliceId.getSize());
    }

    auto SS = dynS->getStaticStream();
    SS->statistic.numLLCIssueSlice++;

    // Add this to the request.
    auto reqType = this->getDirectStreamReqType(dynS);
    if (reqType != reqIter->requestType) {
      LLC_SLICE_PANIC(
          sliceId,
          "Mismatch RequestType for Multicast Slice, Target %s, Ours %s.",
          reqIter->requestType, reqType);
    }
    if (reqType == CoherenceRequestType_GETU) {
      SS->statistic.numLLCSentSlice++;
      SS->se->numLLCSentSlice++;
      SS->statistic.numLLCMulticastSlice++;
      SS->statistic.numLLCCanMulticastSlice++;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast Issue.\n");
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    if (hasIndirectDependent) {
      LLC_SLICE_PANIC(sliceId, "Multicast Issue with IndirectDependent.\n");
    }
    dynS->prevIssuedCycle = this->controller->curCycle();
    dynS->updateIssueClearCycle();
    // Track infly requests.
    dynS->inflyRequests++;

    reqIter->multicastSliceIds.push_back(sliceId);
  }

  if (!reqIter->multicastSliceIds.empty()) {
    targetDynS->getStaticStream()->statistic.numLLCMulticastSlice++;
  }

  // Finally we want to make sure we are sorted.
  this->sortMulticastGroup(group);
}

void LLCStreamEngine::processStreamFlowControlMsg() {
  auto iter = this->pendingStreamFlowControlMsgs.begin();
  auto end = this->pendingStreamFlowControlMsgs.end();
  while (iter != end) {
    const auto &msg = *iter;
    bool processed = false;
    for (auto stream : this->streams) {
      if (stream->getDynamicStreamId() == msg.getDynStreamId() &&
          msg.getStartIdx() == stream->creditedSliceIdx) {
        // We found it.
        // Update the idx.
        LLC_S_DPRINTF(stream->getDynamicStreamId(), "Add credit %lu -> %lu.\n",
                      msg.getStartIdx(), msg.getEndIdx());
        stream->addCredit(msg.getNumElements());
        // Maybe we want to resort the Multicast group.
        if (this->controller->isStreamMulticastEnabled() &&
            this->hasMergedAsMulticast(stream)) {
          this->sortMulticastGroup(this->getMulticastGroup(stream));
        }
        processed = true;
        break;
      }
    }
    if (processed) {
      iter = this->pendingStreamFlowControlMsgs.erase(iter);
    } else {
      // LLCSE_DPRINTF("Failed to process stream credit %s [%lu, %lu).\n",
      //               msg.streamId.name.c_str(), msg.getStartIdx(),
      //               msg.getEndIdx());
      ++iter;
    }
  }
}

void LLCStreamEngine::issueStreams() {

  /**
   * Enforce thresholds for issue stream requests here.
   * 1. If there are many requests in the queue, there is no need to inject
   * more packets to block the queue.
   * 2. As a sanity check, we limit the total number of infly direct requests.
   */

  if (this->streamIssueMsgBuffer->getSize(this->controller->clockEdge()) >=
      this->maxInqueueRequests) {
    return;
  }

  // By cheching i < nStreams we avoid issuing the same stream more than once.
  auto streamIter = this->streams.begin();
  auto streamEnd = this->streams.end();
  for (int i = 0, issuedStreams = 0, nStreams = this->streams.size();
       i < nStreams && issuedStreams < this->issueWidth; ++i) {
    auto curStream = streamIter;
    // Move to the next one.
    ++streamIter;
    auto readyS = this->findStreamReadyToIssue(*curStream);
    if (readyS) {
      if (readyS->isIndirect()) {
        this->issueStreamIndirect(readyS);
      } else {
        this->issueStreamDirect(readyS);
      }
      issuedStreams++;
      // Push the stream back to the end.
      this->streams.splice(streamEnd, this->streams, curStream);
    }
  }
}

LLCDynamicStreamPtr
LLCStreamEngine::findStreamReadyToIssue(LLCDynamicStreamPtr dynS) {

  auto S = dynS->getStaticStream();
  auto &statistic = S->statistic;
  /**
   * Prioritize indirect streams.
   */
  LLCDynamicStreamPtr readyS = this->findIndirectStreamReadyToIssue(dynS);
  if (readyS) {
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::IndirectPriority);
    return readyS;
  }

  if (!dynS->isNextSliceCredited()) {
    // LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynamicStreamId(),
    //                "Not issue: NextSliceNotAllocated.\n");
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::NextSliceNotAllocated);
    return nullptr;
  }

  /**
   * If we enabled Multicast and this is not the lowest stream in
   * the multicast group, i.e. lagging the most behind, then we do
   * not issue it as we are waiting for behind streams to catch up
   * and explore multicast opportunity.
   */
  if (this->controller->isStreamMulticastEnabled()) {
    if (!this->canIssueByMulticastPolicy(dynS)) {
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MulticastPolicy);
      return nullptr;
    }
  }

  /**
   * Check if we have reached issue limit for this stream. Only do this for
   * streams with core user.
   */
  const auto curCycle = this->controller->curCycle();
  if (dynS->shouldUpdateIssueClearCycle()) {
    if (curCycle < dynS->prevIssuedCycle + dynS->issueClearCycle) {
      // We can not issue yet.
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynamicStreamId(),
                     "Not issue: IssueClearCycle %s Current %s.\n",
                     dynS->issueClearCycle, curCycle - dynS->prevIssuedCycle);
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::IssueClearCycle);
      return nullptr;
    }
  }

  // Enforce the per stream maxInflyRequests constraint.
  if (dynS->inflyRequests == this->maxInflyRequestsPerStream) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynamicStreamId(),
                   "Not issue: MaxInflyRequests %d.\n",
                   this->maxInflyRequestsPerStream);
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
    return nullptr;
  }

  /**
   * Allocate the element on Atomic and StoreStream.
   * Additional check on StoreStream, which should have StoreValue ready.
   */
  if (S->isStoreComputeStream() || S->isAtomicComputeStream()) {
    auto nextSlice = dynS->getNextAllocSlice();
    if (!nextSlice) {
      LLC_S_PANIC(dynS->getDynamicStreamId(),
                  "Failed to get next alloc slice.");
    }
    const auto &nextSliceId = nextSlice->getSliceId();
    for (auto idx = nextSliceId.getStartIdx(); idx < nextSliceId.getEndIdx();
         ++idx) {
      auto element = dynS->getElementPanic(idx, "Check StoreValue Ready.");
      if (S->isStoreComputeStream() && !element->isReady()) {
        // Simply schedule the computation.
        if (element->areBaseElementsReady() &&
            !element->isComputationScheduled()) {
          this->pushReadyComputation(element);
        }
        LLC_SLICE_DPRINTF(
            nextSliceId,
            "StoreValue from element %llu not ready, delay issuing.\n", idx);
        return nullptr;
      }
    }
  }

  /**
   * Check that the next address is still handled here.
   * Due to the waiting indirect element, a stream may not be migrated
   * immediately after the stream engine found the next element is not
   * handled here. In such case, we simply give up and return false.
   *
   * In case of faulting, the slice will be skipped (see issueDirectStream()).
   */
  Addr vaddr = dynS->peekNextAllocVAddr();
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {
    if (!this->isPAddrHandledByMe(paddr)) {
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::PendingMigrate);
      return nullptr;
    }
  }

  // We should be able to issue this stream.
  statistic.sampleLLCStreamEngineIssueReason(
      StreamStatistic::LLCStreamEngineIssueReason::Issued);
  return dynS;
}

LLCDynamicStreamPtr
LLCStreamEngine::findIndirectStreamReadyToIssue(LLCDynamicStreamPtr dynS) {

  if (!dynS->hasIndirectElementReadyToIssue()) {
    return nullptr;
  }

  // Find the indirect stream with lowest element index.
  LLCDynamicStreamPtr readyS = nullptr;
  uint64_t readyElementIdx = 0;
  for (auto dynIS : dynS->getIndStreams()) {
    // Enforce the per stream maxInflyRequests constraint.
    if (dynIS->inflyRequests == this->maxInflyRequestsPerStream) {
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynIS->getDynamicStreamId(),
                     "Not issue: MaxInflyRequests %d.\n",
                     this->maxInflyRequestsPerStream);
      dynIS->getStaticStream()->statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
      continue;
    }

    if (auto element = dynIS->getFirstReadyToIssueElement()) {
      auto elementIdx = element->idx;
      if (!readyS || readyElementIdx > elementIdx) {
        readyS = dynIS;
        readyElementIdx = elementIdx;
      }
    }
  }

  return readyS;
}

void LLCStreamEngine::issueStreamDirect(LLCDynamicStream *dynS) {

  auto S = dynS->getStaticStream();
  auto &statistic = S->statistic;

  // Get the next address.
  auto slice = this->allocateSlice(dynS);
  const auto &sliceId = slice->getSliceId();
  Addr vaddr = sliceId.vaddr;
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {

    // The paddr is valid. We issue request to the LLC.
    Addr vaddrLine = makeLineAddress(vaddr);
    Addr paddrLine = makeLineAddress(paddr);

    // Remember that the slice has issued.
    slice->issue();

    if (!this->isPAddrHandledByMe(paddr)) {
      LLC_S_PANIC(dynS->getDynamicStreamId(),
                  "Next address is not handled here %#x.", paddr);
    }

    statistic.numLLCIssueSlice++;

    // Push to the request queue.
    auto reqType = this->getDirectStreamReqType(dynS);
    if (reqType == CoherenceRequestType_GETU) {
      statistic.numLLCSentSlice++;
      S->se->numLLCSentSlice++;
      if (this->hasMergedAsMulticast(dynS)) {
        statistic.numLLCCanMulticastSlice++;
      }
    }
    auto requestIter = this->enqueueRequest(S->getCPUDelegator(), sliceId,
                                            vaddrLine, paddrLine, reqType);

    if (S->isStoreStream()) {
      /**
       * For StoreStream, we build the stored data by extracting overlap
       * region from elements. Notice that we can release any older elements,
       * as later we perform the store in slice granularity, not element
       * granularity. Thus element is not used anymore.
       */
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        assert(dynS->idxToElementMap.count(idx) &&
               "Missing element for StoreStream.");
        const auto &element = dynS->idxToElementMap.at(idx);
        assert(element->isReady() && "StoreElement is not ready.");

        // Compute the overlap and set the data.
        int elementOffset;
        int sliceOffset;
        int overlapSize = element->computeOverlap(
            sliceId.vaddr, sliceId.getSize(), sliceOffset, elementOffset);
        requestIter->dataBlock.setData(element->getUInt8Ptr(elementOffset),
                                       sliceOffset, overlapSize);
        requestIter->storeSize = overlapSize;
        LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                           "Get StoreValue from element %llu, line [%#x, +%d), "
                           "elementOffset %#x.\n",
                           element->idx, sliceId.vaddr + sliceOffset,
                           overlapSize, elementOffset);
      }
    }

    // Check if we track inflyRequests.
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    dynS->inflyRequests++;
    LLC_SLICE_DPRINTF(sliceId, "Issue, InflyRequests + 1 = %d.\n",
                      dynS->inflyRequests);
    /**
     * Try to handle multicast for streams:
     * 1. Has multicast group.
     * 2. No indirect dependent (can be relaxed later).
     */
    if (!hasIndirectDependent && this->controller->isStreamMulticastEnabled()) {
      this->generateMulticastRequest(requestIter, dynS);
    }

  } else {

    /**
     * ! The paddr is not valid. We ignore this slice.
     */
    LLC_SLICE_DPRINTF(sliceId, "Discard due to fault.\n");
    slice->faulted();

    assert(dynS->getIndStreams().empty() &&
           "Faulted stream with indirect streams.");
    statistic.numLLCFaultSlice++;
  }

  // This is also considered issued.
  dynS->prevIssuedCycle = this->controller->curCycle();
  dynS->updateIssueClearCycle();
}

CoherenceRequestType
LLCStreamEngine::getDirectStreamReqType(LLCDynamicStream *stream) const {
  auto reqType = CoherenceRequestType_GETH;
  auto SS = stream->getStaticStream();
  switch (SS->getStreamType()) {
  case ::LLVM::TDG::StreamInfo_Type_AT:
  case ::LLVM::TDG::StreamInfo_Type_ST:
    reqType = CoherenceRequestType_STREAM_STORE;
    break;
  case ::LLVM::TDG::StreamInfo_Type_LD: {
    if (SS->isUpdateStream()) {
      reqType = CoherenceRequestType_STREAM_STORE;
    } else if (SS->isLoadComputeStream()) {
      // LoadComputeStream sends back the computed value.
      reqType = CoherenceRequestType_GETH;
    } else {
      if (auto dynS = SS->getDynamicStream(stream->getDynamicStreamId())) {
        if (dynS->shouldCoreSEIssue()) {
          // We have to send back the data.
          reqType = CoherenceRequestType_GETU;
        }
      } else {
        // The dynamic stream is already released, we don't really care.
      }
    }
    break;
  }
  default:
    panic("Invalid offloaded stream type.\n");
  }
  return reqType;
}

void LLCStreamEngine::issueStreamIndirect(LLCDynamicStream *dynIS) {

  auto element = dynIS->getFirstReadyToIssueElement();
  if (!element) {
    LLC_S_PANIC(dynIS->getDynamicStreamId(),
                "Try to issue, but no ready element.");
  }
  auto elementIdx = element->idx;
  if (dynIS->shouldIssueBeforeCommit()) {
    // We delay issuing this after committed.
    this->generateIndirectStreamRequest(dynIS, element);
  } else {
    LLC_S_DPRINTF(dynIS->getDynamicStreamId(),
                  "Delay Issuing for AfterCommit element %llu\n.", elementIdx);
  }
  // Don't forget to the element issued.
  dynIS->markElementIssued(elementIdx);
}

void LLCStreamEngine::generateIndirectStreamRequest(
    LLCDynamicStream *dynIS, LLCStreamElementPtr element) {

  auto IS = dynIS->getStaticStream();
  if (IS->isReduction()) {
    LLC_S_PANIC(dynIS->getDynamicStreamId(),
                "Reduction is no longer handled here.");
    return;
  }

  if (IS->isStoreComputeStream() || IS->isAtomicComputeStream()) {
    this->issueIndirectStoreOrAtomicRequest(dynIS, element);
    return;
  }

  /**
   * Finally normal indirect load stream.
   */
  this->issueIndirectLoadRequest(dynIS, element);
  return;
}

void LLCStreamEngine::issueIndirectLoadRequest(LLCDynamicStream *dynIS,
                                               LLCStreamElementPtr element) {
  /**
   * This function handles the most basic case: IndirectLoadStream.
   */
  auto elementIdx = element->idx;
  DynamicStreamSliceId sliceId;
  sliceId.getDynStreamId() = dynIS->getDynamicStreamId();
  sliceId.getStartIdx() = elementIdx;
  sliceId.getEndIdx() = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  Addr elementVAddr = element->vaddr;

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticStream();
  auto dynCoreIS = IS->getDynamicStream(dynIS->getDynamicStreamId());

  auto reqType = CoherenceRequestType_GETH;
  if (dynCoreIS && dynCoreIS->shouldCoreSEIssue()) {
    // For LoadComputeStream, we issue GETH and send back the compute result.
    if (!IS->isLoadComputeStream()) {
      reqType = CoherenceRequestType_GETU;
    }
  }
  LLC_SLICE_DPRINTF(sliceId,
                    "Issue IndirectLoad %s VAddr %#x CoreDynS %d "
                    "ShouldCoreSEIssue %d IsLoadCompute %d.\n",
                    CoherenceRequestType_to_string(reqType), elementVAddr,
                    dynCoreIS != nullptr,
                    dynCoreIS ? dynCoreIS->shouldCoreSEIssue() : -1,
                    IS->isLoadComputeStream());

  assert(!dynIS->isPseudoOffload() &&
         "Indirect stream should never be PseudoOffload.");
  auto totalSliceSize = 0;
  auto totalSlices = 0;
  while (totalSliceSize < elementSize) {
    Addr curSliceVAddr = elementVAddr + totalSliceSize;
    // Make sure the slice is contained within one line.
    int lineOffset = curSliceVAddr % blockBytes;
    auto curSliceSize = std::min(elementSize - totalSliceSize,
                                 static_cast<int>(blockBytes) - lineOffset);
    // Here we set the slice vaddr and size.
    sliceId.vaddr = curSliceVAddr;
    sliceId.size = curSliceSize;
    Addr curSlicePAddr;
    if (dynIS->translateToPAddr(curSliceVAddr, curSlicePAddr)) {
      Addr curSliceVAddrLine = makeLineAddress(curSliceVAddr);
      Addr curSlicePAddrLine = makeLineAddress(curSlicePAddr);
      IS->statistic.numLLCIssueSlice++;
      if (reqType == CoherenceRequestType_GETU) {
        IS->statistic.numLLCSentSlice++;
        IS->se->numLLCSentSlice++;
      }

      // Push to the request queue.
      this->enqueueRequest(IS->getCPUDelegator(), sliceId, curSliceVAddrLine,
                           curSlicePAddrLine, reqType);
      dynIS->inflyRequests++;
    } else {
      // For faulted slices, we simply ignore it.
      LLC_SLICE_DPRINTF(sliceId, "Discard due to fault, vaddr %#x.\n",
                        sliceId.vaddr);
      dynIS->getStaticStream()->statistic.numLLCFaultSlice++;
    }

    totalSliceSize += curSliceSize;
    totalSlices++;
  }

  if (IS->isLoadComputeStream() && totalSlices != 1) {
    LLC_S_PANIC(
        dynIS->getDynamicStreamId(),
        "IndirectLoadComputeStream with Multi-Line Element is not supported.");
  }
}

void LLCStreamEngine::issueIndirectStoreOrAtomicRequest(
    LLCDynamicStream *dynIS, LLCStreamElementPtr element) {

  auto elementIdx = element->idx;
  DynamicStreamSliceId sliceId;
  sliceId.getDynStreamId() = dynIS->getDynamicStreamId();
  sliceId.getStartIdx() = elementIdx;
  sliceId.getEndIdx() = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  Addr elementVAddr = element->vaddr;
  LLC_SLICE_DPRINTF(sliceId, "Issue IndirectStore/Atomic VAddr %#x.\n",
                    elementVAddr);

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticStream();
  const auto &indirectConfig = dynIS->configData;

  // This is a store/atomic, we need to issue STREAM_STORE request.
  assert(elementSize <= sizeof(uint64_t) && "Oversized merged store stream.");
  if (dynIS->hasTotalTripCount()) {
    assert(elementIdx < dynIS->getTotalTripCount() &&
           "Try to store beyond TotalTripCount.");
  }

  int lineOffset = elementVAddr % blockBytes;
  assert(lineOffset + elementSize <= blockBytes &&
         "Multi-line merged store stream.");

  sliceId.vaddr = elementVAddr;
  sliceId.size = elementSize;
  Addr elementPAddr;
  if (dynIS->translateToPAddr(elementVAddr, elementPAddr)) {
    IS->statistic.numLLCIssueSlice++;
    auto vaddrLine = makeLineAddress(elementVAddr);
    auto paddrLine = makeLineAddress(elementPAddr);
    /**
     * Compute the store value.
     * If this is a MergededPedicatedStream, it is a constant value.
     * If this is a MergededLoadStoreDepStream, it is computed use the
     * StoreCallback.
     * TODO: These should be merged together.
     */
    uint64_t storeValue = 0;
    if (IS->isMergedPredicated()) {
      // TODO: This is no longer supported.
      panic("MergedPredicated is not supported for now.");
      // storeValue = indirectConfig->constUpdateValue;
    } else if (IS->isMergedLoadStoreDepStream()) {
      // Compute the value.
      auto getBaseStreamValue =
          [&element](uint64_t baseStreamId) -> StreamValue {
        return element->getBaseStreamValue(baseStreamId);
      };
      auto params = convertFormalParamToParam(indirectConfig->storeFormalParams,
                                              getBaseStreamValue);
      storeValue = indirectConfig->storeCallback->invoke(params).front();
    } else {
      assert("Unknow merged stream type.");
    }

    // Push to the request queue.
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore -> RequestQueue, StoreValue %lu.\n",
                       storeValue);
    bool isIdeaStore = false;
    int storeSize = sliceId.size;
    if (this->controller->isStreamIdeaStoreEnabled()) {
      isIdeaStore = true;
    } else if (this->controller->isStreamCompactStoreEnabled()) {
      /**
       * Check if we can compact.
       * This is just an approximation, as the request is sending
       * out immediately.
       * TODO: Implement a realistic compact scheme.
       */
      if (dynIS->prevStorePAddrLine == paddrLine) {
        // We can compact.
        isIdeaStore = true;
      } else {
        // As an overhead, we set StoreSize to 64 due to compaction.
        if (IS->isDirectMemStream()) {
          storeSize = RubySystem::getBlockSizeBytes();
        }
      }
    }

    dynIS->prevStorePAddrLine = paddrLine;
    dynIS->prevStoreCycle = this->controller->curCycle();
    if (isIdeaStore) {
      this->performStore(elementPAddr, elementSize,
                         reinterpret_cast<uint8_t *>(&storeValue));
      LLC_SLICE_DPRINTF_(
          LLCRubyStreamStore, sliceId,
          "Ideal StreamStore done with value %llu, send back StreamAck.\n",
          storeValue);

      const bool forceIdeaAck = true;
      this->issueStreamAckToMLC(sliceId, forceIdeaAck);
      if (!this->requestQueue.empty()) {
        this->scheduleEvent(Cycles(1));
      }
    } else {
      auto reqIter =
          this->enqueueRequest(IS->getCPUDelegator(), sliceId, vaddrLine,
                               paddrLine, CoherenceRequestType_STREAM_STORE);
      dynIS->inflyRequests++;
      auto lineOffset = sliceId.vaddr % RubySystem::getBlockSizeBytes();
      reqIter->dataBlock.setData(reinterpret_cast<uint8_t *>(&storeValue),
                                 lineOffset, sliceId.size);
      reqIter->storeSize = storeSize;
    }

  } else {
    panic("Faulted merged store stream.");
  }
}

LLCStreamEngine::RequestQueueIter LLCStreamEngine::enqueueRequest(
    GemForgeCPUDelegator *cpuDelegator, const DynamicStreamSliceId &sliceId,
    Addr vaddrLine, Addr paddrLine, CoherenceRequestType type) {
  this->requestQueue.emplace_back(sliceId, paddrLine, type);
  auto requestQueueIter = std::prev(this->requestQueue.end());
  // To match with TLB interface, we first create a fake packet.
  auto tc = cpuDelegator->getSingleThreadContext();
  RequestPtr req = std::make_shared<Request>(paddrLine, sliceId.getSize(), 0,
                                             cpuDelegator->dataMasterId());
  // Set the vaddrLine as this is what we want to translate.
  req->setVirt(vaddrLine);
  // Simply always read request, since this is a fake request.
  auto pkt = Packet::createRead(req);
  // Do not allocate data for this fake packet.
  uint8_t *pktData = nullptr;
  pkt->dataStatic(pktData);
  // Start the translation.
  LLC_SLICE_DPRINTF(sliceId, "Enqueue %s Req: Start Translation.\n",
                    CoherenceRequestType_to_string(type));
  this->translationBuffer->addTranslation(pkt, tc, requestQueueIter);
  // Since this generates a request, we schedule a wakeup.
  this->scheduleEvent(Cycles(1));
  return requestQueueIter;
}

void LLCStreamEngine::translationCallback(PacketPtr pkt, ThreadContext *tc,
                                          RequestQueueIter reqIter) {
  assert(!reqIter->translationDone && "Translation already done.");
  reqIter->translationDone = true;
  LLC_SLICE_DPRINTF(reqIter->sliceId, "Translated %s Req.\n",
                    CoherenceRequestType_to_string(reqIter->requestType));
  // Remember to release the pkt.
  delete pkt;
}

void LLCStreamEngine::issueStreamRequestToLLCBank(const LLCStreamRequest &req) {
  const auto &sliceId = req.sliceId;
  const auto paddrLine = req.paddrLine;
  auto selfMachineId = this->controller->getMachineID();
  auto destMachineId = selfMachineId;
  bool handledHere = this->isPAddrHandledByMe(req.paddrLine);
  if (handledHere) {
    LLC_SLICE_DPRINTF(
        sliceId, "Issue [local] %s request vaddr %#x paddrLine %#x value %s.\n",
        CoherenceRequestType_to_string(req.requestType), sliceId.vaddr,
        paddrLine, req.dataBlock);
  } else {
    destMachineId = this->mapPaddrToLLCBank(paddrLine);
    LLC_SLICE_DPRINTF(sliceId, "Issue [remote] %s request to LLC%d value %s.\n",
                      CoherenceRequestType_to_string(req.requestType),
                      destMachineId.num, req.dataBlock);
  }

  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = req.requestType;
  msg->m_XXNewRewquestor.add(
      MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                sliceId.getDynStreamId().coreId));
  msg->m_Destination.add(destMachineId);
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_sliceIds.add(sliceId);

  // We need to set hold the store value.
  if (req.requestType == CoherenceRequestType_STREAM_STORE) {
    msg->m_streamStoreBlk = req.dataBlock;
    if (req.storeSize > 8) {
      // We model this as a whole cache line put back.
      msg->m_MessageSize = MessageSizeType_Response_Data;
    }
  } else if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
    msg->m_DataBlk = req.dataBlock;
    msg->m_sendToStreamId = req.forwardToStreamId;
    /**
     * We model special size for StreamForward request.
     */
    msg->m_MessageSize = this->controller->getMessageSizeType(req.payloadSize);
  }

  if (Debug::LLCRubyStreamMulticast && !req.multicastSliceIds.empty()) {
    std::stringstream ss;
    for (const auto &multicastSliceId : req.multicastSliceIds) {
      auto mlcMachineID =
          MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                    multicastSliceId.getDynStreamId().coreId);
      ss << ' ' << mlcMachineID;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast to %s.\n",
                       ss.str());
  }

  for (const auto &multicastSliceId : req.multicastSliceIds) {
    // TODO: We should really also pass on the sliceId.
    auto mlcMachineID =
        MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                  multicastSliceId.getDynStreamId().coreId);
    msg->m_XXNewRewquestor.add(mlcMachineID);
    msg->m_sliceIds.add(multicastSliceId);
  }

  if (handledHere) {
    // Quick path for StreamForward to myself.
    if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
      this->receiveStreamForwardRequest(*msg);
      return;
    }
    Cycles latency(1);
    this->streamIssueMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
  } else {
    Cycles latency(1);
    this->streamIndirectIssueMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
  }
}

LLCStreamEngine::ResponseMsgPtr LLCStreamEngine::createStreamMsgToMLC(
    const DynamicStreamSliceId &sliceId, CoherenceResponseType type,
    Addr paddrLine, const uint8_t *data, int dataSize, int payloadSize,
    int lineOffset) {
  auto selfMachineId = this->controller->getMachineID();
  MachineID mlcMachineId(static_cast<MachineType>(selfMachineId.type - 1),
                         sliceId.getDynStreamId().coreId);

  auto msg = std::make_shared<ResponseMsg>(this->controller->clockEdge());
  // For StreamAck, we do not care about the address?
  msg->m_addr = paddrLine;
  msg->m_Type = type;
  msg->m_Sender = selfMachineId;
  msg->m_Destination.add(mlcMachineId);
  msg->m_MessageSize = MessageSizeType_Response_Control;
  msg->m_sliceIds.add(sliceId);
  // Try to copy data.
  if (data) {
    assert(lineOffset + dataSize <= RubySystem::getBlockSizeBytes());
    msg->m_DataBlk.setData(data, lineOffset, dataSize);
    msg->m_MessageSize = this->controller->getMessageSizeType(payloadSize);
  }
  return msg;
}

void LLCStreamEngine::issueStreamMsgToMLC(ResponseMsgPtr msg, bool forceIdea) {

  auto mlcMachineId = msg->m_Destination.singleElement();
  const auto &sliceId = msg->m_sliceIds.singleSliceId();

  if (this->controller->isStreamIdeaAckEnabled() || forceIdea) {
    auto mlcController =
        AbstractStreamAwareController::getController(mlcMachineId);
    auto mlcSE = mlcController->getMLCStreamEngine();
    // StreamAck is also disguised as StreamData.
    mlcSE->receiveStreamData(*msg);
    LLC_SLICE_DPRINTF(sliceId, "Send ideal %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  } else {
    /**
     * This should match with LLC controller l2_response_latency.
     * TODO: Really get this value from the controller.
     */
    Cycles latency(2);
    this->streamResponseMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
    LLC_SLICE_DPRINTF(sliceId, "Send %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  }
}

void LLCStreamEngine::issueStreamAckToMLC(const DynamicStreamSliceId &sliceId,
                                          bool forceIdea) {

  // For StreamAck, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_ACK, paddrLine, nullptr, 0, 0, 0);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDoneToMLC(const DynamicStreamSliceId &sliceId,
                                           bool forceIdea) {

  // For StreamDone, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_DONE, paddrLine, nullptr, 0, 0, 0);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamRangesToMLC() {
  if (!this->controller->isStreamRangeSyncEnabled()) {
    return;
  }
  for (auto stream : this->streams) {
    auto &rangeBuilder = stream->getRangeBuilder();
    if (!rangeBuilder->hasReadyRanges()) {
      continue;
    }
    auto range = rangeBuilder->popReadyRange();
    LLC_SE_DPRINTF_(StreamRangeSync, "Issue range to MLC: %s.\n", *range);
    this->issueStreamRangeToMLC(range);
  }
}

void LLCStreamEngine::issueStreamRangeToMLC(DynamicStreamAddressRangePtr &range,
                                            bool forceIdea) {
  // Create a fake paddr and slice id.
  Addr paddrLine = 0;
  DynamicStreamSliceId sliceId;
  sliceId.elementRange = range->elementRange;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_RANGE, paddrLine, nullptr, 0, 0, 0);
  msg->m_range = range;
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToMLC(const DynamicStreamSliceId &sliceId,
                                           Addr paddrLine, const uint8_t *data,
                                           int dataSize, int payloadSize,
                                           int lineOffset, bool forceIdea) {
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_DATA_EXCLUSIVE, paddrLine, data, dataSize,
      payloadSize, lineOffset);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToLLC(
    LLCDynamicStreamPtr stream, const DynamicStreamSliceId &sliceId,
    const DataBlock &dataBlock, const CacheStreamConfigureDataPtr &recvConfig,
    int payloadSize) {
  /**
   * Unlike sending data to MLC, we have to calculate the virtual address of the
   * receiving stream and translate that.
   * Also, we can only handle the simpliest case so far: no spliting, and no
   * multi-line receiver element.
   */
  auto elementIdx = sliceId.getStartIdx();
  auto recvElementVAddr =
      recvConfig->addrGenCallback
          ->genAddr(elementIdx, recvConfig->addrGenFormalParams,
                    getStreamValueFail)
          .front();
  auto recvElementVAddrEnd = recvElementVAddr + recvConfig->elementSize;
  // Check that receiver does not across lines.
  for (auto idx = sliceId.getStartIdx() + 1; idx < sliceId.getEndIdx(); ++idx) {
    auto vaddr =
        recvConfig->addrGenCallback
            ->genAddr(idx, recvConfig->addrGenFormalParams, getStreamValueFail)
            .front();
    auto vaddrEnd = vaddr + recvConfig->elementSize;
    recvElementVAddr = std::min(recvElementVAddr, vaddr);
    recvElementVAddrEnd = std::max(recvElementVAddrEnd, vaddrEnd);
  }
  auto recvElementVAddrLine = makeLineAddress(recvElementVAddr);
  auto recvElementVAddrEndLine = makeLineAddress(recvElementVAddr);
  if (recvElementVAddrLine != recvElementVAddrEndLine) {
    LLC_SLICE_PANIC(sliceId, "Multiline StreamForward Receiver: %s.",
                    recvConfig->dynamicId);
  }
  Addr recvElementPAddrLine;
  if (stream->translateToPAddr(recvElementVAddrLine, recvElementPAddrLine)) {
    // Now we enqueue the translation request.
    auto reqIter = this->enqueueRequest(
        recvConfig->stream->getCPUDelegator(), sliceId, recvElementVAddrLine,
        recvElementPAddrLine, CoherenceRequestType_STREAM_FORWARD);
    // Remember the receiver dynamic id and forwarded data block.
    reqIter->forwardToStreamId = recvConfig->dynamicId;
    reqIter->dataBlock = dataBlock;
    reqIter->payloadSize = payloadSize;
  } else {
    LLC_SLICE_PANIC(sliceId, "Translation fault on the ReceiverStream: %s.",
                    recvConfig->dynamicId);
  }
}

void LLCStreamEngine::findMigratingStreams() {
  // Scan all streams for migration target.
  auto streamIter = this->streams.begin();
  auto streamEnd = this->streams.end();
  while (streamIter != streamEnd) {
    auto stream = *streamIter;
    if (this->canMigrateStream(stream)) {
      this->migratingStreams.emplace_back(stream);
      streamIter = this->streams.erase(streamIter);
    } else {
      ++streamIter;
    }
  }
}

void LLCStreamEngine::migrateStreams() {
  auto streamIter = this->migratingStreams.begin();
  auto streamEnd = this->migratingStreams.end();
  int migrated = 0;
  while (streamIter != streamEnd && migrated < this->migrateWidth) {
    auto stream = *streamIter;
    assert(this->canMigrateStream(stream) && "Can't migrate stream.");
    this->migrateStream(stream);
    streamIter = this->migratingStreams.erase(streamIter);
    migrated++;
  }
}

void LLCStreamEngine::migrateStream(LLCDynamicStream *stream) {

  // Create the migrate request.
  Addr vaddr = stream->peekNextAllocVAddr();
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Migrating streams should have valid paddr.");
  Addr paddrLine = makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLC(paddrLine, selfMachineId.type);

  LLC_S_DPRINTF(
      stream->getDynamicStreamId(),
      "Migrate to LLC%d, InflyReq %d AdvancedMigration %d IndirectS %d.\n",
      addrMachineId.num, stream->inflyRequests,
      this->controller->isStreamAdvanceMigrateEnabled(),
      stream->getIndStreams().size());

  auto msg =
      std::make_shared<StreamMigrateRequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  msg->m_MessageSize = MessageSizeType_Data;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  this->removeStreamFromMulticastTable(stream);

  stream->migratingStart();
}

void LLCStreamEngine::migrateStreamCommit(LLCDynamicStream *stream,
                                          Addr paddr) {
  // Create the migrate request.
  Addr paddrLine = makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLC(paddrLine, selfMachineId.type);

  LLC_S_DPRINTF_(StreamRangeSync, stream->getDynamicStreamId(),
                 "[Commit] Migrate to LLC%d.\n", addrMachineId.num);

  auto msg =
      std::make_shared<StreamMigrateRequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  // Migrating CommitHead is just a control message.
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_IsCommit = true;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));
}

MachineID LLCStreamEngine::mapPaddrToLLCBank(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLC(paddr, selfMachineId.type);
  return addrMachineId;
}

bool LLCStreamEngine::isPAddrHandledByMe(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLC(paddr, selfMachineId.type);
  return addrMachineId == selfMachineId;
}

void LLCStreamEngine::print(std::ostream &out) const {}

void LLCStreamEngine::receiveStreamIndirectRequest(const RequestMsg &req) {

  this->initializeTranslationBuffer();

  // Simply copy and inject the msg to L1 request in.
  const auto &sliceId = req.m_sliceIds.singleSliceId();
  assert(sliceId.isValid() && "Invalid stream slice for indirect request.");

  LLC_SLICE_DPRINTF(
      sliceId, "Receive [indirect] %s request paddrLine %#x delay cycle %s.\n",
      CoherenceRequestType_to_string(req.m_Type), req.m_addr,
      this->controller->curCycle() -
          this->controller->ticksToCycles(req.getTime()));

  if (req.m_Type == CoherenceRequestType_STREAM_FORWARD) {
    // Quick pass for stream forwarding.
    this->receiveStreamForwardRequest(req);
    return;
  }

  auto msg = std::make_shared<RequestMsg>(req);
  Cycles latency(1);
  this->streamIssueMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                      this->controller->cyclesToTicks(latency));
}

void LLCStreamEngine::receiveStreamForwardRequest(const RequestMsg &req) {
  this->processStreamForwardRequest(req);
}

void LLCStreamEngine::processStreamForwardRequest(const RequestMsg &req) {

  const auto &sliceId = req.m_sliceIds.singleSliceId();
  const auto &recvDynId = req.m_sendToStreamId;
  // Search through the direct streams.
  auto dynS = LLCDynamicStream::getLLCStream(recvDynId);
  if (!dynS) {
    // The stream must be terminated.
    LLC_SLICE_DPRINTF(sliceId, "Cannot find the direct receiver: %s.",
                      recvDynId);
    return;
  }
  /**
   * Normally we search for the receiver in myself and my indirect stream.
   * However, there is a special case: I am the sender!
   * This is used so far to implement IndirectReductionS that dependent both
   * on the BackBaseIndirectS and BackBaseDirectS:
   *
   * BaseBaseDirectS -> BackBaseIndirectS -> IndirectReductionS.
   *  |                                              |
   *  ----------------------->>>---------------------
   *
   * In such case, we only search in my Two-Level IndirectS...
   */
  bool foundReceiver = false;
  if (sliceId.getDynStreamId() != dynS->getDynamicStreamId()) {
    // Search for receiver in myself and my indirect streams.
    if (dynS->isBasedOn(sliceId.getDynStreamId())) {
      foundReceiver = true;
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        dynS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
      }
    }

    for (auto dynIS : dynS->getIndStreams()) {
      if (dynIS->isBasedOn(sliceId.getDynStreamId())) {
        foundReceiver = true;
        for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
             ++idx) {
          dynIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
        }
      }
    }
  } else {
    // Sender is myself. Search for Two-Level Indirection.
    for (auto dynIS : dynS->getIndStreams()) {
      for (auto dynIIS : dynIS->getIndStreams()) {
        if (dynIIS->isBasedOn(sliceId.getDynStreamId())) {
          foundReceiver = true;
          for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
               ++idx) {
            dynIIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
          }
        }
      }
    }
  }
  if (!foundReceiver) {
    LLC_SLICE_PANIC(sliceId, "Cannot find the receiver: %s.", recvDynId);
  }
}

void LLCStreamEngine::triggerIndirectElement(LLCDynamicStreamPtr stream,
                                             LLCStreamElementPtr element) {
  if (stream->getIndStreams().empty() && stream->predicatedStreams.empty()) {
    // There is no stream dependent on my data.
    return;
  }

  auto idx = element->idx;
  assert(element->isReady());

  // First we handle any indirect element.
  for (auto IS : stream->getIndStreams()) {

    /**
     * If the indirect stream is behind one iteration, base element of
     * iteration i should trigger the indirect element of iteration i + 1.
     * Also we should be careful to not overflow the boundary.
     */
    auto indirectElementIdx = idx;
    if (IS->isOneIterationBehind()) {
      indirectElementIdx = idx + 1;
    }
    auto indirectTripCount = IS->configData->totalTripCount;
    if (indirectTripCount != -1 && indirectElementIdx > indirectTripCount) {
      // Ignore overflow elements.
      continue;
    }

    // We should have the element.
    if (!IS->idxToElementMap.count(indirectElementIdx)) {
      LLC_S_PANIC(IS->getDynamicStreamId(), "Missing IndirectElement %llu.",
                  indirectElementIdx);
    }

    auto &indirectElement = IS->idxToElementMap.at(indirectElementIdx);

    /**
     * Check if the stream has predication.
     */
    assert(!IS->isPredicated() && "Disable predication for now.");
    // if (IS->isPredicated()) {
    //   assert(!IS->isOneIterationBehind() && "How to handle this?");
    //   // Push the element to the predicate list.
    //   // We add the element to the predicateElements.
    //   IS->predicateStream->waitingPredicatedElements
    //       .emplace(std::piecewise_construct, std::forward_as_tuple(idx),
    //                std::forward_as_tuple())
    //       .first->second.emplace_back(IS, element);
    // }
    // Not predicated, add to readyElements.
    if (stream->baseStream) {
      // The only type of two-level indirection is IndirectReduction.
      if (!IS->getStaticStream()->isReduction()) {
        LLC_S_PANIC(
            IS->getDynamicStreamId(),
            "Does not support Two-Level Indirection other than Reduction.");
      }
    }
    LLC_S_DPRINTF(IS->getDynamicStreamId(),
                  "Check if element %llu BaseElementsReady %d.\n",
                  indirectElement->idx,
                  indirectElement->areBaseElementsReady());
    if (indirectElement->areBaseElementsReady()) {
      if (IS->getStaticStream()->isReduction()) {
        // Reduction now is handled as computation.
        this->pushReadyComputation(indirectElement);
      } else {
        IS->markElementReadyToIssue(indirectElementIdx);
      }
    } else {
      for (const auto &baseE : indirectElement->baseElements) {
        LLC_S_DPRINTF(IS->getDynamicStreamId(),
                      "BaseElements Ready %d %s %llu.\n", baseE->isReady(),
                      baseE->dynStreamId, baseE->idx);
      }
    }
  }

  // Now we handle any predication.
  assert(!stream->configData->predCallback && "Disable predication for now.");
  // if (stream->configData->predCallback) {
  //   GetStreamValueFunc getStreamValue =
  //       [&element, stream](uint64_t streamId) -> StreamValue {
  //     assert(streamId == stream->getStaticId() &&
  //            "Mismatch stream id for predication.");
  //     StreamValue v;
  //     v.front() = element->getUInt64();
  //     return v;
  //   };
  //   auto params = convertFormalParamToParam(
  //       stream->configData->predFormalParams, getStreamValue);
  //   bool predicatedTrue =
  //       stream->configData->predCallback->invoke(params).front() & 0x1;
  //   auto predicatedIter = stream->waitingPredicatedElements.find(idx);
  //   if (predicatedIter != stream->waitingPredicatedElements.end()) {
  //     for (auto &predEntry : predicatedIter->second) {
  //       auto dynPredS = predEntry.first;
  //       auto predS = dynPredS->getStaticStream();
  //       auto &predBaseElement = predEntry.second;
  //       LLC_S_DPRINTF(stream->getDynamicStreamId(), "Predicate %d %d: %s.\n",
  //                     predicatedTrue, dynPredS->isPredicatedTrue(),
  //                     dynPredS->getDynamicStreamId());
  //       if (dynPredS->isPredicatedTrue() == predicatedTrue) {
  //         predS->statistic.numLLCPredYSlice++;
  //         // Predicated match, add to ready list.
  //         if (stream->baseStream) {
  //           /**
  //            * The predication is from an indirect stream, this is for
  //            * pattern: if (a[b[i]]) c[xx]; Since this is an indirect
  //            * stream, it is likely that we are in a remote LLC bank where
  //            * a[b[i]] is sitting. We would like to directly generate the
  //            * address and inject to the requestQueue here.
  //            */
  //           this->generateIndirectStreamRequest(dynPredS, idx);
  //         } else {
  //           /**
  //            * The predication is from a direct stream, this is for pattern:
  //            * if (a[i]) b[i];
  //            * There is no data dependence between these two streams.
  //            * In such case we add to readyIndirectElements and waiting to
  //            * be issued.
  //            */
  //           dynPredS->markElementReadyToIssue(idx);
  //         }
  //       } else {
  //         // This element is predicated off.
  //         predS->statistic.numLLCPredNSlice++;
  //         if (predS->isMerged() && predS->isStoreStream()) {
  //           /**
  //            * This is a predicated off merged store, we have to send
  //            * STREAM_ACK. We still have to set the vaddr as the MLC
  //            * requires it to match.
  //            */
  //           auto dynBS = dynPredS->baseStream;
  //           assert(dynBS && "MergedStore stream should have base stream.");
  //           DynamicStreamSliceId sliceId;
  //           sliceId.getDynStreamId() = dynPredS->getDynamicStreamId();
  //           sliceId.getStartIdx() = idx;
  //           sliceId.getEndIdx() = idx + 1;
  //           auto getBaseStreamValue =
  //               [&predBaseElement,
  //                dynBS](uint64_t baseStreamId) -> StreamValue {
  //             assert(baseStreamId == dynBS->getStaticId() &&
  //                    "Invalid baseStreamId.");
  //             assert(predBaseElement->isReady());
  //             assert(predBaseElement->size <= 8);
  //             StreamValue v;
  //             v.front() = predBaseElement->getUInt64();
  //             return v;
  //           };
  //           auto &predConfig = dynPredS->configData;
  //           Addr elementVAddr =
  //               predConfig->addrGenCallback
  //                   ->genAddr(idx, predConfig->addrGenFormalParams,
  //                             getBaseStreamValue)
  //                   .front();
  //           sliceId.vaddr = elementVAddr;
  //           sliceId.size = dynPredS->getMemElementSize();
  //           LLC_SLICE_DPRINTF_(
  //               LLCRubyStreamStore, sliceId,
  //               "StreamStore predicated off, send back StreamAck.\n");
  //           this->issueStreamAckToMLC(sliceId);
  //         }
  //       }
  //     }
  //     stream->waitingPredicatedElements.erase(predicatedIter);
  //   }

  // } else {
  assert(stream->waitingPredicatedElements.empty() &&
         "No predCallback for predicated elements.");
  // }
}

void LLCStreamEngine::triggerUpdate(LLCDynamicStreamPtr stream,
                                    LLCStreamElementPtr element,
                                    const DataBlock &storeValueBlock,
                                    DataBlock &loadValueBlock) {

  auto S = stream->getStaticStream();

  // Perform the operation.
  auto elementMemSize = S->getMemElementSize();
  auto elementCoreSize = S->getCoreElementSize();
  assert(elementCoreSize <= elementMemSize &&
         "CoreElementSize should not exceed MemElementSize.");
  auto elementVAddr = element->vaddr;

  // Create a single slice.
  DynamicStreamSliceId sliceId;
  sliceId.getDynStreamId() = stream->getDynamicStreamId();
  sliceId.getStartIdx() = element->idx;
  sliceId.getEndIdx() = element->idx + 1;

  Addr elementPAddr;
  assert(stream->translateToPAddr(elementVAddr, elementPAddr) &&
         "Fault on vaddr of LLCStore/Atomic/UpdateStream.");
  auto lineOffset = elementVAddr % RubySystem::getBlockSizeBytes();

  if (S->isAtomicStream()) {
    // Very limited AtomicRMW support.
    auto loadedValue =
        this->performStreamAtomicOp(stream, element, elementPAddr, sliceId);
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "Perform StreamAtomic, RetValue %llu.\n", loadedValue);
    loadValueBlock.setData(reinterpret_cast<uint8_t *>(&loadedValue),
                           lineOffset, elementCoreSize);
    if (element->hasFirstIndirectAtomicReqSeen()) {
      LLC_ELEMENT_PANIC(element, "Perform atomic operation more than once.");
    }
    element->setFirstIndirectAtomicReqSeen();
  } else {
    // This is an update stream.
    auto getStreamValue = [&element](uint64_t streamId) -> StreamValue {
      return element->getBaseStreamValue(streamId);
    };
    auto params = convertFormalParamToParam(
        stream->configData->storeFormalParams, getStreamValue);
    auto storeValue = stream->configData->storeCallback->invoke(params);
    assert(elementMemSize <= sizeof(storeValue) &&
           "UpdateStream size overflow.");
    this->performStore(elementPAddr, elementMemSize, storeValue.uint8Ptr());
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamUpdate done with value %s.\n", storeValue);
  }
}

LLCStreamSlicePtr LLCStreamEngine::allocateSlice(LLCDynamicStreamPtr dynS) {
  auto slice = dynS->allocNextSlice(this);
  this->allocatedSlices.push_back(slice);
  return slice;
}

LLCStreamSlicePtr
LLCStreamEngine::tryGetSlice(const DynamicStreamSliceId &sliceId) {
  for (auto &slice : this->allocatedSlices) {
    const auto &id = slice->getSliceId();
    /**
     * We have additional check for the vaddr in case for multi-line elements.
     */
    if (id == sliceId && id.vaddr == sliceId.vaddr) {
      return slice;
    }
  }
  return nullptr;
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::releaseSlice(SliceList::iterator sliceIter) {
  const auto &slice = *sliceIter;
  LLC_SLICE_DPRINTF(slice->getSliceId(), "Released.\n");
  slice->released();
  const auto &sliceId = slice->getSliceId();
  if (auto dynS = LLCDynamicStream::getLLCStream(sliceId.getDynStreamId())) {
    while (!dynS->idxToElementMap.empty()) {
      auto elementIter = dynS->idxToElementMap.begin();
      auto &element = elementIter->second;
      if (element->isReady() && element->areSlicesReleased()) {
        if (!element->areBaseElementsReady()) {
          LLC_ELEMENT_PANIC(
              element, "Released when Ready %d ValueBaseReady %d Slices %d.",
              element->isReady(), element->areBaseElementsReady(),
              element->getNumSlices());
        }
        /**
         * We avoid releasing the element if it is the only one left
         * in idxToElementMap and it is known not the last one. This
         * is to avoid a bug when there are multi-line elements, the
         * next slice is not initialized yet, thus the element has not
         * seen all the slices and may falsely return true for
         * areSlicesReleased().
         * TODO: Handle this multi-line elements more elegantly.
         */
        if (dynS->idxToElementMap.size() > 1 ||
            (dynS->hasTotalTripCount() &&
             element->idx + 1 >= dynS->getTotalTripCount())) {
          dynS->eraseElement(elementIter);
          continue;
        }
      }
      break;
    }
  }
  return this->allocatedSlices.erase(sliceIter);
}

void LLCStreamEngine::processSlices() {
  auto iter = this->allocatedSlices.begin();
  auto end = this->allocatedSlices.end();
  while (iter != end) {
    iter = this->processSlice(iter);
  }
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::processSlice(SliceList::iterator sliceIter) {
  auto &slice = *sliceIter;
  auto dynS =
      LLCDynamicStream::getLLCStream(slice->getSliceId().getDynStreamId());
  if (!dynS) {
    // Jesus, the LLCStream is already released.
    switch (slice->getState()) {
    default:
      LLC_SLICE_PANIC(slice->getSliceId(),
                      "LLCStream released, but slice not.");
    case LLCStreamSlice::State::ALLOCATED:
    case LLCStreamSlice::State::RESPONDED:
    case LLCStreamSlice::State::FAULTED:
      return this->releaseSlice(sliceIter);
    case LLCStreamSlice::State::ISSUED:
      // We are still waiting for the response.
      return ++sliceIter;
    }
  }
  switch (slice->getState()) {
  default:
    LLC_SLICE_PANIC(slice->getSliceId(), "Invalid state.");
  case LLCStreamSlice::State::ALLOCATED:
  case LLCStreamSlice::State::ISSUED:
    // We are still waiting for the response.
    return ++sliceIter;
  case LLCStreamSlice::State::FAULTED:
    return this->releaseSlice(sliceIter);
  case LLCStreamSlice::State::RESPONDED:
    break;
  }
  /**
   * The slice is already responded, see if we can process it.
   * So far we need to process the slice for these two cases:
   * 1. AtomicComputeStream/UpdateStream.
   * This is where the write request is generated, and is done after all
   * elements are committed in the core (if RangeSync enabled).
   * 2. LoadComputeStream.
   * This is where we schedule the computation for LoadComputeStream, and
   * send back the result to core if core needs the value. This does not
   * need to wait for committment.
   */

  const auto &sliceId = slice->getSliceId();
  auto S = dynS->getStaticStream();
  /**
   * For LoadComputeStream, we schedule computation if the element is value
   * ready. If all element's LoadComputeValue is ready, we send back to core.
   * Also, we have to wait until the LoadComputeValue sent back to core before
   * releasing the slice.
   */
  if (S->isLoadComputeStream()) {
    this->processLoadComputeSlice(dynS, slice);
    if (!slice->isLoadComputeValueSent()) {
      return ++sliceIter;
    }
  }
  /**
   * If this stream require RangeSync, we have to check that all elements are
   * committed in the core.
   * One exception is for IndirectLoadComputeStream, which we should release
   * immediately.
   */
  if (dynS->shouldRangeSync() &&
      !(S->isLoadComputeStream() && dynS->isIndirect())) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElementPanic(idx, "Check element committed for update.");
      if (!element->hasCoreCommitted()) {
        // We are still waiting for the core to commit.
        return ++sliceIter;
      }
    }
  }
  if (S->isAtomicComputeStream() || S->isUpdateStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElementPanic(idx, "Check base elements ready for update.");
      // LLC_SLICE_DPRINTF(
      //     sliceId, "Process for element %llu, Ready %d, BaseReady %d.\n",
      //     element->idx, element->isReady(), element->areBaseElementsReady());
      if (!element->areBaseElementsReady()) {
        // We are still waiting for base elements.
        return ++sliceIter;
      }
    }
    // We can finally process it.
    this->processAtomicOrUpdateSlice(dynS, sliceId, slice->getStoreBlock());
  }

  /**
   * We are done with this slice.
   * If this is a StoreStream with RangeSync, we send back the Ack here.
   * TODO: This duplicated the total traffic, as we really only need one
   * TODO: StreamDone message.
   */
  if (dynS->shouldRangeSync() && S->isStoreComputeStream()) {
    this->issueStreamAckToMLC(sliceId);
  }
  return this->releaseSlice(sliceIter);
}

void LLCStreamEngine::processLoadComputeSlice(LLCDynamicStreamPtr dynS,
                                              LLCStreamSlicePtr slice) {
  const auto &sliceId = slice->getSliceId();
  // Schedule the computation.
  bool allLoadComputeValueReady = true;
  for (auto elementIdx = sliceId.getStartIdx();
       elementIdx < sliceId.getEndIdx(); ++elementIdx) {
    auto element = dynS->getElementPanic(elementIdx, "ProcessLoadComputeSlice");
    if (element->isReady() && !element->isComputationScheduled() &&
        !element->isLoadComputeValueReady()) {
      this->pushReadyComputation(element);
    }
    if (!element->isLoadComputeValueReady()) {
      allLoadComputeValueReady = false;
    }
  }
  if (!allLoadComputeValueReady) {
    return;
  }
  // We can send back the LoadComputeValue back to core.
  // It is actually quite tricky to slice for LoadComputeStream.
  if (sliceId.getNumElements() > 1) {
    LLC_SLICE_PANIC(sliceId, "Multi-Element Slice for LoadComputeStream.");
  }

  auto S = dynS->getStaticStream();
  bool coreNeedValue = false;
  auto dynCoreS = S->getDynamicStream(dynS->getDynamicStreamId());
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  Addr paddr = 0;
  assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
  auto paddrLine = makeLineAddress(paddr);
  DataBlock loadValueBlock;
  int payloadSize = 0;
  for (auto elementIdx = sliceId.getStartIdx();
       elementIdx < sliceId.getEndIdx(); ++elementIdx) {
    auto element = dynS->getElementPanic(elementIdx, "ProcessLoadComputeSlice");
    const auto &loadComputeValue = element->getLoadComputeValue();

    int sliceOffset;
    int elementOffset;
    int overlapSize =
        element->computeOverlap(sliceId.vaddr, RubySystem::getBlockSizeBytes(),
                                sliceOffset, elementOffset);
    payloadSize += S->getCoreElementSize();

    /**
     * Copy the value from LoadComputeValue to LoadValueBlock.
     * For simplicity we just copy MemElementSize, but the real data size should
     * be CoreElementSize. But this is OK as long as the user only uses the
     * first CoreElementSize bytes' data.
     */
    auto valuePtr = loadComputeValue.uint8Ptr(elementOffset);
    loadValueBlock.setData(valuePtr, sliceOffset, overlapSize);
  }

  // TotalOverlapSize should never exceed the line size.
  if (payloadSize > RubySystem::getBlockSizeBytes()) {
    payloadSize = RubySystem::getBlockSizeBytes();
  }

  if (coreNeedValue) {
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(), payloadSize /* payloadSize */,
        0 /* Line offset */);
    S->statistic.numLLCSentSlice++;
    S->se->numLLCSentSlice++;
    LLC_SLICE_DPRINTF(
        sliceId,
        "Send LoadComputeValue to MLC: PAddrLine %#x Data %s PayloadSize %d.\n",
        paddrLine, loadValueBlock, payloadSize);
  } else {
    LLC_SLICE_DPRINTF(sliceId,
                      "Not send LoadComputeValue to MLC: PAddrLine %#x Data %s "
                      "PayloadSize %d.\n",
                      paddrLine, loadValueBlock, payloadSize);
  }

  /**
   * Send the data to receiver stream.
   */
  for (const auto &recvConfig : dynS->sendToConfigs) {
    LLC_SLICE_DPRINTF(
        sliceId,
        "Send LoadComputeValue to ReceiverStream: %s Data %s PayloadSize %d.\n",
        recvConfig->dynamicId, loadValueBlock, payloadSize);
    this->issueStreamDataToLLC(dynS, sliceId, loadValueBlock, recvConfig,
                               payloadSize);
  }
  slice->setLoadComputeValueSent();
}

void LLCStreamEngine::processAtomicOrUpdateSlice(
    LLCDynamicStreamPtr dynS, const DynamicStreamSliceId &sliceId,
    const DataBlock &storeValueBlock) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  auto S = dynS->getStaticStream();
  bool coreNeedValue = false;
  auto dynCoreS = S->getDynamicStream(dynS->getDynamicStreamId());
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  /**
   * Speical case for the second request for IndirectAtomicStream with core
   * usage. We just need to send back an Ack.
   */
  if (dynS->isIndirect() && S->isAtomicComputeStream()) {
    auto elementIdx = sliceId.getStartIdx();
    auto element = dynS->getElementPanic(
        elementIdx, "Check IndirectAtomicElement second request.");
    if (element->hasFirstIndirectAtomicReqSeen()) {
      // This is the second time, we just send back an Ack.
      LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                         "[Commit] Atomic released.\n");
      this->issueStreamAckToMLC(sliceId);
      // We should release the element now.
      return;
    }
  }

  // The final value return to the core.
  DataBlock loadValueBlock;
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto element =
        dynS->getElementPanic(idx, "Process slice of Atomic/UpdateStream");
    LLC_SLICE_DPRINTF(sliceId, "TriggerUpdate for element %llu vaddr %#x.\n",
                      element->idx, element->vaddr);
    if (!element->isReady()) {
      // Not ready yet. Break.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu not ready while we are triggering update.",
                      idx);
    }
    if (!element->areBaseElementsReady()) {
      // We are still waiting for base elements.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu has base element not ready when updating.",
                      idx);
    }
    this->triggerUpdate(dynS, element, storeValueBlock, loadValueBlock);
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(),
        RubySystem::getBlockSizeBytes() /* payloadSizse */,
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  } else {
    this->issueStreamAckToMLC(sliceId);
  }
}

void LLCStreamEngine::performStore(Addr paddr, int size, const uint8_t *value) {
  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support store stream without BackingStore.");
  assert((paddr % RubySystem::getBlockSizeBytes()) + size <=
             RubySystem::getBlockSizeBytes() &&
         "Can not store to multi-line elements.");
  RequestPtr req =
      std::make_shared<Request>(paddr, size, 0 /* Flags */, 0 /* MasterId */);
  PacketPtr pkt = Packet::createWrite(req);
  pkt->dataStaticConst(value);
  rubySystem->getPhysMem()->functionalAccess(pkt);
  delete pkt;
}

uint64_t LLCStreamEngine::performStreamAtomicOp(
    LLCDynamicStreamPtr dynS, LLCStreamElementPtr element, Addr elementPAddr,
    const DynamicStreamSliceId &sliceId) {
  assert(sliceId.getNumElements() == 1 &&
         "Can not support multi-element atomic op.");
  auto S = dynS->getStaticStream();
  auto elementSize = S->getMemElementSize();

  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support atomicrmw stream without BackingStore.");
  assert(elementSize <= 8 && "At most 8 byte data.");
  assert((elementPAddr % RubySystem::getBlockSizeBytes()) + elementSize <=
             RubySystem::getBlockSizeBytes() &&
         "Can not atomicrmw to multi-line elements.");

  /**
   * Create the atomic op.
   */
  const auto &formalParams = dynS->configData->storeFormalParams;
  FIFOEntryIdx entryIdx(
      sliceId.getDynStreamId(),
      LLVMDynamicInst::INVALID_SEQ_NUM /* Fake ConfigSeqNum */);
  entryIdx.entryIdx = sliceId.getStartIdx();
  auto getBaseStreamValue = [element](uint64_t baseStreamId) -> StreamValue {
    return element->getBaseStreamValue(baseStreamId);
  };
  auto atomicOp =
      S->setupAtomicOp(entryIdx, elementSize, formalParams, getBaseStreamValue);

  /**
   * Create the packet.
   */
  MasterID masterId = 0;
  Addr pc = 0;
  int contextId = 0;

  Request::Flags flags;
  flags.set(Request::ATOMIC_RETURN_OP);
  RequestPtr req =
      std::make_shared<Request>(element->vaddr, elementSize, flags, masterId,
                                pc, contextId, std::move(atomicOp));
  req->setPaddr(elementPAddr);
  PacketPtr pkt = Packet::createWrite(req);
  // Fake some data.
  uint8_t *pkt_data = new uint8_t[req->getSize()];
  pkt->dataDynamic(pkt_data);

  /**
   * Send to backing store to perform atomic op.
   */
  rubySystem->getPhysMem()->functionalAccess(pkt);
  LLC_SLICE_DPRINTF_(
      LLCRubyStreamStore, sliceId,
      "Functional accessed pkt, isWrite %d, vaddr %#x, paddr %#x, size %d.\n",
      pkt->isWrite(), pkt->req->getVaddr(), pkt->getAddr(), pkt->getSize());

  // Get the loaded value.
  uint64_t loadedValue = 0;
  {
    auto atomicOp = dynamic_cast<StreamAtomicOp *>(pkt->getAtomicOp());
    loadedValue = atomicOp->getLoadedValue().front();
  }

  // Don't forget to release the packet.
  delete pkt;

  return loadedValue;
}

void LLCStreamEngine::pushReadyComputation(LLCStreamElementPtr &element) {
  LLC_ELEMENT_DPRINTF(element, "Push computation.\n");
  assert(element->areBaseElementsReady() && "Element is not ready yet.");
  auto dynS = LLCDynamicStream::getLLCStreamPanic(element->dynStreamId);
  dynS->incompleteComputations++;
  this->readyComputations.emplace_back(element);
  element->scheduledComputation();
}

void LLCStreamEngine::pushInflyComputation(LLCStreamElementPtr &element,
                                           const StreamValue &result,
                                           Cycles &latency) {
  assert(this->inflyComputations.size() < 100 && "Too many infly results.");
  assert(latency < 100 && "Latency too long.");
  Cycles readyCycle = this->controller->curCycle() + latency;
  for (auto iter = this->inflyComputations.rbegin(),
            end = this->inflyComputations.rend();
       iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      this->inflyComputations.emplace(iter.base(), element, result, readyCycle);
      return;
    }
  }
  this->inflyComputations.emplace_front(element, result, readyCycle);
}

void LLCStreamEngine::startComputation() {
  int startedComputation = 0;
  const int computationWidth =
      this->controller->getLLCStreamEngineComputeWidth();
  while (startedComputation < computationWidth &&
         !this->readyComputations.empty()) {
    auto &element = this->readyComputations.front();
    auto dynS = LLCDynamicStream::getLLCStreamPanic(element->dynStreamId);
    Cycles latency(0);
    auto result = dynS->computeStreamElementValue(element, latency);
    auto forceZeroLat =
        this->controller->isLLCStreamEngineZeroComputeLatencyEnabled();
    if (forceZeroLat) {
      latency = Cycles(0);
    }
    LLC_ELEMENT_DPRINTF(
        element, "Start computation. Charge Latency %llu (ZeroLat %d).\n",
        latency, forceZeroLat);
    this->pushInflyComputation(element, result, latency);

    this->readyComputations.pop_front();
    startedComputation++;
  }
}

void LLCStreamEngine::completeComputation() {
  // We don't charge complete width.
  auto curCycle = this->controller->curCycle();
  while (!this->inflyComputations.empty()) {
    auto &computation = this->inflyComputations.front();
    auto &element = computation.element;
    if (computation.readyCycle > curCycle) {
      LLC_ELEMENT_DPRINTF(
          element,
          "Cannot complete computation, readyCycle %llu, curCycle %llu.\n",
          computation.readyCycle, curCycle);
      break;
    }
    LLC_ELEMENT_DPRINTF(element, "Complete computation.\n");
    auto dynS = LLCDynamicStream::getLLCStreamPanic(element->dynStreamId);
    dynS->completeComputation(this, element, computation.result);
    this->inflyComputations.pop_front();
  }
}