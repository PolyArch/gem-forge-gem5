
#include "LLCStreamEngine.hh"
#include "LLCStreamAtomicLockManager.hh"
#include "LLCStreamCommitController.hh"
#include "LLCStreamMigrationController.hh"
#include "LLCStreamNDCController.hh"
#include "LLCStreamRangeBuilder.hh"
#include "MLCStreamEngine.hh"
#include "StreamRequestBuffer.hh"
#include "pum/DataMoveCompiler.hh"
#include "pum/PUMEngine.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

// Generated by slicc.
#include "mem/ruby/protocol/StreamMigrateRequestMsg.hh"
#include "mem/simple_mem.hh"

#include "cpu/gem_forge/accelerator/stream/stream_atomic_op.hh"
#include "cpu/gem_forge/accelerator/stream/stream_engine.hh"
#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/LLCRubyStreamBase.hh"
#include "debug/LLCRubyStreamLife.hh"
#include "debug/LLCRubyStreamMulticast.hh"
#include "debug/LLCRubyStreamNotIssue.hh"
#include "debug/LLCRubyStreamReduce.hh"
#include "debug/LLCRubyStreamStore.hh"
#include "debug/LLCStreamPUM.hh"
#include "debug/StreamRangeSync.hh"
#define DEBUG_TYPE LLCRubyStreamBase
#include "../stream_log.hh"

#define LLCSE_DPRINTF(format, args...)                                         \
  DPRINTF(LLCRubyStreamBase, "[%s_SE%d]: " format,                             \
          this->curRemoteMachineType(), this->curRemoteBank(), ##args)

LLCStreamEngine::LLCStreamEngine(AbstractStreamAwareController *_controller,
                                 MessageBuffer *_streamMigrateMsgBuffer,
                                 MessageBuffer *_streamIssueMsgBuffer,
                                 MessageBuffer *_streamIndirectIssueMsgBuffer,
                                 MessageBuffer *_streamResponseMsgBuffer)
    : Consumer(_controller), controller(_controller),
      streamMigrateMsgBuffer(_streamMigrateMsgBuffer),
      streamIssueMsgBuffer(_streamIssueMsgBuffer),
      streamIndirectIssueMsgBuffer(_streamIndirectIssueMsgBuffer),
      streamResponseMsgBuffer(_streamResponseMsgBuffer),
      issueWidth(_controller->getLLCStreamEngineIssueWidth()),
      migrateWidth(_controller->getLLCStreamEngineMigrateWidth()),
      maxInflyRequests(8), maxInqueueRequests(2), translationBuffer(nullptr) {
  this->controller->registerLLCStreamEngine(this);
  this->commitController = m5::make_unique<LLCStreamCommitController>(this);
  this->atomicLockManager = m5::make_unique<LLCStreamAtomicLockManager>(this);
  this->ndcController = m5::make_unique<LLCStreamNDCController>(this);
  this->indReqBuffer = m5::make_unique<StreamRequestBuffer>(
      this->controller, this->streamIndirectIssueMsgBuffer, Cycles(1),
      4 /* Max Inqueue Requests Per Stream */,
      this->controller->myParams->ind_stream_req_max_per_multicast_msg,
      this->controller->myParams->ind_stream_req_multicast_group_size);
  this->migrateController = m5::make_unique<LLCStreamMigrationController>(
      this->controller,
      this->controller->myParams
          ->neighbor_stream_threshold /* NeighborStreamsThreshold */,
      Cycles(this->controller->myParams->neighbor_migration_delay) /* Delay */
  );
  this->reuseBuffer = m5::make_unique<StreamReuseBuffer>(
      this->controller->getMachineID(),
      this->controller->myParams->reuse_buffer_lines_per_core,
      true /* PerCoreMode */
  );
  this->pumEngine = m5::make_unique<PUMEngine>(this);
}

LLCStreamEngine::~LLCStreamEngine() { this->streams.clear(); }

int LLCStreamEngine::getNumDirectStreams() const {
  return this->streams.size() + this->migratingStreams.size();
}

int LLCStreamEngine::getNumDirectStreamsWithStaticId(
    const DynStreamId &dynStreamId) const {
  int count = 0;
  for (auto dynS : this->streams) {
    if (dynS->getDynStreamId().staticId == dynStreamId.staticId) {
      count++;
    }
  }
  for (auto dynS : this->migratingStreams) {
    if (dynS->getDynStreamId().staticId == dynStreamId.staticId) {
      count++;
    }
  }
  return count;
}

int LLCStreamEngine::curRemoteBank() const {
  return this->controller->getMachineID().num;
}

MachineType LLCStreamEngine::myMachineType() const {
  return this->controller->getMachineID().getType();
}

const char *LLCStreamEngine::curRemoteMachineType() const {
  return this->controller->getMachineTypeString();
}

void LLCStreamEngine::receiveStreamConfigure(PacketPtr pkt) {

  // Initialize the translation buffer.
  this->initializeTranslationBuffer();

  auto streamConfigureData = *(pkt->getPtr<CacheStreamConfigureDataPtr>());
  LLCSE_DPRINTF("Received Pkt %#x, StreamConfigure %#x, initVAddr "
                "%#x, "
                "initPAddr %#x.\n",
                pkt, streamConfigureData, streamConfigureData->initVAddr,
                streamConfigureData->initPAddr);

  // Create the stream.
  auto S = LLCDynStream::getLLCStreamPanic(DynStrandId(
      streamConfigureData->dynamicId, streamConfigureData->strandIdx,
      streamConfigureData->totalStrands));
  LLC_S_DPRINTF_(LLCRubyStreamLife, S->getDynStrandId(),
                 "Configure DirectStream InitAllocatedSlice %d "
                 "TotalTripCount %lld.\n",
                 streamConfigureData->initCreditedIdx, S->getTotalTripCount());
  S->remoteConfigured(this->controller);

  // Add the initial credits.
  if (streamConfigureData->initCreditedIdx > 0) {
    S->addCredit(streamConfigureData->initCreditedIdx);
  }

  // Remember the stream to the CommitController if we have that.
  if (S->shouldRangeSync()) {
    this->commitController->registerStream(S);
  }

  // Check if we have indirect streams.
  for (const auto &edge : streamConfigureData->depEdges) {
    if (edge.type == CacheStreamConfigureData::DepEdge::Type::UsedBy) {
      auto &ISConfig = edge.data;
      // Let's create an indirect stream.
      auto IS = LLCDynStream::getLLCStreamPanic(DynStrandId(
          ISConfig->dynamicId, ISConfig->strandIdx, ISConfig->totalStrands));
      LLC_S_DPRINTF_(LLCRubyStreamLife, IS->getDynStrandId(),
                     "Configure IndirectStream MemElementSize %d "
                     "TotalTripCount %lld.\n",
                     IS->getMemElementSize(), IS->getTotalTripCount());
      IS->remoteConfigured(this->controller);
    }
  }

  // Release memory.
  *(pkt->getPtr<CacheStreamConfigureDataPtr>()) = nullptr;
  delete pkt;

  S->traceEvent(::LLVM::TDG::StreamFloatEvent::CONFIG);
  // Let's check if StreamEnd packet has arrived earlier.
  if (this->pendingEndStrandIds.count(S->getDynStrandId())) {
    S->terminate();
  } else {
    this->streams.emplace_back(S);
    this->addStreamToMulticastTable(S);
    // Let's schedule a wakeup event.
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::receiveStreamEnd(PacketPtr pkt) {
  auto endStrandId = *(pkt->getPtr<DynStrandId *>());
  LLC_S_DPRINTF_(LLCRubyStreamLife, *endStrandId, "Received StreamEnd.\n");
  // Search for this stream.
  for (auto streamIter = this->streams.begin(), streamEnd = this->streams.end();
       streamIter != streamEnd; ++streamIter) {
    auto &S = *streamIter;
    if (S->getDynStrandId() == (*endStrandId)) {
      // Found it.
      // ? Can we just sliently release it?
      this->removeStreamFromMulticastTable(S);
      S->terminate();
      this->streams.erase(streamIter);
      // Don't forgot to release the memory.
      delete endStrandId;
      delete pkt;
      return;
    }
  }
  /**
   * ? No need to search in migratingStreams?
   * For migrating streams, the end message should be sent to the
   * destination llcBank.
   */

  /**
   * If not found, it is similar case as stream flow control message.
   * We are waiting for the stream to migrate here.
   * Add the message to the pending
   */
  this->pendingEndStrandIds.insert(*endStrandId);

  // Don't forgot to release the memory.
  delete endStrandId;
  delete pkt;
}

void LLCStreamEngine::receiveStreamMigrate(LLCDynStreamPtr stream,
                                           bool isCommit) {

  this->initializeTranslationBuffer();

  /**
   * Handle the case for commit migration.
   */
  if (isCommit) {
    LLC_S_DPRINTF_(StreamRangeSync, stream->getDynStrandId(),
                   "[Commit] Received migrate.\n");
    if (stream->isTerminated()) {
      LLC_S_DPRINTF_(StreamRangeSync, stream->getDynStrandId(),
                     "[Commit] Already terminated.\n");

    } else {
      this->commitController->registerStream(stream);
      this->scheduleEvent(Cycles(1));
    }
    return;
  }

  // Sanity check.
  auto vaddrAndMachineType = stream->peekNextAllocVAddrAndMachineType();
  auto vaddr = vaddrAndMachineType.first;
  auto machineType = vaddrAndMachineType.second;
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Paddr should always be valid to migrate a stream.");
  Addr paddrLine = makeLineAddress(paddr);
  assert(this->isPAddrHandledByMe(paddrLine, machineType) &&
         "Stream migrated to wrong remote bank.\n");

  if (!this->controller->isStreamAdvanceMigrateEnabled()) {
    if (stream->hasIndirectDependent()) {
      // This is only enforced when there is dependent streams.
      assert(stream->inflyRequests == 0 &&
             "Stream migrated with inflyRequests.");
    }
    assert(!stream->hasIndirectElemReadyToIssue() &&
           "Stream migrated with readyIndirectElements.");
  }

  LLC_S_DPRINTF(stream->getDynStrandId(),
                "Received migrate. DirectStreams %llu.\n",
                this->streams.size());

  stream->migratingDone(this->controller);

  // Check for if the stream is already ended.
  if (this->pendingEndStrandIds.count(stream->getDynStrandId())) {
    stream->terminate();
    return;
  }

  this->streams.emplace_back(stream);
  this->addStreamToMulticastTable(stream);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamFlow(const DynStreamSliceId &sliceId) {
  // Simply append it to the list.
  LLC_SLICE_DPRINTF(sliceId, "Received stream flow [%lu, +%lu).\n",
                    sliceId.getStartIdx(), sliceId.getNumElements());
  this->pendingStreamFlowControlMsgs.push_back(sliceId);
  this->scheduleEvent(Cycles(1));
}

void LLCStreamEngine::receiveStreamCommit(const DynStreamSliceId &sliceId) {
  LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                     "Received stream commit [%llu, %llu).\n",
                     sliceId.getStartIdx(), sliceId.getEndIdx());
  auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
  if (!dynS) {
    // The stream is already released.
    return;
  }
  dynS->addCommitMessage(sliceId);
}

void LLCStreamEngine::receiveStreamDataVec(Cycles delayCycle, Addr paddrLine,
                                           const DynStreamSliceIdVec &sliceIds,
                                           const DataBlock &dataBlock,
                                           const DataBlock &storeValueBlock) {
  auto readyCycle = this->controller->curCycle() + delayCycle;

  /**
   * Notice that we replace the data block here if we are using
   * back storage.
   */
  DataBlock loadValueBlock = dataBlock;
  auto rubySystem = this->controller->params()->ruby_system;
  if (rubySystem->getAccessBackingStore()) {
    // Get the data from backing store.
    RequestPtr req =
        std::make_shared<Request>(paddrLine, rubySystem->getBlockSizeBytes(),
                                  0 /* Flags */, 0 /* MasterId */);
    PacketPtr pkt = Packet::createRead(req);
    pkt->dataStatic(loadValueBlock.getDataMod(0 /* offset */));
    rubySystem->getPhysMem()->functionalAccess(pkt);
    delete pkt;
  }

  for (const auto &sliceId : sliceIds.sliceIds) {
    this->enqueueIncomingStreamDataMsg(readyCycle, paddrLine, sliceId,
                                       loadValueBlock, storeValueBlock);
  }
  this->scheduleEvent(Cycles(delayCycle));
}

void LLCStreamEngine::notifyStreamRequestMiss(
    const DynStreamSliceIdVec &sliceIds) {
  if (this->myMachineType() == MachineType::MachineType_L2Cache) {
    for (const auto &sliceId : sliceIds.sliceIds) {
      auto llcS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
      if (llcS) {
        auto S = llcS->getStaticS();
        S->statistic.numMissL2++;
      }
    }
  }
}

void LLCStreamEngine::receiveStreamNDCRequest(PacketPtr pkt) {
  this->ndcController->receiveStreamNDCRequest(pkt);
}

void LLCStreamEngine::enqueueIncomingStreamDataMsg(
    Cycles readyCycle, Addr paddrLine, const DynStreamSliceId &sliceId,
    const DataBlock &dataBlock, const DataBlock &storeValueBlock) {
  auto iter = this->incomingStreamDataQueue.rbegin();
  for (auto end = this->incomingStreamDataQueue.rend(); iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      break;
    }
  }
  this->incomingStreamDataQueue.emplace(iter.base(), readyCycle, paddrLine,
                                        sliceId, dataBlock, storeValueBlock);
  LLC_SLICE_DPRINTF(sliceId, "[IncomingElemQueue] Enqueued %lu.\n",
                    this->incomingStreamDataQueue.size());
  // Some sanity check.
  // if (this->incomingStreamDataQueue.size() > 2048) {
  //   LLC_SLICE_PANIC(sliceId, "[IncomingElemQueue] overflow.");
  // }
}

void LLCStreamEngine::drainIncomingStreamDataMsg() {
  auto curCycle = this->controller->curCycle();
  while (!this->incomingStreamDataQueue.empty()) {
    auto &msg = this->incomingStreamDataQueue.front();
    if (msg.readyCycle <= curCycle) {
      this->receiveStreamData(msg.paddrLine, msg.sliceId, msg.dataBlock,
                              msg.storeValueBlock);
      this->incomingStreamDataQueue.pop_front();
    } else {
      break;
    }
  }
}

void LLCStreamEngine::receiveStreamData(Addr paddrLine,
                                        const DynStreamSliceId &sliceId,
                                        const DataBlock &dataBlock,
                                        const DataBlock &storeValueBlock) {
  /**
   * Since we notify the stream engine for all stream data,
   * it is possible that we don't find the stream if it is not direct
   * stream. Thus we just look up the global map.
   */
  auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
  if (!dynS) {
    // Try stream near-data computing.
    this->ndcController->receiveStreamData(sliceId, dataBlock, storeValueBlock);
    return;
  }
  // Update inflyRequests.
  if (dynS->inflyRequests == 0) {
    LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
  }
  dynS->inflyRequests--;

  auto S = dynS->getStaticS();

  /**
   * Check if we need to cache this stream for reuse.
   */
  if (this->reuseBuffer->shouldCacheStream(S, dynS->getDynStreamId())) {
    this->reuseBuffer->addLine(sliceId, paddrLine, dataBlock);
  }

  bool needIndirect =
      !(dynS->getIndStreams().empty() && dynS->predicatedStreams.empty());
  bool needUpdate = S->isUpdateStream() || S->isAtomicStream();
  bool needSendTo = !(dynS->sendToEdges.empty());

  LLC_SLICE_DPRINTF(sliceId,
                    "Received StreamData, InflyRequests %d, NeedIndirect %d, "
                    "NeedUpdate %d NeedSendTo %d StoreBlock %s.\n",
                    dynS->inflyRequests, needIndirect, needUpdate, needSendTo,
                    storeValueBlock);

  // Construct all the element data (except for StoreStream).
  if (!S->isStoreComputeStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element = dynS->getElemPanic(idx, "RecvElementData");
      if (element->hasFirstIndirectAtomicReqSeen()) {
        // This is just the second request for IndirectAtomic.
        // No need to extract data.
        continue;
      }
      if (element->isReady()) {
        LLC_SLICE_PANIC(sliceId, "Elements already ready.");
      }
      element->extractElementDataFromSlice(
          dynS->getStaticS()->getCPUDelegator(), sliceId, dataBlock);
    }
  }

  /**
   * For DirectStream, we should have the slice in our
   * AllocatedSlice.
   */
  LLCStreamSlicePtr slice = nullptr;
  if (!dynS->isIndirect()) {
    slice = this->tryGetSlice(sliceId);
    if (!slice) {
      LLC_SLICE_PANIC(sliceId, "Failed to get slice when receiving "
                               "data for DirectStream.");
    }
    slice->responded(dataBlock, storeValueBlock);
  }

  /**
   * There are many things to do here.
   * 1. Slice - For StoreStream, perform the store and send back Ack.
   * 2. Slice - For SendTo dependence, send the slice to the
   * receiver.
   * 3. Element - Evaluate LoopBoundFunc.
   * 4. Element - Trigger indirect elements if the base is ready (in
   * order).
   * 5. Element - Trigger update operations (out-of-order).
   * 6. Element - Release ready elements in order.
   */

  if (S->isStoreStream()) {
    this->receiveStoreStreamData(dynS, sliceId, storeValueBlock);
  }

  /**
   * Normally we could just send the data to the receiver stream.
   * However, for LoadComputeStream, we should send after the value
   * is computed.
   */
  if (!S->isLoadComputeStream()) {
    for (const auto &edge : dynS->sendToEdges) {
      this->issueStreamDataToLLC(
          dynS, sliceId, dataBlock, edge,
          RubySystem::getBlockSizeBytes() /* PayloadSize */);
    }
    for (const auto &edge : dynS->sendToPUMEdges) {
      this->issueStreamDataToPUM(
          dynS, sliceId, dataBlock, edge,
          RubySystem::getBlockSizeBytes() /* PayloadSize */);
    }
    if (dynS->configData->isPUMPrefetch &&
        this->myMachineType() == MachineType_Directory) {
      // We need to send back the prefetched line to LLC.
      this->issuePUMPrefetchStreamDataToLLC(dynS, sliceId, dataBlock);
    }
  }

  // Evaluate LoopBound.
  dynS->evaluateLoopBound(this);

  if (!dynS->getIndStreams().empty()) {
    for (auto &idxElement : dynS->idxToElementMap) {
      auto &element = idxElement.second;
      LLC_SLICE_DPRINTF(sliceId, "Process for elem %llu, Ready %d.\n",
                        element->idx, element->isReady());
      if (element->idx < dynS->getNextTriggerIndElemIdx()) {
        continue;
      }
      if (!element->isReady()) {
        // Not ready yet. Break.
        break;
      }
      this->triggerIndElems(dynS, element);
      dynS->markElemTriggeredIndirect(element->idx);
    }
  }

  // Alert MLC prefetch stream is done.
  if (dynS->configData->isPUMPrefetch) {
    this->tryFinishPUMPrefetchStream(dynS, sliceId);
  }

  /**
   * The following logic is only for IndirectStream.
   * For DirectStream, these cases are handled in processSlice().
   */
  if (!dynS->isIndirect()) {
    return;
  }

  if (S->isAtomicComputeStream()) {
    this->processIndirectAtomicSlice(dynS, sliceId);
  } else if (S->isUpdateStream()) {
    this->processIndirectUpdateSlice(dynS, sliceId, storeValueBlock);
  }

  if (S->isLoadComputeStream()) {
    /**
     * We register a slice here, directly advance to RESPONDED state,
     * and schedule the computation to merge the code path for
     * DirectStream.
     */
    if (sliceId.getNumElements() != 1) {
      LLC_SLICE_PANIC(sliceId, "IndirectLoadComputeStream with more "
                               "than one element per slice.");
    }
    auto element =
        dynS->getElemPanic(sliceId.getStartIdx(),
                           "ReceiveStreamData for IndirectLoadComputeStream");
    auto slice = std::make_shared<LLCStreamSlice>(S, sliceId);
    slice->allocate(this);
    slice->issue();
    slice->responded(dataBlock, storeValueBlock);
    this->allocatedSlices.push_back(slice);
    element->addSlice(slice);
    this->processLoadComputeSlice(dynS, slice);
  }

  /**
   * Here we release the indirect element, with a few exceptions:
   * 1. DirectStream element released after all slices are released.
   * 2. For IndirectAtomicComputeStream:
   *   a. If it issues after commit, will be released when the final request is
   *      handled.
   *   b. If not, will be released in postProcessIndirectAtomicSlice().
   * 3. IndirectLoadComputeStream is released in releaseSlice().
   */
  LLC_S_DPRINTF(dynS->getDynStrandId(),
                "[IndirectRelease] Check ShouldIssueAfterCommit %d "
                "IsLoadCompute %d.\n",
                dynS->shouldIssueAfterCommit(), S->isLoadComputeStream());
  if (!dynS->shouldIssueAfterCommit() && !S->isLoadComputeStream() &&
      !S->isAtomicComputeStream()) {
    while (!dynS->idxToElementMap.empty()) {
      auto elementIter = dynS->idxToElementMap.begin();
      const auto &element = elementIter->second;
      if (!element->areBaseElemsReady()) {
        LLC_ELEMENT_DPRINTF(element,
                            "Cannot release AreBaseElementsReady %d.\n",
                            element->areBaseElemsReady());
        break;
      }
      if (S->isStoreComputeStream()) {
        if (!element->isIndirectStoreAcked()) {
          LLC_ELEMENT_DPRINTF(element,
                              "Cannot release IndirectStore not acked.\n");
          break;
        }
      } else {
        if (!element->isReady()) {
          LLC_ELEMENT_DPRINTF(element, "Cannot release IsReady %d.\n",
                              element->isReady());
          break;
        }
      }
      dynS->eraseElem(elementIter);
    }
  }

  return;
}

void LLCStreamEngine::receiveStoreStreamData(LLCDynStreamPtr dynS,
                                             const DynStreamSliceId &sliceId,
                                             const DataBlock &storeValueBlock) {
  /**
   * We received the response for the StoreStream, we now perform the
   * store. And issue Ack back here if this is DirectStream and no
   * range sync.
   *
   * Although we really should perform the store after the core
   * committed, here I store and only delay sending back the Ack in
   * releaseSlice. So far this only works with DirectStream.
   *
   * This means we still immediately send back StreamAck for:
   * 1. StoreComputeStream without RangeSync.
   * 2. Indirect StoreComputeStream.
   *
   * NOTE: We have to construct the overlap instead of storing the
   * whole line.
   */
  Addr paddr;
  if (!dynS->translateToPAddr(sliceId.vaddr, paddr)) {
    LLC_SLICE_PANIC(sliceId,
                    "Failed to translate StoreStream slice vaddr %#x to paddr.",
                    sliceId.vaddr);
  }
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    assert(dynS->idxToElementMap.count(idx) &&
           "Missing element for StoreStream.");
    auto element = dynS->getElemPanic(idx, "ReceiveStoreStreamData");

    // Compute the overlap and set the data.
    int elementOffset;
    int sliceOffset;
    int overlapSize = element->computeOverlap(sliceId.vaddr, sliceId.getSize(),
                                              sliceOffset, elementOffset);
    auto storeValue = storeValueBlock.getData(sliceOffset, overlapSize);
    LLC_SLICE_DPRINTF_(
        LLCRubyStreamStore, sliceId,
        "StreamStore done with Element %llu, Slice vaddr %#x paddr "
        "%#x, "
        "SliceOffset %d OverlapSize %d Value %s.\n",
        idx, sliceId.vaddr, paddr, sliceOffset, overlapSize,
        GemForgeUtils::dataToString(storeValue, overlapSize));
    this->performStore(paddr + sliceOffset, overlapSize, storeValue);
  }
  if (!dynS->shouldRangeSync() || dynS->isIndirect()) {
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore send back StreamAck.\n");
    if (dynS->isIndirect()) {
      auto element =
          dynS->getElemPanic(sliceId.getStartIdx(), "AckIndirectStore");
      element->setIndirectStoreAcked();
    }
    /**
     * Normally without RangeSync, we would send out one Ack per
     * slice. However, we could just sent this out coarse grained.
     * For simplicity, here I just hack by force some idea ack.
     */
    bool forceIdea = dynS->isNextIdeaAck();
    dynS->ackedOneSlice();
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
}

bool LLCStreamEngine::isNextElemHandledHere(LLCDynStreamPtr dynS) const {
  auto nextVAddrAndMachineType = dynS->peekNextAllocVAddrAndMachineType();
  auto nextVAddr = nextVAddrAndMachineType.first;
  auto nextMachineType = nextVAddrAndMachineType.second;
  Addr nextPAddr;
  if (!dynS->translateToPAddr(nextVAddr, nextPAddr)) {
    // If the address is faulted, we stay here.
    return true;
  }
  // Check if it is still on this bank.
  if (this->isPAddrHandledByMe(nextPAddr, nextMachineType)) {
    // Still here.
    return true;
  }
  return false;
}

bool LLCStreamEngine::canMigrateStream(LLCDynStream *dynS) const {
  /**
   * In this implementation, the stream will aggressively
   * migrate to the next element bank, even the credit has only been
   * allocated to the previous element. Therefore, we do not need to
   * check if the next element is allocated.
   */
  if (this->isNextElemHandledHere(dynS)) {
    return false;
  }
  if (dynS->hasLoopBound() && dynS->isLoopBoundBrokenOut()) {
    return false;
  }
  /**
   * We can only enable AdvanceMigrate for DirectStreams.
   * PointerChaseStream can never advance migrate.
   * Streams with LoopBound function can not advance migrate.
   * Streams with PUMSendTo edges can not advance migrate.
   */
  if (!this->controller->isStreamAdvanceMigrateEnabled() ||
      dynS->isPointerChase() || dynS->hasLoopBound() ||
      !dynS->sendToPUMEdges.empty()) {
    if (dynS->hasIndirectDependent() || dynS->isPointerChase() ||
        dynS->hasLoopBound() || !dynS->sendToEdges.empty()) {
      if (dynS->inflyRequests > 0) {
        // We are still waiting data for indirect usages:
        // 1. Indirect streams.
        // 2. Update request.
        // 3. Pointer chasing.
        // 4. Send to PUM.
        LLC_S_DPRINTF(dynS->getDynStrandId(),
                      "[Delay Migrate] InflyRequests %llu.\n",
                      dynS->inflyRequests);
        return false;
      }
    }
    if (dynS->hasLoopBound()) {
      /**
       * We need to check that all loop bound has been evaluated here.
       */
      const auto &nextAllocSliceId = dynS->peekNextAllocSliceId();
      auto nextLoopBoundElemIdx = dynS->getNextLoopBoundElemIdx();
      if (nextLoopBoundElemIdx < nextAllocSliceId.getStartIdx()) {
        LLC_S_DPRINTF(
            dynS->getDynStrandId(),
            "[Delay Migrate] NextLoopBoundElemIdx %lu NextAllocSliceId %s.\n",
            nextLoopBoundElemIdx, nextAllocSliceId);
        return false;
      }
    }
    if (dynS->hasIndirectElemReadyToIssue()) {
      // We are still waiting for some indirect streams to be issued.
      LLC_S_DPRINTF(dynS->getDynStrandId(),
                    "[Delay Migrate] ReadyIndirectElements %llu.\n",
                    dynS->getNumIndirectElemReadyToIssue());
      return false;
    }
    /**
     * ! A hack to delay migrate if there is waitingPredicatedElements for any
     * ! indirect stream.
     */
    for (auto IS : dynS->getIndStreams()) {
      if (!IS->waitingPredicatedElements.empty()) {
        return false;
      }
      if (IS->getStaticS()->isReduction() ||
          IS->getStaticS()->isPointerChaseIndVar()) {
        // We wait for the reduction element to be done.
        if (!IS->idxToElementMap.empty()) {
          const auto &element = IS->idxToElementMap.begin()->second;
          /**
           * ! Due to the current hack implementation, an element may
           * already be allocated for the next bank. Our way to
           * hack this is check if the base is already ready. If
           * not, then they are for next bank.
           */
          if (!element->isReady()) {
            for (const auto &baseE : element->baseElements) {
              if (baseE->strandId == dynS->getDynStrandId()) {
                if (baseE->isReady()) {
                  // The base element is ready, which means this is
                  // from this bank. If it's not ready, then we
                  // should have inflyRequest.
                  LLC_S_DPRINTF(IS->getDynStrandId(),
                                "[Delay Migrate] Reduction Elem %lu.\n",
                                element->idx);
                  return false;
                }
              }
            }
          }
        }
      }
    }
  }
  return true;
}

void LLCStreamEngine::wakeup() {

  // Sanity check.
  if (this->streams.size() >= 1000) {
    panic("Too many LLCStream.\n");
  }

  if (this->streams.size() > 0) {
    this->controller->m_statLLCNumDirectStreams.sample(this->streams.size());
  }
  if (!this->readyComputations.empty()) {
    this->controller->m_statLLCNumReadyComputations.sample(
        this->readyComputations.size());
  }
  if (!this->inflyComputations.empty()) {
    this->controller->m_statLLCNumInflyComputations.sample(
        this->inflyComputations.size());
  }

  // Drain incoming element data.
  this->drainIncomingStreamDataMsg();

  this->processStreamFlowControlMsg();
  this->issueStreams();
  this->issueStreamRangesToMLC();
  this->findMigratingStreams();
  this->migrateStreams();
  this->startComputation();
  this->completeComputation();
  this->processSlices();
  this->commitController->commit();

  // So we limit the issue rate in issueStreams.
  while (!this->requestQueue.empty()) {
    const auto &req = this->requestQueue.front();
    if (!req.translationDone) {
      break;
    }
    this->issueStreamRequestToRemoteBank(req);
    this->requestQueue.pop_front();
  }

  this->pumEngine->tick();

  if (!this->streams.empty() || !this->migratingStreams.empty() ||
      !this->requestQueue.empty() || !this->incomingStreamDataQueue.empty() ||
      !this->allocatedSlices.empty() || !this->readyComputations.empty() ||
      !this->inflyComputations.empty() ||
      this->commitController->hasStreamToCommit()) {
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::initializeTranslationBuffer() {
  if (!this->translationBuffer) {
    this->translationBuffer =
        m5::make_unique<StreamTranslationBuffer<RequestQueueIter>>(
            this->controller->getCPUDelegator()->getDataTLB(),
            [this](PacketPtr pkt, ThreadContext *tc, RequestQueueIter reqIter)
                -> void { this->translationCallback(pkt, tc, reqIter); },
            true /* AccessLastLevelTLBOnly */
        );
  }
}

bool LLCStreamEngine::canMergeAsMulticast(LLCDynStreamPtr dynSA,
                                          LLCDynStreamPtr dynSB) const {
  /**
   * Streams are considered possible to merged into one multicast
   * stream iff:
   * 1. They are from cores within the same multicast group.
   * 2. They both have linear address generation function.
   * 3. They have same dynamic parameters for address generation.
   * 4. They have the same request type.
   */
  const auto &dynSAId = dynSA->getDynStreamId();
  const auto &dynSBId = dynSB->getDynStreamId();
  if (dynSAId.coreId == dynSBId.coreId) {
    // Ignore streams from the same core.
    return false;
  }
  if (dynSA->getStaticS()->isAtomicComputeStream() ||
      dynSB->getStaticS()->isAtomicComputeStream()) {
    // Should never multicast atomic streams.
    return false;
  }
  auto multicastGroupIdA = this->controller->getMulticastGroupId(
      dynSAId.coreId, this->controller->myParams->stream_multicast_group_size);
  auto multicastGroupIdB = this->controller->getMulticastGroupId(
      dynSBId.coreId, this->controller->myParams->stream_multicast_group_size);
  if (multicastGroupIdA != multicastGroupIdB) {
    // They are not from the same multicast group.
    return false;
  }
  if (dynSA->getStaticId() != dynSA->getStaticId()) {
    return false;
  }
  auto linearAddrGenA = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSA->configData->addrGenCallback);
  auto linearAddrGenB = std::dynamic_pointer_cast<LinearAddrGenCallback>(
      dynSB->configData->addrGenCallback);
  if (!linearAddrGenA || !linearAddrGenB) {
    return false;
  }
  const auto &formalParamsA = dynSA->configData->addrGenFormalParams;
  const auto &formalParamsB = dynSB->configData->addrGenFormalParams;
  if (formalParamsA.size() != formalParamsB.size()) {
    return false;
  }
  for (auto i = 0; i < formalParamsA.size(); ++i) {
    const auto &paramA = formalParamsA.at(i);
    const auto &paramB = formalParamsB.at(i);
    if (!paramA.isInvariant || !paramB.isInvariant) {
      // One of the parameters rely on stream.
      return false;
    }
    if (paramA.invariant != paramB.invariant) {
      return false;
    }
  }
  if (this->getDirectStreamReqType(dynSA) !=
      this->getDirectStreamReqType(dynSB)) {
    return false;
  }
  return true;
}

void LLCStreamEngine::addStreamToMulticastTable(LLCDynStreamPtr dynS) {
  bool hasIndirectDependent = dynS->hasIndirectDependent();
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                 "Add to MulticastTable, HasIndirectDependent %d "
                 "DepEdges %d.\n",
                 hasIndirectDependent, dynS->configData->depEdges.size());
  /**
   * Currently we do not try to multicast streams with indirect
   * dependence. This includes streams with SendTo dependence.
   */
  // We only try to merge into multicast if it has no indirect
  // dependent.
  if (!hasIndirectDependent && dynS->configData->depEdges.empty()) {
    for (auto &entry : this->multicastStreamMap) {
      auto dynSRoot = entry.first;
      auto &group = entry.second;
      auto canMerge = this->canMergeAsMulticast(dynS, dynSRoot);
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynStrandId(),
                     "Check CanMergeAsMulticast %d.\n", canMerge);
      if (canMerge) {
        // Found the entry.
        group.push_back(dynS);
        dynS->setMulticastGroupLeader(dynSRoot);
        this->sortMulticastGroup(group);
        LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynSRoot->getDynStrandId(),
                       "Merged into MulticastGroup.\n");
        return;
      }
    }
  }
  // Not found.
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                 "New MulticastGroup.\n");
  this->multicastStreamMap
      .emplace(std::piecewise_construct, std::forward_as_tuple(dynS),
               std::forward_as_tuple())
      .first->second.push_back(dynS);
  dynS->setMulticastGroupLeader(dynS);
}

void LLCStreamEngine::removeStreamFromMulticastTable(LLCDynStreamPtr dynS) {
  LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                 "Remove from MulticastTable.\n");
  auto multicastGroupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(multicastGroupLeader);
  assert(mapIter != this->multicastStreamMap.end() &&
         "Failed to find multicast group.");
  // First we remove dynS from this group.
  auto &group = mapIter->second;
  bool erased = false;
  for (auto iter = group.begin(), end = group.end(); iter != end; ++iter) {
    if ((*iter) == dynS) {
      group.erase(iter);
      erased = true;
      break;
    }
  }
  assert(erased && "Failed to erase from MulticastGroup.");
  // Clear the multicast leader for dynS.
  dynS->setMulticastGroupLeader(nullptr);
  if (mapIter->first == dynS) {
    if (!group.empty()) {
      // If this is the leader and the group is not empty after
      // removing, we reinsert this group with a new leader.
      auto newLeader = group.front();
      for (auto &S : group) {
        S->setMulticastGroupLeader(newLeader);
      }
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, newLeader->getDynStrandId(),
                     "Select as NewLeader.\n");
      this->multicastStreamMap.emplace(newLeader, group);
    }
    // We can remove the group from the table now.
    assert(this->multicastStreamMap.erase(dynS) == 1 &&
           "Failed to remove the group");
  }
}

bool LLCStreamEngine::hasMergedAsMulticast(LLCDynStreamPtr dynS) const {
  return this->getMulticastGroup(dynS).size() > 1;
}

LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynStreamPtr dynS) {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

const LLCStreamEngine::StreamVec &
LLCStreamEngine::getMulticastGroup(LLCDynStreamPtr dynS) const {
  auto groupLeader = dynS->getMulticastGroupLeader();
  auto mapIter = this->multicastStreamMap.find(groupLeader);
  assert(mapIter != this->multicastStreamMap.end());
  return mapIter->second;
}

bool LLCStreamEngine::canIssueByMulticastPolicy(LLCDynStreamPtr dynS) const {
  /**
   * There are some policies to tune if we want to delay a stream
   * from issuing to have more multicast oppotunties. Here are the
   * policies:
   * ----- Most Relaxed (Optimize for Latency) ------
   * - Do nothing. Always return ture.
   * - The first stream with NextSliceAllocated in the
   * MulticastGroup.
   * - The stream must be the first one in the MulticastGroup.
   * ---- Most Constranit (Optimize for Traffic) ----
   */

  const auto &group = this->getMulticastGroup(dynS);

  const auto policy = this->controller->getStreamMulticastIssuePolicy();
  switch (policy) {
  case AbstractStreamAwareController::MulticastIssuePolicy::Any:
    return true;
  case AbstractStreamAwareController::MulticastIssuePolicy::FirstAllocated:
    for (const auto &S : group) {
      if (!S->isNextSliceCredited()) {
        continue;
      }
      // This is the first available stream.
      return S == dynS;
    }
    // Should never happen.
    assert(false && "DynS not found in MulticastGroup.");
  case AbstractStreamAwareController::MulticastIssuePolicy::First:
    return group.front() == dynS;
  default:
    return true;
  }
}

void LLCStreamEngine::sortMulticastGroup(StreamVec &group) const {
  auto comparator = [this](const LLCDynStreamPtr &SA,
                           const LLCDynStreamPtr &SB) -> bool {
    auto sliceIdxA = SA->getNextAllocSliceIdx();
    auto sliceIdxB = SB->getNextAllocSliceIdx();
    if (sliceIdxA != sliceIdxB) {
      return sliceIdxA < sliceIdxB;
    }
    /**
     * When the next sliceId is the same, it's interesting how we
     * break the tie.
     * 1. If we considered streams with next slice not allocated
     * "smaller", we are more frequently blocked and this achieves
     * maximum save of the traffic, as it exposes more multicast
     * opportunity.
     * 2. Otherwise, we try to issue ready streams with smaller
     * sliceId as soon as possible. This reduces the multicast
     * opportunity, but may help the latency.
     */
    if (SA->isNextSliceCredited() != SB->isNextSliceCredited()) {
      return !SA->isNextSliceCredited(); // Option 1
      // return SA->isNextSliceCredited(); // Option 2
    }
    // Break the tie with core id.
    return SA->getDynStreamId().coreId < SB->getDynStreamId().coreId;
  };
  std::sort(group.begin(), group.end(), comparator);
  if (Debug::LLCRubyStreamMulticast) {
    DPRINTF(LLCRubyStreamMulticast, "Sorted MulticastGroup:---\n");
    for (auto &dynS : group) {
      LLC_S_DPRINTF_(LLCRubyStreamMulticast, dynS->getDynStrandId(),
                     "NextAllocSliceIdx %lu, Allocated %d.\n",
                     dynS->getNextAllocSliceIdx(), dynS->isNextSliceCredited());
    }
    DPRINTF(LLCRubyStreamMulticast, "---\n");
  }
}

void LLCStreamEngine::generateMulticastRequest(RequestQueueIter reqIter,
                                               LLCDynStreamPtr targetDynS) {
  assert(this->controller->isStreamMulticastEnabled());
  auto &group = this->getMulticastGroup(targetDynS);

  const auto &targetSliceId = reqIter->sliceId;
  auto targetSliceIdx = targetDynS->getNextAllocSliceIdx();
  assert(targetSliceIdx > 0 &&
         "DynS should have positive NextSliceIdx as it generated "
         "reqIter.");
  LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, targetSliceId,
                     "Generate MulticastRequest.\n");
  // Start to scan, skip dynS.
  for (auto idx = 0; idx < group.size(); ++idx) {
    auto dynS = group.at(idx);
    if (dynS == targetDynS) {
      // We just issued.
      continue;
    }
    if (!dynS->getCoreDynS()) {
      // The CoreDynS has already been released. Skip this one.
      continue;
    }
    if (!dynS->isNextSliceCredited()) {
      // Not allocated, skip this one.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 < targetSliceIdx) {
      // This is behind stream, skip it.
      continue;
    }
    if (dynS->getNextAllocSliceIdx() + 1 > targetSliceIdx) {
      // This is future stream, we are done.
      break;
    }
    // Found a multicast stream candidate.
    auto slice = this->allocateSlice(dynS);
    slice->issue();
    const auto &sliceId = slice->getSliceId();
    // Sanity check for multicast slices.
    if (sliceId.vaddr != targetSliceId.vaddr) {
      LLC_SLICE_PANIC(sliceId, "Mismatch VAddr %#x for Multicast Slice %#x.",
                      sliceId.vaddr, targetSliceId.vaddr);
    }
    if (sliceId.getSize() != targetSliceId.getSize()) {
      LLC_SLICE_PANIC(sliceId, "Mismatch Size %d for Multicast Slice %d.",
                      sliceId.getSize(), targetSliceId.getSize());
    }

    auto SS = dynS->getStaticS();
    this->incrementIssueSlice(SS->statistic);

    // Add this to the request.
    auto reqType = this->getDirectStreamReqType(dynS);
    if (reqType != reqIter->requestType) {
      LLC_SLICE_PANIC(sliceId, "Multicast ReqType Mismatch Target %s, Ours %s.",
                      reqIter->requestType, reqType);
    }
    if (reqType == CoherenceRequestType_GETU) {
      SS->statistic.numLLCSentSlice++;
      SS->se->numLLCSentSlice++;
      SS->statistic.numLLCMulticastSlice++;
      SS->statistic.numLLCCanMulticastSlice++;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast Issue.\n");
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    if (hasIndirectDependent) {
      LLC_SLICE_PANIC(sliceId, "Multicast Issue with IndirectDependent.\n");
    }
    dynS->prevIssuedCycle = this->controller->curCycle();
    dynS->updateIssueClearCycle();
    // Track infly requests.
    dynS->inflyRequests++;

    reqIter->multicastSliceIds.push_back(sliceId);
  }

  if (!reqIter->multicastSliceIds.empty()) {
    targetDynS->getStaticS()->statistic.numLLCMulticastSlice++;
  }

  // Finally we want to make sure we are sorted.
  this->sortMulticastGroup(group);
}

void LLCStreamEngine::processStreamFlowControlMsg() {
  auto iter = this->pendingStreamFlowControlMsgs.begin();
  auto end = this->pendingStreamFlowControlMsgs.end();
  while (iter != end) {
    const auto &msg = *iter;
    bool processed = false;
    for (auto stream : this->streams) {
      if (stream->getDynStrandId() == msg.getDynStrandId() &&
          msg.getStartIdx() == stream->creditedSliceIdx) {
        // We found it.
        // Update the idx.
        LLC_S_DPRINTF(stream->getDynStrandId(), "Add credit %lu -> %lu.\n",
                      msg.getStartIdx(), msg.getEndIdx());
        stream->addCredit(msg.getNumElements());
        // Maybe we want to resort the Multicast group.
        if (this->controller->isStreamMulticastEnabled() &&
            this->hasMergedAsMulticast(stream)) {
          this->sortMulticastGroup(this->getMulticastGroup(stream));
        }
        processed = true;
        break;
      }
    }
    if (!processed) {
      // Delete the credit message if the stream is already released
      // due to StreamLoopBound.
      if (!LLCDynStream::getLLCStream(msg.getDynStrandId())) {
        LLC_S_DPRINTF(msg.getDynStrandId(),
                      "[Credit] Discard credit %lu -> %lu as LLCDynStream "
                      "already released.\n",
                      msg.getStartIdx(), msg.getEndIdx());
        processed = true;
      }
    }
    if (processed) {
      iter = this->pendingStreamFlowControlMsgs.erase(iter);
    } else {
      // LLCSE_DPRINTF("Failed to process stream credit %s [%lu,
      // %lu).\n",
      //               msg.streamId.name.c_str(), msg.getStartIdx(),
      //               msg.getEndIdx());
      ++iter;
    }
  }
}

void LLCStreamEngine::issueStreams() {

  /**
   * Enforce thresholds for issue stream requests here.
   * 1. If there are many requests in the queue, there is no need to
   * inject more packets to block the queue.
   * 2. As a sanity check, we limit the total number of infly direct
   * requests.
   */

  if (this->streamIssueMsgBuffer->getSize(this->controller->clockEdge()) >=
      this->maxInqueueRequests) {

    // Record this in streams.
    for (auto dynS : this->streams) {
      auto &statistic = dynS->getStaticS()->statistic;
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MaxEngineInflyRequest);
    }

    return;
  }

  // By cheching i < nStreams we avoid issuing the same stream more
  // than once.
  auto streamIter = this->streams.begin();
  auto streamEnd = this->streams.end();
  auto checkedStreams = 0;
  auto issuedStreams = 0;
  auto nStreams = this->streams.size();
  for (; checkedStreams < nStreams && issuedStreams < this->issueWidth;
       ++checkedStreams) {
    auto curStream = streamIter;
    // Move to the next one.
    ++streamIter;
    auto readyS = this->findStreamReadyToIssue(*curStream);
    if (readyS) {
      if (readyS->isIndirect()) {
        this->issueStreamIndirect(readyS);
      } else {
        this->issueStreamDirect(readyS);
      }
      issuedStreams++;
      // Push the stream back to the end.
      this->streams.splice(streamEnd, this->streams, curStream);
    }
  }
  for (; checkedStreams < nStreams; ++checkedStreams) {
    // Record that they are not checked.
    assert(streamIter != streamEnd && "Should never happen.");
    auto dynS = *streamIter;
    auto &statistic = dynS->getStaticS()->statistic;
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxIssueWidth);
  }
}

LLCDynStreamPtr LLCStreamEngine::findStreamReadyToIssue(LLCDynStreamPtr dynS) {

  auto S = dynS->getStaticS();
  auto &statistic = S->statistic;
  statistic.sampleLLCAliveElements(dynS->idxToElementMap.size());
  statistic.sampleLLCInflyComputation(dynS->incompleteComputations);
  /**
   * Prioritize indirect streams.
   */
  LLCDynStreamPtr readyS = this->findIndirectStreamReadyToIssue(dynS);
  if (readyS) {
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::IndirectPriority);
    return readyS;
  }

  if (!dynS->isNextSliceCredited()) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                   "[Not Issue] NextSliceNotAllocated.\n");
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::NextSliceNotAllocated);
    return nullptr;
  }

  if (dynS->isNextSliceOverflown()) {
    // Do not try to issue this slice if it is overflown.
    LLC_S_DPRINTF(dynS->getDynStrandId(),
                  "[Not Issue] NextSliceOverTripCount.\n");
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::NextSliceOverTripCount);
    return nullptr;
  }

  /**
   * If we enabled Multicast and this is not the lowest stream in
   * the multicast group, i.e. lagging the most behind, then we do
   * not issue it as we are waiting for behind streams to catch up
   * and explore multicast opportunity.
   */
  if (this->controller->isStreamMulticastEnabled()) {
    if (!this->canIssueByMulticastPolicy(dynS)) {
      LLC_S_DPRINTF(dynS->getDynStrandId(), "[Not Issue] MulticastPolicy.\n");
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MulticastPolicy);
      return nullptr;
    }
  }

  /**
   * Check if we have reached issue limit for this stream. Only do
   * this for streams with core user.
   */
  const auto curCycle = this->controller->curCycle();
  if (dynS->shouldUpdateIssueClearCycle()) {
    if (curCycle < dynS->prevIssuedCycle + dynS->issueClearCycle) {
      // We can not issue yet.
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                     "[Not Issue] IssueClearCycle %s Current %s.\n",
                     dynS->issueClearCycle, curCycle - dynS->prevIssuedCycle);
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::IssueClearCycle);
      return nullptr;
    }
  }

  /**
   * Enforce the per stream maxInflyRequests constraint.
   * PointerChaseStream always has at most one infly request.
   */
  if (dynS->inflyRequests == dynS->getMaxInflyRequests()) {
    LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                   "[Not Issue] MaxInflyReqs %d.\n",
                   dynS->getMaxInflyRequests());
    statistic.sampleLLCStreamEngineIssueReason(
        StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
    return nullptr;
  }

  /**
   * Check that the next address is still handled here.
   * Due to the waiting indirect element, a stream may not be
   * migrated immediately after the stream engine found the next
   * element is not handled here. In such case, we simply give up and
   * return false.
   *
   * In case of faulting, the slice will be skipped (see
   * issueDirectStream()).
   */
  auto vaddrAndMachineType = dynS->peekNextAllocVAddrAndMachineType();
  Addr vaddr = vaddrAndMachineType.first;
  auto machineType = vaddrAndMachineType.second;
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {
    if (!this->isPAddrHandledByMe(paddr, machineType)) {
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                     "[Not Issue] PendingMigrate.\n");
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::PendingMigrate);
      return nullptr;
    }
  }

  /**
   * If this stream needs to be coordinated with the PUMEngine, check that the
   * PUMEngine is done.
   */
  if (dynS->configData->needSyncWithPUMEngine()) {
    auto nextElemIdx = dynS->peekNextAllocElemIdx();
    auto waitForPUMRounds = dynS->configData->waitForPUMRounds(nextElemIdx);
    if (this->pumEngine->shouldWaitPUMRound(
            dynS->configData->pumContextId, waitForPUMRounds,
            dynS->configData->waitPUMRoundStart)) {
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynS->getDynStrandId(),
                     "[Not Issue] Elem %lu Waiting for PUM Round %ld.\n",
                     nextElemIdx, waitForPUMRounds);
      statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::WaitingPUM);
      return nullptr;
    }
  }

  /**
   * Allocate the element on Atomic and StoreStream.
   * Additional check on StoreStream, which should have StoreValue
   * ready.
   */
  if (S->isStoreComputeStream() || S->isAtomicComputeStream()) {
    auto nextSlice = dynS->getNextAllocSlice();
    if (!nextSlice) {
      LLC_S_PANIC(dynS->getDynStrandId(), "Failed to get next alloc slice.");
    }
    const auto &nextSliceId = nextSlice->getSliceId();
    if (S->isStoreComputeStream()) {
      /**
       * Try to schedule compuation for each slice.
       * This is to break the limitation that only one StoreComputeSlice is
       * scheduled at one time.
       */
      for (auto iter = dynS->idxToElementMap.find(nextSliceId.getStartIdx()),
                end = dynS->idxToElementMap.end();
           iter != end; ++iter) {
        auto &elem = iter->second;
        /**
         * If the element is from next slice, we need to check that it's handled
         * here.
         */
        if (elem->idx >= nextSliceId.getEndIdx()) {
          Addr paddr;
          assert(dynS->translateToPAddr(elem->vaddr, paddr) &&
                 "Failed to translate for DirectStoreComputeStream.");
          auto elementMachineType = dynS->getFloatMachineTypeAtElem(elem->idx);
          if (!this->isPAddrHandledByMe(paddr, elementMachineType)) {
            // This element is not handled here.
            break;
          }
        }
        if (!elem->isReady()) {
          if (!elem->areBaseElemsReady() ||
              dynS->incompleteComputations >=
                  this->controller->myParams
                      ->llc_stream_engine_max_infly_computation) {
            // In order issue with maximum number incomplete
            // computations equals to the LLC SE throughput.
            break;
          }
          if (elem->areBaseElemsReady() && !elem->isComputationScheduled()) {
            this->pushReadyComputation(elem, true /* TryVectorize */);
          }
        }
      }
      for (auto idx = nextSliceId.getStartIdx(); idx < nextSliceId.getEndIdx();
           ++idx) {
        auto elem = dynS->getElemPanic(idx, "Check StoreValue Ready.");
        // Check if the element is ready.
        if (!elem->isReady()) {
          LLC_SLICE_DPRINTF_(
              LLCRubyStreamNotIssue, nextSliceId,
              "StoreValue from Elem %llu not ready, delay issuing.\n", idx);
          if (!elem->areBaseElemsReady()) {
            statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::BaseValueNotReady);
          } else {
            statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::ValueNotReady);
          }
          return nullptr;
        }
      }
    }
  }

  // We should be able to issue this stream.
  statistic.sampleLLCStreamEngineIssueReason(
      StreamStatistic::LLCStreamEngineIssueReason::Issued);
  return dynS;
}

LLCDynStreamPtr
LLCStreamEngine::findIndirectStreamReadyToIssue(LLCDynStreamPtr dynS) {

  if (!dynS->hasIndirectElemReadyToIssue()) {
    return nullptr;
  }

  // Find the indirect stream with lowest element index.
  LLCDynStreamPtr readyS = nullptr;
  uint64_t readyElementIdx = 0;
  for (auto dynIS : dynS->getAllIndStreams()) {
    auto IS = dynIS->getStaticS();
    IS->statistic.sampleLLCAliveElements(dynIS->idxToElementMap.size());
    // Enforce the per stream maxInflyRequests constraint.
    if (dynIS->inflyRequests == dynIS->getMaxInflyRequests()) {
      LLC_S_DPRINTF_(LLCRubyStreamNotIssue, dynIS->getDynStrandId(),
                     "[NotIssue] MaxInflyReqs %d.\n",
                     dynIS->getMaxInflyRequests());
      IS->statistic.sampleLLCStreamEngineIssueReason(
          StreamStatistic::LLCStreamEngineIssueReason::MaxInflyRequest);
      continue;
    }

    if (auto element = dynIS->getFirstReadyToIssueElement()) {
      auto elementIdx = element->idx;

      /**
       * Hack: We enforce ordering of alised IndirectUpdateStream
       * here.
       * TODO: Really implement the ordering scheme by piggyback the
       * previous element going to that bank and let the indrect LLC
       * SE handles ordering. However, delay issuing here actually
       * pays more overhead, so we should be okay as we are not
       * cheating for performance.
       */
      if (IS->isUpdateStream()) {
        bool hasAliasedWithPreviousElement = false;
        for (const auto &idxElement : dynIS->idxToElementMap) {
          if (idxElement.first >= elementIdx) {
            break;
          }
          const auto &prevElement = idxElement.second;
          if (prevElement->vaddr == element->vaddr &&
              !prevElement->isComputedValueReady()) {
            LLC_ELEMENT_DPRINTF(element,
                                "[NotIssue] Aliased Indirect "
                                "UpdateElement %llu %#x.\n",
                                prevElement->idx, prevElement->vaddr);
            IS->statistic.sampleLLCStreamEngineIssueReason(
                StreamStatistic::LLCStreamEngineIssueReason::
                    AliasedIndirectUpdate);
            hasAliasedWithPreviousElement = true;
            break;
          }
        }
        if (hasAliasedWithPreviousElement) {
          continue;
        }
      }

      if (!readyS || readyElementIdx > elementIdx) {
        readyS = dynIS;
        readyElementIdx = elementIdx;
      }
    }
  }

  return readyS;
}

void LLCStreamEngine::issueStreamDirect(LLCDynStream *dynS) {

  auto S = dynS->getStaticS();
  auto &statistic = S->statistic;

  // Get the next address.
  auto slice = this->allocateSlice(dynS);
  const auto &sliceId = slice->getSliceId();
  Addr vaddr = sliceId.vaddr;
  auto machineType = dynS->getFloatMachineTypeAtElem(sliceId.getStartIdx());
  Addr paddr;
  if (dynS->translateToPAddr(vaddr, paddr)) {

    // The paddr is valid. We issue request to the LLC.
    Addr vaddrLine = makeLineAddress(vaddr);
    Addr paddrLine = makeLineAddress(paddr);

    // Remember that the slice has issued.
    slice->issue();

    if (!this->isPAddrHandledByMe(paddr, machineType)) {
      LLC_S_PANIC(dynS->getDynStrandId(),
                  "Next address is not handled here %#x.", paddr);
    }

    this->incrementIssueSlice(statistic);

    // Push to the request queue.
    auto reqType = this->getDirectStreamReqType(dynS);
    if (reqType == CoherenceRequestType_GETU) {
      statistic.numLLCSentSlice++;
      S->se->numLLCSentSlice++;
      if (this->hasMergedAsMulticast(dynS)) {
        statistic.numLLCCanMulticastSlice++;
      }
    }
    auto requestIter = this->enqueueRequest(S, sliceId, vaddrLine, paddrLine,
                                            this->myMachineType(), reqType);

    if (S->isStoreStream()) {
      /**
       * For StoreStream, we build the stored data by extracting
       * overlap region from elements. Notice that we can release any
       * older elements, as later we perform the store in slice
       * granularity, not element granularity. Thus element is not
       * used anymore.
       */
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        assert(dynS->idxToElementMap.count(idx) &&
               "Missing element for StoreStream.");
        const auto &element = dynS->idxToElementMap.at(idx);
        assert(element->isReady() && "StoreElement is not ready.");

        // Compute the overlap and set the data.
        int elementOffset;
        int sliceOffset;
        int overlapSize = element->computeOverlap(
            sliceId.vaddr, sliceId.getSize(), sliceOffset, elementOffset);
        requestIter->dataBlock.setData(element->getUInt8Ptr(elementOffset),
                                       sliceOffset, overlapSize);
        requestIter->storeSize = overlapSize;
        LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                           "Get StoreValue from element %llu, line [%#x, +%d), "
                           "elementOffset %#x.\n",
                           element->idx, sliceId.vaddr + sliceOffset,
                           overlapSize, elementOffset);
      }
    }

    // Check if we track inflyRequests.
    bool hasIndirectDependent = dynS->hasIndirectDependent();
    dynS->inflyRequests++;
    LLC_SLICE_DPRINTF(sliceId, "Issue, InflyRequests + 1 = %d.\n",
                      dynS->inflyRequests);
    /**
     * Try to handle multicast for streams:
     * 1. Has multicast group.
     * 2. No indirect dependent (can be relaxed later).
     */
    if (!hasIndirectDependent && this->controller->isStreamMulticastEnabled()) {
      this->generateMulticastRequest(requestIter, dynS);
    }

  } else {

    /**
     * ! The paddr is not valid. We ignore this slice.
     */
    LLC_SLICE_DPRINTF(sliceId, "Discard due to fault.\n");
    slice->faulted();

    if (!dynS->getIndStreams().empty()) {
      // Unless this is PtrChaseIV stream.
      if (dynS->isPointerChase()) {
      } else {
        LLC_SLICE_PANIC(sliceId, "Faulted at %#x with Indirect Streams.",
                        sliceId.vaddr);
      }
    }
    statistic.numLLCFaultSlice++;
  }

  // This is also considered issued.
  dynS->prevIssuedCycle = this->controller->curCycle();
  dynS->updateIssueClearCycle();
}

CoherenceRequestType
LLCStreamEngine::getDirectStreamReqType(LLCDynStream *stream) const {
  auto reqType = CoherenceRequestType_GETH;
  auto SS = stream->getStaticS();
  switch (SS->getStreamType()) {
  case ::LLVM::TDG::StreamInfo_Type_AT:
  case ::LLVM::TDG::StreamInfo_Type_ST:
    reqType = CoherenceRequestType_STREAM_STORE;
    break;
  case ::LLVM::TDG::StreamInfo_Type_LD: {
    if (SS->isUpdateStream()) {
      reqType = CoherenceRequestType_STREAM_STORE;
    } else if (SS->isLoadComputeStream()) {
      // LoadComputeStream sends back the computed value.
      reqType = CoherenceRequestType_GETH;
    } else {
      if (auto dynS = stream->getCoreDynS()) {
        if (dynS->shouldCoreSEIssue()) {
          // We have to send back the data.
          reqType = CoherenceRequestType_GETU;
        }
      } else {
        // The dynamic stream is already released, we don't really
        // care.
      }
    }
    break;
  }
  default:
    panic("Invalid offloaded stream type.\n");
  }

  // (Override) Prefetch streams are always uncached.
  if (stream->configData->isPUMPrefetch) {
    reqType = CoherenceRequestType_GETH;
  }

  return reqType;
}

void LLCStreamEngine::issueStreamIndirect(LLCDynStream *dynIS) {

  auto element = dynIS->getFirstReadyToIssueElement();
  if (!element) {
    LLC_S_PANIC(dynIS->getDynStrandId(), "Try to issue, but no ready element.");
  }
  auto elementIdx = element->idx;
  if (dynIS->shouldIssueBeforeCommit()) {
    this->generateIndirectStreamRequest(dynIS, element);
  } else {
    // We delay issuing this after committed.
    LLC_S_DPRINTF(dynIS->getDynStrandId(),
                  "Delay Issuing for AfterCommit element %llu\n.", elementIdx);
  }
  // Don't forget to the element issued.
  dynIS->markElemIssued(elementIdx);
}

void LLCStreamEngine::generateIndirectStreamRequest(
    LLCDynStream *dynIS, LLCStreamElementPtr element) {

  auto IS = dynIS->getStaticS();
  if (IS->isReduction() || IS->isPointerChaseIndVar()) {
    LLC_S_PANIC(dynIS->getDynStrandId(),
                "Reduction is no longer handled here.");
    return;
  }

  if (IS->isStoreComputeStream() || IS->isAtomicComputeStream()) {
    this->issueIndirectStoreOrAtomicRequest(dynIS, element);
    return;
  }

  /**
   * Finally normal indirect load stream.
   */
  this->issueIndirectLoadRequest(dynIS, element);
  return;
}

void LLCStreamEngine::issueIndirectLoadRequest(LLCDynStream *dynIS,
                                               LLCStreamElementPtr element) {
  /**
   * This function handles the most basic case: IndirectLoadStream.
   */
  auto elementIdx = element->idx;
  DynStreamSliceId sliceId;
  sliceId.getDynStrandId() = dynIS->getDynStrandId();
  sliceId.getStartIdx() = elementIdx;
  sliceId.getEndIdx() = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  Addr elementVAddr = element->vaddr;
  auto elementMachineType = dynIS->getFloatMachineTypeAtElem(elementIdx);

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticS();
  auto dynCoreIS = dynIS->getCoreDynS();

  auto reqType = CoherenceRequestType_GETH;
  if (dynCoreIS && dynCoreIS->shouldCoreSEIssue()) {
    /**
     * For LoadComputeStream, we issue GETH and send back the compute
     * result. For UpdateStream, we issue GETH and send back the old
     * value.
     */
    if (!IS->isLoadComputeStream() && !IS->isUpdateStream()) {
      reqType = CoherenceRequestType_GETU;
    }
  }
  LLC_SLICE_DPRINTF(sliceId,
                    "Issue IndirectLoad InflyReq %d %s VAddr %#x CoreDynS %d "
                    "ShouldCoreSEIssue %d IsLoadCompute %d.\n",
                    dynIS->inflyRequests,
                    CoherenceRequestType_to_string(reqType), elementVAddr,
                    dynCoreIS != nullptr,
                    dynCoreIS ? dynCoreIS->shouldCoreSEIssue() : -1,
                    IS->isLoadComputeStream());

  assert(!dynIS->isPseudoOffload() &&
         "Indirect stream should never be PseudoOffload.");
  auto totalSliceSize = 0;
  auto totalSlices = 0;
  while (totalSliceSize < elementSize) {
    Addr curSliceVAddr = elementVAddr + totalSliceSize;
    // Make sure the slice is contained within one line.
    int lineOffset = curSliceVAddr % blockBytes;
    auto curSliceSize = std::min(elementSize - totalSliceSize,
                                 static_cast<int>(blockBytes) - lineOffset);
    // Here we set the slice vaddr and size.
    sliceId.vaddr = curSliceVAddr;
    sliceId.size = curSliceSize;
    Addr curSlicePAddr;
    if (dynIS->translateToPAddr(curSliceVAddr, curSlicePAddr)) {
      Addr curSliceVAddrLine = makeLineAddress(curSliceVAddr);
      Addr curSlicePAddrLine = makeLineAddress(curSlicePAddr);
      this->incrementIssueSlice(IS->statistic);
      if (reqType == CoherenceRequestType_GETU) {
        IS->statistic.numLLCSentSlice++;
        IS->se->numLLCSentSlice++;
      }

      // Push to the request queue.
      this->enqueueRequest(IS, sliceId, curSliceVAddrLine, curSlicePAddrLine,
                           elementMachineType, reqType);
      dynIS->inflyRequests++;
    } else {
      // For faulted slices, we simply ignore it.
      LLC_SLICE_DPRINTF(sliceId, "Discard due to fault, vaddr %#x.\n",
                        sliceId.vaddr);
      dynIS->getStaticS()->statistic.numLLCFaultSlice++;
    }

    totalSliceSize += curSliceSize;
    totalSlices++;
  }

  if (IS->isLoadComputeStream() && totalSlices != 1) {
    LLC_S_PANIC(dynIS->getDynStrandId(),
                "IndirectLoadComputeStream with Multi-Line Element "
                "is not supported.");
  }
}

void LLCStreamEngine::issueIndirectStoreOrAtomicRequest(
    LLCDynStream *dynIS, LLCStreamElementPtr element) {

  auto elementIdx = element->idx;
  DynStreamSliceId sliceId;
  sliceId.getDynStrandId() = dynIS->getDynStrandId();
  sliceId.getStartIdx() = elementIdx;
  sliceId.getEndIdx() = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  Addr elementVAddr = element->vaddr;
  auto elementMachineType = dynIS->getFloatMachineTypeAtElem(elementIdx);
  LLC_SLICE_DPRINTF(sliceId, "Issue IndirectStore/Atomic VAddr %#x At %s.\n",
                    elementVAddr, elementMachineType);

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticS();
  const auto &indirectConfig = dynIS->configData;

  // This is a store/atomic, we need to issue STREAM_STORE request.
  assert(elementSize <= sizeof(uint64_t) && "Oversized merged store stream.");
  if (dynIS->hasTotalTripCount()) {
    assert(elementIdx < dynIS->getTotalTripCount() &&
           "Try to store beyond TotalTripCount.");
  }

  int lineOffset = elementVAddr % blockBytes;
  assert(lineOffset + elementSize <= blockBytes &&
         "Multi-line merged store stream.");

  sliceId.vaddr = elementVAddr;
  sliceId.size = elementSize;
  Addr elementPAddr;
  if (dynIS->translateToPAddr(elementVAddr, elementPAddr)) {
    this->incrementIssueSlice(IS->statistic);
    auto vaddrLine = makeLineAddress(elementVAddr);
    auto paddrLine = makeLineAddress(elementPAddr);
    /**
     * Compute the store value.
     * If this is a MergededPedicatedStream, it is a constant value.
     * If this is a MergededLoadStoreDepStream, it is computed use
     * the StoreCallback.
     * TODO: These should be merged together.
     */
    uint64_t storeValue = 0;
    if (IS->isMergedPredicated()) {
      // TODO: This is no longer supported.
      panic("MergedPredicated is not supported for now.");
      // storeValue = indirectConfig->constUpdateValue;
    } else if (IS->isMergedLoadStoreDepStream()) {
      // Compute the value.
      auto getBaseStreamValue =
          [&element](uint64_t baseStreamId) -> StreamValue {
        return element->getBaseStreamValue(baseStreamId);
      };
      auto params = convertFormalParamToParam(indirectConfig->storeFormalParams,
                                              getBaseStreamValue);
      storeValue = indirectConfig->storeCallback->invoke(params).front();
    } else {
      assert("Unknow merged stream type.");
    }

    // Push to the request queue.
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamStore -> RequestQueue, StoreValue %lu.\n",
                       storeValue);
    bool isIdeaStore = false;
    int storeSize = sliceId.size;
    if (this->controller->isStreamIdeaStoreEnabled()) {
      isIdeaStore = true;
    } else if (this->controller->isStreamCompactStoreEnabled()) {
      /**
       * Check if we can compact.
       * This is just an approximation, as the request is sending
       * out immediately.
       * TODO: Implement a realistic compact scheme.
       */
      if (dynIS->prevStorePAddrLine == paddrLine) {
        // We can compact.
        isIdeaStore = true;
      } else {
        // As an overhead, we set StoreSize to 64 due to compaction.
        if (IS->isDirectMemStream()) {
          storeSize = RubySystem::getBlockSizeBytes();
        }
      }
    }

    dynIS->prevStorePAddrLine = paddrLine;
    dynIS->prevStoreCycle = this->controller->curCycle();
    if (isIdeaStore) {
      this->performStore(elementPAddr, elementSize,
                         reinterpret_cast<uint8_t *>(&storeValue));
      LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                         "Ideal StreamStore done with value %llu, "
                         "send back StreamAck.\n",
                         storeValue);

      const bool forceIdeaAck = true;
      this->issueStreamAckToMLC(sliceId, forceIdeaAck);
      if (!this->requestQueue.empty()) {
        this->scheduleEvent(Cycles(1));
      }
    } else {
      auto reqIter = this->enqueueRequest(IS, sliceId, vaddrLine, paddrLine,
                                          elementMachineType,
                                          CoherenceRequestType_STREAM_STORE);
      dynIS->inflyRequests++;
      auto lineOffset = sliceId.vaddr % RubySystem::getBlockSizeBytes();
      reqIter->dataBlock.setData(reinterpret_cast<uint8_t *>(&storeValue),
                                 lineOffset, sliceId.size);
      reqIter->storeSize = storeSize;
    }

  } else {
    panic("Faulted merged store stream.");
  }
}

void LLCStreamEngine::issueIndirectAtomicUnlockRequest(
    LLCDynStream *dynIS, LLCStreamElementPtr element) {

  auto elementIdx = element->idx;
  DynStreamSliceId sliceId;
  sliceId.getDynStrandId() = dynIS->getDynStrandId();
  sliceId.getStartIdx() = elementIdx;
  sliceId.getEndIdx() = elementIdx + 1;
  auto elementSize = dynIS->getMemElementSize();
  Addr elementVAddr = element->vaddr;
  auto elementMachineType = dynIS->getFloatMachineTypeAtElem(elementIdx);
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Issue IndirectStore/Atomic VAddr %#x At %s.\n",
                     elementVAddr, elementMachineType);

  const auto blockBytes = RubySystem::getBlockSizeBytes();

  auto IS = dynIS->getStaticS();

  if (!(dynIS->shouldIssueBeforeCommit() && dynIS->shouldIssueAfterCommit() &&
        IS->isAtomicComputeStream())) {
    LLC_SLICE_PANIC(sliceId, "[IndirectUnlock] Not Requiring Unlock.");
  }

  assert(elementSize <= sizeof(uint64_t) && "Oversized merged store stream.");
  if (dynIS->hasTotalTripCount()) {
    assert(elementIdx < dynIS->getTotalTripCount() &&
           "Try to store beyond TotalTripCount.");
  }

  int lineOffset = elementVAddr % blockBytes;
  assert(lineOffset + elementSize <= blockBytes &&
         "Multi-line merged store stream.");

  sliceId.vaddr = elementVAddr;
  sliceId.size = elementSize;
  Addr elementPAddr;
  if (dynIS->translateToPAddr(elementVAddr, elementPAddr)) {
    this->incrementIssueSlice(IS->statistic);
    auto vaddrLine = makeLineAddress(elementVAddr);
    auto paddrLine = makeLineAddress(elementPAddr);

    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamUnlock -> RequestQueue.\n");

    /**
     * For the second request of AtomicStream, we need to issue StreamUnlock.
     * Push to the request queue.
     */
    auto reqType = CoherenceRequestType_STREAM_UNLOCK;
    this->enqueueRequest(IS, sliceId, vaddrLine, paddrLine, elementMachineType,
                         reqType);
    dynIS->inflyRequests++;

  } else {
    panic("Faulted IndirectAtomic StreamUnlock.");
  }
}

LLCStreamEngine::RequestQueueIter LLCStreamEngine::enqueueRequest(
    Stream *S, const DynStreamSliceId &sliceId, Addr vaddrLine, Addr paddrLine,
    MachineType destMachineType, CoherenceRequestType type) {
  this->requestQueue.emplace_back(S, sliceId, paddrLine, destMachineType, type);
  auto requestQueueIter = std::prev(this->requestQueue.end());
  // To match with TLB interface, we first create a fake packet.
  auto cpuDelegator = S->getCPUDelegator();
  auto tc = cpuDelegator->getSingleThreadContext();
  RequestPtr req = std::make_shared<Request>(paddrLine, sliceId.getSize(), 0,
                                             cpuDelegator->dataMasterId());
  // Set the vaddrLine as this is what we want to translate.
  req->setVirt(vaddrLine);
  // Simply always read request, since this is a fake request.
  auto pkt = Packet::createRead(req);
  // Do not allocate data for this fake packet.
  uint8_t *pktData = nullptr;
  pkt->dataStatic(pktData);
  // Start the translation.
  LLC_SLICE_DPRINTF(sliceId, "Enqueue %s Req: Start Translation.\n",
                    CoherenceRequestType_to_string(type));
  this->translationBuffer->addTranslation(pkt, tc, requestQueueIter);
  // Since this generates a request, we schedule a wakeup.
  this->scheduleEvent(Cycles(1));
  return requestQueueIter;
}

void LLCStreamEngine::translationCallback(PacketPtr pkt, ThreadContext *tc,
                                          RequestQueueIter reqIter) {
  assert(!reqIter->translationDone && "Translation already done.");
  reqIter->translationDone = true;
  LLC_SLICE_DPRINTF(reqIter->sliceId, "Translated %s Req.\n",
                    CoherenceRequestType_to_string(reqIter->requestType));
  // Remember to release the pkt.
  delete pkt;
}

void LLCStreamEngine::issueStreamRequestToRemoteBank(
    const LLCStreamRequest &req) {
  const auto &sliceId = req.sliceId;
  const auto paddrLine = req.paddrLine;
  auto selfMachineId = this->controller->getMachineID();

  auto destMachineType = req.destMachineType;
  if (destMachineType != MachineType::MachineType_L2Cache &&
      destMachineType != MachineType::MachineType_Directory) {
    LLC_SLICE_PANIC(sliceId, "Issue to Unsupported MachineType %s.\n",
                    destMachineType);
  }

  auto destMachineId = selfMachineId;
  bool handledHere = (destMachineType == selfMachineId.getType()) &&
                     this->isPAddrHandledByMe(req.paddrLine, destMachineType);
  if (handledHere) {
    LLC_SLICE_DPRINTF(sliceId,
                      "Issue [local] %s request vaddr %#x paddrLine %#x value "
                      "%s.\n",
                      req.requestType, sliceId.vaddr, paddrLine, req.dataBlock);

    /**
     * Check if the data is cached in reuse buffer.
     */
    if (req.requestType == CoherenceRequestType_GETH) {
      const auto &dynSId = sliceId.getDynStreamId();
      if (this->reuseBuffer->shouldCheckReuse(req.S, dynSId) &&
          this->reuseBuffer->contains(sliceId, paddrLine)) {
        LLC_SLICE_DPRINTF(sliceId,
                          "Reuse [local] %s request vaddr %#x paddrLine %#x.\n",
                          req.requestType, sliceId.vaddr, paddrLine);

        req.S->statistic.numRemoteReuseSlice++;

        const auto &reuseDataBlock =
            this->reuseBuffer->reuse(sliceId, paddrLine);

        /**
         * We charge 4 cycle delay.
         */
        Cycles reuseDelayCycles(4);
        DynStreamSliceIdVec sliceIds;
        sliceIds.add(sliceId);
        DataBlock fakeStoreValueBlock;
        this->receiveStreamDataVec(reuseDelayCycles, paddrLine, sliceIds,
                                   reuseDataBlock, fakeStoreValueBlock);

        return;
      }
    }

  } else {
    destMachineId =
        this->controller->mapAddressToLLCOrMem(paddrLine, destMachineType);
    LLC_SLICE_DPRINTF(
        sliceId,
        "Issue [remote] %s request to %s paddr %#x inqueue %d buffered %d "
        "value %s.\n",
        req.requestType, destMachineId, paddrLine,
        this->streamIndirectIssueMsgBuffer->getSize(curTick()),
        this->indReqBuffer->getTotalBufferedRequests(), req.dataBlock);
  }

  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = req.requestType;
  msg->m_Requestors.add(MachineID(MachineType::MachineType_L1Cache,
                                  sliceId.getDynStreamId().coreId));
  msg->m_Destination.add(destMachineId);
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_sliceIds.add(sliceId);

  // We need to set hold the store value.
  if (req.requestType == CoherenceRequestType_STREAM_STORE) {
    msg->m_streamStoreBlk = req.dataBlock;
    if (req.storeSize > 8) {
      // We model this as a whole cache line put back.
      msg->m_MessageSize = MessageSizeType_Response_Data;
    }
  } else if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
    msg->m_DataBlk = req.dataBlock;
    msg->m_sendToStrandId = req.forwardToStrandId;
    /**
     * We model special size for StreamForward request.
     */
    msg->m_MessageSize = this->controller->getMessageSizeType(req.payloadSize);
  }

  if (Debug::LLCRubyStreamMulticast && !req.multicastSliceIds.empty()) {
    std::stringstream ss;
    for (const auto &multicastSliceId : req.multicastSliceIds) {
      auto mlcMachineID =
          MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                    multicastSliceId.getDynStreamId().coreId);
      ss << ' ' << mlcMachineID;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamMulticast, sliceId, "Multicast to %s.\n",
                       ss.str());
  }

  for (const auto &multicastSliceId : req.multicastSliceIds) {
    // TODO: We should really also pass on the sliceId.
    auto mlcMachineID =
        MachineID(static_cast<MachineType>(selfMachineId.type - 1),
                  multicastSliceId.getDynStreamId().coreId);
    msg->m_Requestors.add(mlcMachineID);
    msg->m_sliceIds.add(multicastSliceId);
  }

  if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
    auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
    if (dynS) {
      auto totalNodesBeforeLLC =
          MachineType_base_number(MachineType::MachineType_L2Cache);
      dynS->getStaticS()->statistic.sampleLLCSendTo(
          selfMachineId.getRawNodeID() - totalNodesBeforeLLC,
          destMachineId.getRawNodeID() - totalNodesBeforeLLC);
    }
  }

  if (handledHere) {
    // Quick path for StreamForward to myself.
    if (req.requestType == CoherenceRequestType_STREAM_FORWARD) {
      this->receiveStreamForwardRequest(*msg);
      return;
    }
    /**
     * Quick path for the second request to release an indirect
     * atomic.
     */
    if (this->tryToProcessIndirectAtomicUnlockReq(*msg)) {
      return;
    }
    Cycles latency(1);
    this->streamIssueMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
  } else {
    /**
     * Issue to StreamRequestBuffer to enforce
     * MaxInqueueRequestPerStream.
     */
    this->indReqBuffer->pushRequest(msg);
  }
}

LLCStreamEngine::ResponseMsgPtr LLCStreamEngine::createStreamMsgToMLC(
    const DynStreamSliceId &sliceId, CoherenceResponseType type, Addr paddrLine,
    const uint8_t *data, int dataSize, int payloadSize, int lineOffset) {
  auto selfMachineId = this->controller->getMachineID();
  MachineID mlcMachineId(MachineType::MachineType_L1Cache,
                         sliceId.getDynStreamId().coreId);

  auto msg = std::make_shared<ResponseMsg>(this->controller->clockEdge());
  // For StreamAck, we do not care about the address?
  msg->m_addr = paddrLine;
  msg->m_Type = type;
  msg->m_Sender = selfMachineId;
  msg->m_Destination.add(mlcMachineId);
  msg->m_MessageSize = MessageSizeType_Response_Control;
  msg->m_sliceIds.add(sliceId);
  // Try to copy data.
  if (data) {
    assert(lineOffset + dataSize <= RubySystem::getBlockSizeBytes());
    msg->m_DataBlk.setData(data, lineOffset, dataSize);
    msg->m_MessageSize = this->controller->getMessageSizeType(payloadSize);
  }
  return msg;
}

void LLCStreamEngine::issueStreamMsgToMLC(ResponseMsgPtr msg, bool forceIdea) {

  auto mlcMachineId = msg->m_Destination.singleElement();
  const auto &sliceId = msg->m_sliceIds.singleSliceId();

  if (forceIdea) {
    auto mlcController =
        AbstractStreamAwareController::getController(mlcMachineId);
    auto mlcSE = mlcController->getMLCStreamEngine();
    // StreamAck is also disguised as StreamData.
    mlcSE->receiveStreamData(*msg);
    LLC_SLICE_DPRINTF(sliceId, "Send ideal %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  } else {
    /**
     * This should match with LLC controller l2_response_latency.
     * TODO: Really get this value from the controller.
     */
    Cycles latency(2);
    this->streamResponseMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
    LLC_SLICE_DPRINTF(sliceId, "Send %s to MLC.\n",
                      CoherenceResponseType_to_string(msg->m_Type));
  }
}

void LLCStreamEngine::issueStreamAckToMLC(const DynStreamSliceId &sliceId,
                                          bool forceIdea) {

  // For StreamAck, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_ACK, paddrLine, nullptr, 0, 0, 0);
  if (this->controller->isStreamIdeaAckEnabled()) {
    forceIdea = true;
  }
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDoneToMLC(const DynStreamSliceId &sliceId,
                                           bool forceIdea) {

  // For StreamDone, we do not care about the address?
  auto paddrLine = 0;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_DONE, paddrLine, nullptr, 0, 0, 0);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamRangesToMLC() {
  if (!this->controller->isStreamRangeSyncEnabled()) {
    return;
  }
  for (auto stream : this->streams) {
    auto &rangeBuilder = stream->getRangeBuilder();
    if (!rangeBuilder->hasReadyRanges()) {
      continue;
    }
    auto range = rangeBuilder->popReadyRange();
    /**
     * For DirectStream without IndirectStreams, we issue
     * immediately, as the MLC should really be the one creating this
     * range.
     */
    bool isDirectRange = !stream->isIndirect() &&
                         stream->getIndStreams().empty() &&
                         !stream->isPointerChase();
    bool isIdeal =
        isDirectRange && this->controller->myParams->mlc_generate_direct_range;
    LLC_SE_DPRINTF_(StreamRangeSync, "Issue %s %s range to MLC: %s.\n",
                    isDirectRange ? "direct" : "mixed",
                    isIdeal ? "idea" : "real", *range);

    this->issueStreamRangeToMLC(range, isIdeal);
  }
}

void LLCStreamEngine::issueStreamRangeToMLC(DynStreamAddressRangePtr &range,
                                            bool forceIdea) {
  // Create a fake paddr and slice id.
  Addr paddrLine = 0;
  DynStreamSliceId sliceId;
  sliceId.elementRange = range->elementRange;
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_STREAM_RANGE, paddrLine, nullptr, 0, 0, 0);
  msg->m_range = range;
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToMLC(const DynStreamSliceId &sliceId,
                                           Addr paddrLine, const uint8_t *data,
                                           int dataSize, int payloadSize,
                                           int lineOffset, bool forceIdea) {
  auto msg = this->createStreamMsgToMLC(
      sliceId, CoherenceResponseType_DATA_EXCLUSIVE, paddrLine, data, dataSize,
      payloadSize, lineOffset);
  this->issueStreamMsgToMLC(msg, forceIdea);
}

void LLCStreamEngine::issueStreamDataToLLC(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const DataBlock &dataBlock,
    const CacheStreamConfigureData::DepEdge &sendToEdge, int payloadSize) {
  /**
   * Unlike sending data to MLC, we have to calculate the virtual
   * address of the receiving stream and translate that. Also, we can
   * only handle the simpliest case so far: no spliting, and no
   * multi-line receiver element.
   *
   * Now that we have strands, we have to be careful translating between
   * StreamElemIdx and StrandElemIdx.
   *
   * SendStrandElemIdx -> SendStreamElemIdx -> RecvStreamElemIdx
   */
  auto recvConfig = sendToEdge.data;

  auto convertSendStrandElemIdxToRecvStreamElemIdx =
      [dynS, &sendToEdge](uint64_t sendStrandElemIdx) -> uint64_t {
    auto sendStreamElemIdx =
        dynS->configData->getStreamElemIdxFromStrandElemIdx(sendStrandElemIdx);
    auto recvStreamElemIdx = CacheStreamConfigureData::convertBaseToDepElemIdx(
        sendStreamElemIdx, sendToEdge.reuse, sendToEdge.skip);
    return recvStreamElemIdx;
  };

  auto getRecvElemVAddr = [&recvConfig](uint64_t recvStreamElemIdx) -> Addr {
    assert(!recvConfig->isStrandConfig() &&
           "RecvConfig should be StreamConfig");
    auto recvElemVAddr =
        recvConfig->addrGenCallback
            ->genAddr(recvStreamElemIdx, recvConfig->addrGenFormalParams,
                      getStreamValueFail)
            .front();
    return recvElemVAddr;
  };

  auto sendStrandElemIdx = sliceId.getStartIdx();
  if (dynS->isOneIterationBehind()) {
    assert(sendStrandElemIdx > 0);
    sendStrandElemIdx--;
  }
  auto recvStreamElemIdx =
      convertSendStrandElemIdxToRecvStreamElemIdx(sendStrandElemIdx);
  auto recvStrandId =
      recvConfig->getStrandIdFromStreamElemIdx(recvStreamElemIdx);

  if (Debug::LLCRubyStreamBase) {
    auto sendStreamElemIdx =
        dynS->configData->getStreamElemIdxFromStrandElemIdx(sendStrandElemIdx);
    auto recvStrandId =
        recvConfig->getStrandIdFromStreamElemIdx(recvStreamElemIdx);
    auto recvStrandElemIdx =
        recvConfig->getStrandElemIdxFromStreamElemIdx(recvStreamElemIdx);
    LLC_SLICE_DPRINTF(
        sliceId,
        "[LLCFwd] SendStrandElemIdx %lu SendStreamElemIdx %lu R/S %ld/%ld -> "
        "RecvStreamElemIdx %lu RecvStrand %s RecvStrandElemIdx %lu.\n",
        sendStrandElemIdx, sendStreamElemIdx, sendToEdge.reuse, sendToEdge.skip,
        recvStreamElemIdx, recvStrandId, recvStrandElemIdx);
  }

  auto recvElemVAddr = getRecvElemVAddr(recvStreamElemIdx);
  auto recvElemVAddrEnd = recvElemVAddr + recvConfig->elementSize;

  // Check that receiver does not across lines.
  for (auto sendStrandElemIdx = sliceId.getStartIdx() + 1;
       sendStrandElemIdx < sliceId.getEndIdx(); ++sendStrandElemIdx) {

    auto recvStreamElemIdx =
        convertSendStrandElemIdxToRecvStreamElemIdx(sendStrandElemIdx);

    auto newRecvStrandId =
        recvConfig->getStrandIdFromStreamElemIdx(recvStreamElemIdx);
    assert(newRecvStrandId == recvStrandId && "Forward to MultiStrand.");

    auto vaddr = getRecvElemVAddr(recvStreamElemIdx);
    auto vaddrEnd = vaddr + recvConfig->elementSize;

    recvElemVAddr = std::min(recvElemVAddr, vaddr);
    recvElemVAddrEnd = std::max(recvElemVAddrEnd, vaddrEnd);
  }

  auto recvElemVAddrLine = makeLineAddress(recvElemVAddr);
  auto recvElemVAddrEndLine = makeLineAddress(recvElemVAddr);
  if (recvElemVAddrLine != recvElemVAddrEndLine) {
    LLC_SLICE_PANIC(sliceId, "Multiline StreamForward Receiver: %s.",
                    recvConfig->dynamicId);
  }

  Addr recvElemPAddrLine;
  if (dynS->translateToPAddr(recvElemVAddrLine, recvElemPAddrLine)) {
    // Now we enqueue the translation request.
    auto recvElementMachineType =
        recvConfig->floatPlan.getMachineTypeAtElem(recvStreamElemIdx);
    auto reqIter = this->enqueueRequest(
        dynS->getStaticS(), sliceId, recvElemVAddrLine, recvElemPAddrLine,
        recvElementMachineType, CoherenceRequestType_STREAM_FORWARD);

    // Remember the receiver StrandId and forwarded data block.
    reqIter->forwardToStrandId =
        recvConfig->getStrandIdFromStreamElemIdx(recvStreamElemIdx);
    reqIter->dataBlock = dataBlock;
    reqIter->payloadSize = payloadSize;
  } else {
    LLC_SLICE_PANIC(sliceId, "Translation fault on the ReceiverStream: %s.",
                    recvConfig->dynamicId);
  }
}

void LLCStreamEngine::issueStreamDataToPUM(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const DataBlock &dataBlock,
    const CacheStreamConfigureData::DepEdge &sendToEdge, int payloadSize) {
  /**
   * Unlike sending Data to another Stream, sending Data to PUM usually involves
   * multicasting. We first get the SubRegion for multicast, and then determine
   * the receiving banks and masks.
   */
  auto recvConfig = sendToEdge.data;

  assert(sliceId.getNumElements() == 1 && "Coalesced SendToPUM stream.");
  assert(!dynS->isOneIterationBehind() && "PUMSendTo with OneIterBehind.");

  auto strandElemIdx = sliceId.getStartIdx();
  auto streamElemIdx =
      dynS->configData->getStreamElemIdxFromStrandElemIdx(strandElemIdx);

  auto broadcastPat = sendToEdge.broadcastPat;
  int64_t adjustStart = sendToEdge.recvPat(streamElemIdx);
  LLC_SLICE_DPRINTF(sliceId,
                    "[PUMSendTo] StreamElemIdx %lu BroadcastPat %s RecvPat %s "
                    "AdjustStart %ld.\n",
                    streamElemIdx, broadcastPat, sendToEdge.recvPat,
                    adjustStart);

  broadcastPat.start += adjustStart;

  DataMoveCompiler compiler(StreamNUCAMap::getPUMHWConfig(),
                            sendToEdge.recvTile);

  // Split the broadcast SubRegion into masks.
  AffinePatternVecT bitline_masks;
  AffinePatternVecT tile_masks;
  compiler.generateSubRegionMasks(broadcastPat, bitline_masks, tile_masks);
  if (Debug::LLCStreamPUM) {
    LLC_SLICE_DPRINTF(sliceId, "[PUMSendTo] ---- Get masks Broadcast %s.\n",
                      broadcastPat);
    for (int i = 0; i < bitline_masks.size(); ++i) {
      LLC_SLICE_DPRINTF(sliceId, "  Tile %s Bitline %s.\n", tile_masks[i],
                        bitline_masks[i]);
    }
  }

  // Intersect with each LLC bank.
  std::vector<AffinePatternVecT> llcBankSubRegions =
      compiler.getLLCBankSubRegions();
  auto numLLCBanks = llcBankSubRegions.size();
  LLC_SLICE_DPRINTF(sliceId, "[PUMSendTo] ---- Intersect with LLCSubRegion.\n");
  for (auto maskIdx = 0; maskIdx < bitline_masks.size(); ++maskIdx) {

    NetDest recvBanks;

    for (auto bankIdx = 0; bankIdx < numLLCBanks; ++bankIdx) {
      bool hasIntersection = false;
      for (const auto &llcSubRegion : llcBankSubRegions.at(bankIdx)) {
        const auto &tileMask = tile_masks[maskIdx];
        auto tileIntersect = AffinePattern::intersectSubRegions(
            compiler.tile_nums, tileMask, llcSubRegion);

        if (tileIntersect.getTotalTrip() == 0) {
          continue;
        }

        LLC_SLICE_DPRINTF(
            sliceId, "Bank %d IntersectTile %s = TileMask %s /\\ LLC %s.\n",
            bankIdx, tileIntersect, tileMask, llcSubRegion);
        hasIntersection = true;
      }

      if (hasIntersection) {
        MachineID recvMachineId(MachineType_L2Cache, bankIdx);
        recvBanks.add(recvMachineId);
      }
    }

    assert(recvBanks.count() > 0 && "No RecvBanks.");

    // Construct a packet and send out.
    this->pumEngine->sendPUMDataToLLC(sliceId, recvBanks,
                                      dynS->getMemElementSize());
    for (const auto &dstNodeId : recvBanks.getAllDest()) {
      dynS->sentPUMDataPacketMap.emplace(dstNodeId, 0).first->second++;
    }
    dynS->sentPUMPackets += recvBanks.count();
  }

  /**
   * We need to sync when we reach the end of the current ComputeRound.
   * Since elements are released out-of-order, we need to check:
   * 1. I am the first unreleased element.
   * 2. All elements between myself and the first one of the next round are
   * released.
   */
  auto elem = dynS->getElemPanic(strandElemIdx, "SendToPUM");
  elem->sentToPUM = true;
  assert(dynS->configData->needSyncWithPUMEngine() &&
         "PUMSendTo should always sync.");
  assert(!dynS->idxToElementMap.empty() && "Already no element?");
  if (dynS->idxToElementMap.begin()->first != strandElemIdx) {
    // I am not the first unreleased one yet. Nothing to do.
    return;
  }

  auto waitPUMRound = dynS->configData->waitForPUMRounds(strandElemIdx);
  auto nextRoundStrandElemIdx =
      dynS->configData->getFirstPUMRoundElemIdx(waitPUMRound + 1);
  LLC_SLICE_DPRINTF(sliceId,
                    "[PUMSendTo] WaitRound %ld NextRoundFirstStrandElemIdx %lu "
                    "TotalSentPkts %ld.\n",
                    waitPUMRound, nextRoundStrandElemIdx, dynS->sentPUMPackets);
  bool allElemInCurrentRoundSent = true;
  for (auto elemIdx = strandElemIdx + 1; elemIdx < nextRoundStrandElemIdx;
       ++elemIdx) {
    auto elem = dynS->getElem(elemIdx);
    if (!elem || !elem->sentToPUM) {
      // This is not allocated yet.
      allElemInCurrentRoundSent = false;
      break;
    }
  }
  if (!allElemInCurrentRoundSent) {
    return;
  }

  // We have reached the end of one round.
  LLC_SLICE_DPRINTF(sliceId, "[PUMSendTo] Reached the end of OneRound.\n");
  this->pumEngine->sendSyncToLLCs(dynS->sentPUMDataPacketMap, sliceId);
  auto sentPUMPkts = dynS->sentPUMPackets;
  dynS->sentPUMPackets = 0;
  dynS->sentPUMDataPacketMap.clear();
  this->pumEngine->sendSyncToMLC(sentPUMPkts);
}

void LLCStreamEngine::issuePUMPrefetchStreamDataToLLC(
    LLCDynStreamPtr stream, const DynStreamSliceId &sliceId,
    const DataBlock &dataBlock) {

  auto vaddr = sliceId.vaddr;
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Failed to Translate PUMPrefetchStream.");

  auto paddrLine = makeLineAddress(paddr);
  auto destLLCBank =
      this->controller->mapAddressToLLCOrMem(paddrLine, MachineType_L2Cache);

  LLC_SLICE_DPRINTF(sliceId, "[PUMPrefetch] Send PUMPrefetchData to %s.\n",
                    destLLCBank);

  NetDest recvBanks;
  recvBanks.add(destLLCBank);
  bool isPUMPrefetch = true;
  this->pumEngine->sendPUMDataToLLC(
      sliceId, recvBanks, RubySystem::getBlockSizeBytes(), isPUMPrefetch);
  for (const auto &dstNodeId : recvBanks.getAllDest()) {
    stream->sentPUMDataPacketMap.emplace(dstNodeId, 0).first->second++;
  }
  stream->sentPUMPackets += recvBanks.count();
}

void LLCStreamEngine::tryFinishPUMPrefetchStream(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {
  assert(dynS->hasTotalTripCount());

  auto tc = dynS->getTotalTripCount();
  auto elemIdx = sliceId.getEndIdx();

  if (elemIdx >= tc) {
    LLC_SLICE_DPRINTF(sliceId, "PUM prefetch done.\n");
    MachineID mlcMachineID(MachineType_L1Cache, dynS->getDynStreamId().coreId);
    auto mlcCtrl = AbstractStreamAwareController::getController(mlcMachineID);
    auto mlcSE = mlcCtrl->getMLCStreamEngine();

    assert(mlcSE);

    mlcSE->notifyMLCPUMManagerPrefetchDone(dynS->sentPUMPackets);
  }
}

void LLCStreamEngine::sendOffloadedLoopBoundRetToMLC(LLCDynStreamPtr stream,
                                                     uint64_t totalTripCount,
                                                     Addr brokenPAddr) {
  auto mlcSE = stream->getMLCController()->getMLCStreamEngine();
  assert(mlcSE && "Missing MLC SE.");
  mlcSE->receiveStreamTotalTripCount(
      stream->getDynStrandId(), totalTripCount, brokenPAddr,
      this->controller->getMachineID().getType());
}

void LLCStreamEngine::findMigratingStreams() {
  // Scan all streams for migration target.
  auto streamIter = this->streams.begin();
  auto streamEnd = this->streams.end();
  while (streamIter != streamEnd) {
    auto stream = *streamIter;
    if (this->canMigrateStream(stream)) {
      this->migratingStreams.emplace_back(stream);
      streamIter = this->streams.erase(streamIter);
    } else {
      ++streamIter;
    }
  }
}

void LLCStreamEngine::migrateStreams() {
  auto streamIter = this->migratingStreams.begin();
  auto streamEnd = this->migratingStreams.end();
  int migrated = 0;
  /**
   * We limit the number of inqueue migrating streams.
   */
  while (streamIter != streamEnd && migrated < this->migrateWidth &&
         this->streamMigrateMsgBuffer->getSize(curTick()) < 2) {
    auto stream = *streamIter;
    assert(this->canMigrateStream(stream) && "Can't migrate stream.");
    /**
     * Check the migrate controller.
     */
    auto nextVAddrAndMachineType = stream->peekNextAllocVAddrAndMachineType();
    auto nextVAddr = nextVAddrAndMachineType.first;
    auto nextMachineType = nextVAddrAndMachineType.second;
    Addr nextPAddr;
    if (!stream->translateToPAddr(nextVAddr, nextPAddr)) {
      LLC_S_PANIC(stream->getDynStrandId(), "Fault on migrating stream.");
    }
    auto nextMachineId = this->controller->mapAddressToLLCOrMem(
        makeLineAddress(nextPAddr), nextMachineType);
    if (!this->migrateController->canMigrateTo(stream, nextMachineId)) {
      ++streamIter;
      continue;
    }
    this->migrateStream(stream);
    this->migrateController->startMigrateTo(stream, nextMachineId);
    streamIter = this->migratingStreams.erase(streamIter);
    migrated++;
  }
}

void LLCStreamEngine::migrateStream(LLCDynStream *stream) {

  // Create the migrate request.
  auto vaddrAndMachineType = stream->peekNextAllocVAddrAndMachineType();
  Addr vaddr = vaddrAndMachineType.first;
  auto machineType = vaddrAndMachineType.second;
  Addr paddr;
  assert(stream->translateToPAddr(vaddr, paddr) &&
         "Migrating streams should have valid paddr.");
  Addr paddrLine = makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddrLine, machineType);

  LLC_S_DPRINTF(stream->getDynStrandId(),
                "Migrate to %s, InflyReq %d AdvancedMigration %d IndirectS "
                "%d. Remain DirectStreams %llu.\n",
                addrMachineId, stream->inflyRequests,
                this->controller->isStreamAdvanceMigrateEnabled(),
                stream->getIndStreams().size(), this->streams.size());

  auto msg =
      std::make_shared<StreamMigrateRequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  msg->m_MessageSize = MessageSizeType_Data;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));

  this->removeStreamFromMulticastTable(stream);

  stream->migratingStart();
}

void LLCStreamEngine::migrateStreamCommit(LLCDynStream *stream, Addr paddr,
                                          MachineType machineType) {
  // Create the migrate request.
  Addr paddrLine = makeLineAddress(paddr);
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddrLine, machineType);

  LLC_S_DPRINTF_(StreamRangeSync, stream->getDynStrandId(),
                 "[Commit] Migrate to LLC%d.\n", addrMachineId.num);

  auto msg =
      std::make_shared<StreamMigrateRequestMsg>(this->controller->clockEdge());
  msg->m_addr = paddrLine;
  msg->m_Type = CoherenceRequestType_STREAM_MIGRATE;
  msg->m_Requestor = selfMachineId;
  msg->m_Destination.add(addrMachineId);
  // Migrating CommitHead is just a control message.
  msg->m_MessageSize = MessageSizeType_Control;
  msg->m_IsCommit = true;
  msg->m_Stream = stream;

  Cycles latency(1); // Just use 1 cycle latency here.

  this->streamMigrateMsgBuffer->enqueue(
      msg, this->controller->clockEdge(),
      this->controller->cyclesToTicks(latency));
}

MachineID LLCStreamEngine::mapPaddrToSameLevelBank(Addr paddr) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddr, selfMachineId.type);
  return addrMachineId;
}

bool LLCStreamEngine::isPAddrHandledByMe(Addr paddr,
                                         MachineType machineType) const {
  auto selfMachineId = this->controller->getMachineID();
  auto addrMachineId =
      this->controller->mapAddressToLLCOrMem(paddr, machineType);
  return addrMachineId == selfMachineId;
}

void LLCStreamEngine::print(std::ostream &out) const {}

void LLCStreamEngine::receiveStreamIndirectRequest(const RequestMsg &req) {

  this->receiveStreamIndirectRequestImpl(req);

  /**
   * Unchain each indirect requests and call receiveStreamIndirectRequestImpl().
   */
  auto chainMsg = req.getChainMsg();
  while (chainMsg) {

    auto chainReq = std::dynamic_pointer_cast<RequestMsg>(chainMsg);
    assert(chainReq && "Should be RequsetMsg.");

    const auto &chainSliceId = chainReq->m_sliceIds.singleSliceId();
    const auto &chainReqNetDest = chainReq->getDestination();
    if (chainReqNetDest.count() != 1) {
      LLC_SLICE_PANIC(chainSliceId, "[Multicast] ChainReq Invalid Dest %s.",
                      chainReqNetDest);
    }

    auto chainReqDest = chainReqNetDest.singleElement();
    if (chainReqDest == this->controller->getMachineID()) {
      /**
       * This is for us. We recursively call receiveStreamIndirectRequest.
       */
      LLC_SLICE_DPRINTF_(
          LLCRubyStreamMulticast, chainSliceId,
          "[Multicast] Unchain [indirect] %s to %s PaddrLine %#x.\n",
          chainReq->m_Type, chainReqDest, chainReq->m_addr);

      // Record the Mulitcast.
      if (auto dynS =
              LLCDynStream::getLLCStream(chainSliceId.getDynStrandId())) {
        auto &statistic = dynS->getStaticS()->statistic;
        statistic.numRemoteMulticastSlice++;
      }

      this->receiveStreamIndirectRequestImpl(*chainReq);
    } else {
      /**
       * Skip this ChainReq and go to the next one.
       */
      LLC_SLICE_DPRINTF_(
          LLCRubyStreamMulticast, chainSliceId,
          "[Multicast] Ignore [indirect] %s ChainReq to %s PaddrLine %#x.\n",
          chainReq->m_Type, chainReqDest, chainReq->m_addr);
    }
    chainMsg = chainReq->getChainMsg();
  }
}

void LLCStreamEngine::receiveStreamIndirectRequestImpl(const RequestMsg &req) {

  this->initializeTranslationBuffer();

  // Simply copy and inject the msg to L1 request in.
  const auto &sliceId = req.m_sliceIds.singleSliceId();
  assert(sliceId.isValid() && "Invalid stream slice for indirect request.");

  auto networkLatency =
      this->curCycle() - this->controller->ticksToCycles(req.getTime());
  LLC_SLICE_DPRINTF(sliceId,
                    "Receive [indirect] %s request paddrLine %#x delay cycle "
                    "%s.\n",
                    CoherenceRequestType_to_string(req.m_Type), req.m_addr,
                    networkLatency);

  if (req.m_Type == CoherenceRequestType_STREAM_FORWARD) {
    // Quick path for stream forwarding.
    this->receiveStreamForwardRequest(req);
    return;
  }

  if (this->tryToProcessIndirectAtomicUnlockReq(req)) {
    // Quick path for the second request to release an indirect
    // atomic.
    return;
  }

  // Record the NoC latency for the indirect request.
  // Search through all streams.
  if (auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId())) {
    auto &statistic = dynS->getStaticS()->statistic;
    statistic.remoteIndReqNoCDelay.sample(networkLatency);
  }

  auto msg = std::make_shared<RequestMsg>(req);
  Cycles latency(1);
  this->streamIssueMsgBuffer->enqueue(msg, this->controller->clockEdge(),
                                      this->controller->cyclesToTicks(latency));
}

void LLCStreamEngine::receivePUMConfigure(const RequestMsg &req) {
  this->pumEngine->receiveKick(req);
}

void LLCStreamEngine::receivePUMData(const RequestMsg &req) {
  this->pumEngine->receiveData(req);
}

void LLCStreamEngine::receiveStreamForwardRequest(const RequestMsg &req) {
  this->processStreamForwardRequest(req);
}

void LLCStreamEngine::processStreamForwardRequest(const RequestMsg &req) {

  const auto &sliceId = req.m_sliceIds.singleSliceId();
  const auto &recvDynId = req.m_sendToStrandId;
  // Search through the direct streams.
  auto dynS = LLCDynStream::getLLCStream(recvDynId);
  if (!dynS) {
    // Failed to find the stream (may be terminated). Try NDC.
    this->ndcController->receiveStreamForwardRequest(req);
    LLC_SLICE_DPRINTF(sliceId, "Cannot find the direct receiver: %s.\n",
                      recvDynId);
    return;
  }
  /**
   * Sample the LLC forward latency.
   */
  auto sendCycle = this->controller->ticksToCycles(req.getTime());
  auto latency = this->curCycle() - sendCycle;
  LLC_SLICE_DPRINTF(sliceId, "[Fwd] Received by %s. Latency %llu.\n", recvDynId,
                    latency);
  if (auto sender = LLCDynStream::getLLCStream(sliceId.getDynStrandId())) {
    sender->getStaticS()->statistic.remoteForwardNoCDelay.sample(latency);
  }

  /**
   * Normally we search for the receiver in myself and my indirect
   * stream. However, there is a special case: I am the sender! This
   * is used so far to implement IndirectReductionS that dependent
   * both on the BackBaseIndirectS and BackBaseDirectS:
   *
   * BaseBaseDirectS -> BackBaseIndirectS -> IndirectReductionS.
   *  |                                              |
   *  ----------------------->>>---------------------
   *
   * In such case, we only search in my Two-Level IndirectS...
   */
  bool foundReceiver = false;
  if (sliceId.getDynStreamId() != dynS->getDynStreamId()) {
    // Search for receiver in myself and my indirect streams.
    if (dynS->isBasedOn(sliceId.getDynStreamId())) {
      foundReceiver = true;
      for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
        dynS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
      }
    }

    for (auto dynIS : dynS->getIndStreams()) {
      if (dynIS->isBasedOn(sliceId.getDynStreamId())) {
        foundReceiver = true;
        for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
             ++idx) {
          dynIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
        }
      }
    }
  } else {
    // Sender is myself. Search for Two-Level Indirection.
    for (auto dynIS : dynS->getIndStreams()) {
      for (auto dynIIS : dynIS->getIndStreams()) {
        if (dynIIS->isBasedOn(sliceId.getDynStreamId())) {
          foundReceiver = true;
          for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx();
               ++idx) {
            dynIIS->recvStreamForward(this, idx, sliceId, req.m_DataBlk);
          }
        }
      }
    }
  }
  if (!foundReceiver) {
    LLC_SLICE_PANIC(sliceId, "Cannot find the receiver: %s.", recvDynId);
  }
}

bool LLCStreamEngine::tryToProcessIndirectAtomicUnlockReq(
    const RequestMsg &req) {
  if (req.m_Type != CoherenceRequestType_STREAM_UNLOCK) {
    // Not single slice id or store request.
    return false;
  }

  /**
   * This is the second request to unlock the line of indirect
   * atomic. We just send back the Ack.
   */
  if (req.m_sliceIds.sliceIds.size() != 1) {
    LLC_SLICE_PANIC(req.m_sliceIds.firstSliceId(),
                    "[Commit] Multi-Slice for IndirectAtomicUnlock.");
  }

  const auto &sliceId = req.m_sliceIds.singleSliceId();
  auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId());
  if (!dynS) {
    // Failed to find the DynStream.
    LLC_SLICE_PANIC(
        sliceId, "[Commit] Failed to find LLCDynS for IndirectAtomicUnlock.");
  }
  auto S = dynS->getStaticS();
  if (!(S->isAtomicComputeStream() && dynS->isIndirect() &&
        dynS->shouldIssueBeforeCommit() && dynS->shouldIssueAfterCommit())) {
    LLC_SLICE_PANIC(sliceId, "[Commit] Not IndirectAtomicStream with Unlock.");
  }
  auto elementIdx = sliceId.getStartIdx();
  assert(sliceId.getNumElements() == 1 &&
         "Multi-Element slice for IndirectAtomicStream.");
  auto element = dynS->getElemPanic(elementIdx, "IndirectAtomicUnlock");
  if (!element->hasFirstIndirectAtomicReqSeen()) {
    LLC_SLICE_PANIC(sliceId, "[Commit] Has not seen FirstIndirectAtomicReq.");
  }
  // Update inflyRequests.
  if (dynS->inflyRequests == 0) {
    LLC_SLICE_PANIC(sliceId, "Negative inflyRequests.\n");
  }
  dynS->inflyRequests--;

  LLC_SLICE_DPRINTF_(StreamRangeSync, sliceId,
                     "[Commit] Atomic released. Remaining Elements %llu.\n",
                     dynS->idxToElementMap.size());
  Addr elementPAddr;
  assert(dynS->translateToPAddr(element->vaddr, elementPAddr) &&
         "Fault on vaddr of LLCStore/Atomic/UpdateStream.");
  auto elementMemSize = dynS->getMemElementSize();
  if (this->controller->isStreamAtomicLockEnabled()) {
    /**
     * For now we just delay the Ack until the line is unlocked.
     */
    this->atomicLockManager->commit(elementPAddr, elementMemSize, element,
                                    true /* shouldAckAfterUnlock */, sliceId);
  } else {
    /**
     * Ideal case: Immediately send back Ack.
     */
    this->atomicLockManager->commit(elementPAddr, elementMemSize, element,
                                    false /* shouldAckAfterUnlock */, sliceId);
    this->issueStreamAckToMLC(sliceId);
  }

  /**
   * No matter what, we should release elements that are
   * unlocked.
   */
  element->setSecondIndirectAtomicReqSeen();
  while (!dynS->idxToElementMap.empty()) {
    auto elementIter = dynS->idxToElementMap.begin();
    const auto &element = elementIter->second;
    if (!element->isReady() || !element->areBaseElemsReady() ||
        !element->hasSecondIndirectAtomicReqSeen()) {
      break;
    }
    dynS->eraseElem(elementIter);
  }
  return true;
}

void LLCStreamEngine::triggerIndElem(LLCDynStreamPtr IS, uint64_t indElemIdx) {

  if (IS->hasTotalTripCount() && indElemIdx > IS->getTotalTripCount()) {
    // Ignore overflow elements.
    LLC_S_DPRINTF(IS, "[TriggerInd] Skip TotalTripCount %ld < ElemIdx %lu.\n",
                  IS->getTotalTripCount(), indElemIdx);
    return;
  }

  /**
   * We should have the indirect element. The only exception is the vectorized
   * reduction stream.
   */
  if (!IS->idxToElementMap.count(indElemIdx)) {

    if (IS->getStaticS()->isReduction() &&
        IS->lastComputedReductionElemIdx >= indElemIdx) {
      LLC_S_DPRINTF(
          IS, "[TriggerInd] Skip ReduceS LastComputedElemIdx %lu > %lu.\n",
          IS->lastComputedReductionElemIdx, indElemIdx);
      return;
    }

    LLC_S_PANIC(IS->getDynStrandId(), "Missing IndElem %llu.", indElemIdx);
  }

  auto &indElem = IS->idxToElementMap.at(indElemIdx);

  /**
   * Check if the stream has predication.
   */
  assert(!IS->isPredicated() && "Disable predication for now.");
  // Not predicated, add to readyElements.
  if (IS->baseStream->baseStream) {
    // The only type of two-level indirection is
    // Reduction/StoreCompute.
    auto ISS = IS->getStaticS();
    if (!ISS->isReduction() && !ISS->isStoreComputeStream()) {
      LLC_S_PANIC(IS->getDynStrandId(),
                  "Does not support Two-Level Indirection other than "
                  "Reduction/StoreCompute.");
    }
  }
  LLC_ELEMENT_DPRINTF(indElem, "Check if BaseElemReady %d.\n",
                      indElem->areBaseElemsReady());
  if (indElem->areBaseElemsReady()) {
    if (IS->getStaticS()->isReduction() ||
        IS->getStaticS()->isPointerChaseIndVar()) {
      if (indElem->isComputationScheduled() || indElem->isComputationDone()) {
      } else {
        // Reduction now is handled as computation.
        this->pushReadyComputation(indElem);
      }
    } else {
      IS->markElemReadyToIssue(indElemIdx);
    }
  } else {
    for (const auto &baseE : indElem->baseElements) {
      LLC_ELEMENT_DPRINTF(indElem, "BaseElements Ready %d %s %llu.\n",
                          baseE->isReady(), baseE->strandId, baseE->idx);
    }
  }
}

void LLCStreamEngine::triggerIndElems(LLCDynStreamPtr stream,
                                      LLCStreamElementPtr elem) {
  if (stream->getIndStreams().empty() && stream->predicatedStreams.empty()) {
    // There is no stream dependent on my data.
    return;
  }

  auto idx = elem->idx;
  assert(elem->isReady());

  // First we handle any indirect element.
  for (auto IS : stream->getIndStreams()) {
    auto reuse = IS->baseStreamReuse;

    /**
     * Two possible cases (can only be one of them).
     *
     * If the indirect stream is behind one iteration, base element
     * of iteration i should trigger the indirect element of
     * iteration i + 1.
     *
     * If the IndS has reuse > 1, then we need to trigger multiple IndElems.
     */
    if (reuse > 1 && IS->isOneIterationBehind()) {
      LLC_S_PANIC(IS, "IndReuse %d > 1 && OneIterBehind.", reuse);
    }

    auto skip = 0;
    auto indElemIdxLhs =
        IS->configData->convertBaseToDepElemIdx(idx, reuse, skip);
    auto indElemIdxRhs =
        IS->configData->convertBaseToDepElemIdx(idx + 1, reuse, skip);

    for (auto indElemIdx = indElemIdxLhs; indElemIdx < indElemIdxRhs;
         ++indElemIdx) {
      if (IS->isOneIterationBehind()) {
        indElemIdx = idx + 1;
      }
      this->triggerIndElem(IS, indElemIdx);
    }
  }

  assert(!stream->configData->predCallback && "Disable predication for now.");
  assert(stream->waitingPredicatedElements.empty() &&
         "No predCallback for predicated elements.");
}

void LLCStreamEngine::triggerUpdate(LLCDynStreamPtr dynS,
                                    LLCStreamElementPtr element,
                                    const DynStreamSliceId &sliceId,
                                    const DataBlock &storeValueBlock,
                                    DataBlock &loadValueBlock,
                                    uint32_t &payloadSize) {

  auto S = dynS->getStaticS();

  // Perform the operation.
  auto elementMemSize = S->getMemElementSize();
  auto elementCoreSize = S->getCoreElementSize();
  assert(elementCoreSize <= elementMemSize &&
         "CoreElementSize should not exceed MemElementSize.");
  auto elementVAddr = element->vaddr;

  Addr elementPAddr;
  assert(dynS->translateToPAddr(elementVAddr, elementPAddr) &&
         "Fault on vaddr of UpdateStream.");
  const auto lineSize = RubySystem::getBlockSizeBytes();

  /**
   * This is an update stream, and we have to handle multi-line
   * elements.
   * 1. Compute the store value if this is the first time, and
   * directly stores all the result.
   * 2. Send back the overlapped old value.
   * TODO: Really schedule the computation to model the latency.
   * TODO: Reload the value here to avoid aliased update stream.
   * TODO: Multi-Line Update should really be careful.
   */
  if (!element->isComputedValueReady()) {
    auto getStreamValue = [&element](uint64_t streamId) -> StreamValue {
      return element->getBaseOrMyStreamValue(streamId);
    };
    auto params = convertFormalParamToParam(dynS->configData->storeFormalParams,
                                            getStreamValue);
    auto storeValue = dynS->configData->storeCallback->invoke(params);

    /**
     * ! For now just record the stats.
     */
    auto numMicroOps = S->getComputationNumMicroOps();
    // For now we don't bother add the stats to the core in my bank.
    S->recordComputationInCoreStats();
    this->controller->m_statLLCScheduledComputation++;
    this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
    this->recordComputationMicroOps(S);

    element->setComputedValue(storeValue);
    assert(elementMemSize <= sizeof(storeValue) &&
           "UpdateStream size overflow.");
    for (int storedSize = 0; storedSize < elementMemSize;) {
      Addr vaddr = elementVAddr + storedSize;
      Addr paddr;
      if (!dynS->translateToPAddr(vaddr, paddr)) {
        LLC_ELEMENT_PANIC(element, "Fault on vaddr of UpdateStream.");
      }
      auto lineOffset = vaddr % lineSize;
      auto size = elementMemSize - storedSize;
      if (lineOffset + size > lineSize) {
        size = lineSize - lineOffset;
      }
      this->performStore(paddr, size, storeValue.uint8Ptr(storedSize));
      storedSize += size;
    }
    LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                       "StreamUpdate done with value %s.\n", storeValue);
  }

  /**
   * Send back the overlap value within this line.
   */
  Addr loadBlockVAddrLine = makeLineAddress(sliceId.vaddr);
  int elementOffset = 0;
  int loadBlockOffset = 0;
  auto overlapSize = element->computeOverlap(loadBlockVAddrLine, lineSize,
                                             loadBlockOffset, elementOffset);
  loadValueBlock.setData(element->getUInt8Ptr(elementOffset), loadBlockOffset,
                         overlapSize);
  payloadSize = overlapSize;
}

void LLCStreamEngine::triggerAtomic(LLCDynStreamPtr dynS,
                                    LLCStreamElementPtr element,
                                    const DynStreamSliceId &sliceId,
                                    DataBlock &loadValueBlock,
                                    uint32_t &payloadSize) {

  auto S = dynS->getStaticS();

  // Perform the operation.
  auto elementMemSize = S->getMemElementSize();
  auto elementCoreSize = S->getCoreElementSize();
  assert(elementCoreSize <= elementMemSize &&
         "CoreElementSize should not exceed MemElementSize.");
  auto elementVAddr = element->vaddr;

  // Create a single slice for this element.
  DynStreamSliceId elementSliceId;
  elementSliceId.getDynStrandId() = dynS->getDynStrandId();
  elementSliceId.getStartIdx() = element->idx;
  elementSliceId.getEndIdx() = element->idx + 1;

  Addr elementPAddr;
  assert(dynS->translateToPAddr(elementVAddr, elementPAddr) &&
         "Fault on vaddr of LLCStore/Atomic/UpdateStream.");
  auto lineOffset = elementVAddr % RubySystem::getBlockSizeBytes();
  if (lineOffset + elementMemSize > RubySystem::getBlockSizeBytes()) {
    LLC_ELEMENT_PANIC(element, "Multi-Line AtomicElement.");
  }

  // Very limited AtomicRMW support.
  auto atomicRet =
      this->performStreamAtomicOp(dynS, element, elementPAddr, elementSliceId);
  auto loadedValue = atomicRet.first;
  bool memoryModified = atomicRet.second;
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Perform StreamAtomic, RetValue %llu.\n", loadedValue);
  loadValueBlock.setData(reinterpret_cast<uint8_t *>(&loadedValue), lineOffset,
                         elementCoreSize);
  payloadSize = elementCoreSize;
  if (element->hasFirstIndirectAtomicReqSeen()) {
    LLC_ELEMENT_PANIC(element, "Perform atomic operation more than once.");
  }
  element->setFirstIndirectAtomicReqSeen();
  this->atomicLockManager->enqueue(elementPAddr, elementMemSize, element,
                                   memoryModified);
  if (!(dynS->shouldIssueBeforeCommit() && dynS->shouldIssueAfterCommit())) {
    // This AtomicStream just takes one request, we can immediately
    // commit it.
    this->atomicLockManager->commit(elementPAddr, elementMemSize, element);
  }
}

LLCStreamSlicePtr LLCStreamEngine::allocateSlice(LLCDynStreamPtr dynS) {
  auto slice = dynS->allocNextSlice(this);
  this->allocatedSlices.push_back(slice);
  return slice;
}

LLCStreamSlicePtr
LLCStreamEngine::tryGetSlice(const DynStreamSliceId &sliceId) {
  for (auto &slice : this->allocatedSlices) {
    const auto &id = slice->getSliceId();
    /**
     * We have additional check for the vaddr in case for multi-line
     * elements.
     */
    if (id == sliceId && id.vaddr == sliceId.vaddr) {
      return slice;
    }
  }
  return nullptr;
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::releaseSlice(SliceList::iterator sliceIter) {
  const auto &slice = *sliceIter;
  LLC_SLICE_DPRINTF(slice->getSliceId(), "Released.\n");
  slice->released();
  const auto &sliceId = slice->getSliceId();
  if (auto dynS = LLCDynStream::getLLCStream(sliceId.getDynStrandId())) {
    while (!dynS->idxToElementMap.empty()) {
      auto elementIter = dynS->idxToElementMap.begin();
      auto &element = elementIter->second;
      // StoreComputeStream is never ready.
      if ((element->isReady() || dynS->getStaticS()->isStoreComputeStream()) &&
          element->areSlicesReleased()) {
        if (!element->areBaseElemsReady()) {
          LLC_ELEMENT_PANIC(
              element, "Released when Ready %d ValueBaseReady %d Slices %d.",
              element->isReady(), element->areBaseElemsReady(),
              element->getNumSlices());
        }
        /**
         * We avoid releasing the element if it is the only two left
         * in idxToElementMap and it is known not the last one. This
         * is to avoid a bug when there are multi-line elements, the
         * next slice is not initialized yet, thus the element has
         * not seen all the slices and may falsely return true for
         * areSlicesReleased().
         * TODO: Handle this multi-line elements more elegantly.
         */
        if (dynS->idxToElementMap.size() > 2 ||
            (dynS->hasTotalTripCount() &&
             element->idx + 2 >= dynS->getTotalTripCount())) {
          dynS->eraseElem(elementIter);
          continue;
        }
      }
      break;
    }
  }
  return this->allocatedSlices.erase(sliceIter);
}

void LLCStreamEngine::processSlices() {
  auto iter = this->allocatedSlices.begin();
  auto end = this->allocatedSlices.end();
  while (iter != end) {
    iter = this->processSlice(iter);
  }
}

LLCStreamEngine::SliceList::iterator
LLCStreamEngine::processSlice(SliceList::iterator sliceIter) {
  auto &slice = *sliceIter;
  auto dynS = LLCDynStream::getLLCStream(slice->getSliceId().getDynStrandId());
  if (!dynS) {
    // Jesus, the LLCStream is already released.
    switch (slice->getState()) {
    default:
      LLC_SLICE_PANIC(slice->getSliceId(),
                      "LLCStream released, but slice not.");
    case LLCStreamSlice::State::ALLOCATED:
    case LLCStreamSlice::State::RESPONDED:
    case LLCStreamSlice::State::FAULTED:
      return this->releaseSlice(sliceIter);
    case LLCStreamSlice::State::ISSUED:
      // We are still waiting for the response.
      return ++sliceIter;
    }
  }
  switch (slice->getState()) {
  default:
    LLC_SLICE_PANIC(slice->getSliceId(), "Invalid state.");
  case LLCStreamSlice::State::ALLOCATED:
  case LLCStreamSlice::State::ISSUED:
    // We are still waiting for the response.
    return ++sliceIter;
  case LLCStreamSlice::State::FAULTED:
    return this->releaseSlice(sliceIter);
  case LLCStreamSlice::State::RESPONDED:
    break;
  }
  /**
   * The slice is already responded, see if we can process it.
   * So far we need to process the slice for these cases:
   * 1. AtomicComputeStream/UpdateStream.
   * This is where the write request is generated, and is done after
   * all elements are committed in the core (if RangeSync enabled).
   * 2. LoadComputeStream.
   * This is where we schedule the computation for LoadComputeStream,
   * and send back the result to core if core needs the value. This
   * does not need to wait for committment.
   * 3. We also need to evaluate the LoopBound, specially when the slice
   * contains multiple elements.
   */

  const auto &sliceId = slice->getSliceId();
  auto S = dynS->getStaticS();
  /**
   * Check the LoopBound before we release the slice.
   */
  if (!dynS->isSliceDoneForLoopBound(sliceId)) {
    // We still need this. Check if we should try to evaluate LoopBound.
    auto nextLoopBoundElemIdx = dynS->getNextLoopBoundElemIdx();
    if (nextLoopBoundElemIdx >= sliceId.getStartIdx() &&
        nextLoopBoundElemIdx < sliceId.getEndIdx()) {
      auto element = dynS->getElemPanic(nextLoopBoundElemIdx,
                                        "Check element for LoopBound.");
      // This slice contains the last element byte.
      assert(element->isReady() && "Element should be ready for LoopBound.");
      dynS->evaluateLoopBound(this);
      assert(dynS->getNextLoopBoundElemIdx() == nextLoopBoundElemIdx + 1 &&
             "LoopBound should make progress.");
    }
    return ++sliceIter;
  }
  /**
   * For LoadComputeStream, we schedule computation if the element is
   * value ready. If all element's LoadComputeValue is ready, we send
   * back to core. Also, we have to wait until the LoadComputeValue
   * sent back to core before releasing the slice.
   */
  if (S->isLoadComputeStream()) {
    this->processLoadComputeSlice(dynS, slice);
    if (!slice->isLoadComputeValueSent()) {
      return ++sliceIter;
    }
  }
  /**
   * If this stream require RangeSync, we have to check that all
   * elements are committed in the core. One exception is for
   * IndirectLoadComputeStream, which we should release immediately.
   */
  if (dynS->shouldRangeSync() &&
      !(S->isLoadComputeStream() && dynS->isIndirect())) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElemPanic(idx, "Check element committed for update.");
      if (!element->hasCoreCommitted()) {
        // We are still waiting for the core to commit.
        return ++sliceIter;
      }
    }
  }
  if (S->isAtomicComputeStream()) {
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element =
          dynS->getElemPanic(idx, "Check base elements ready for update.");
      // LLC_SLICE_DPRINTF(
      //     sliceId, "Process for element %llu, Ready %d, BaseReady
      //     %d.\n", element->idx, element->isReady(),
      //     element->areBaseElementsReady());
      if (!element->areBaseElemsReady()) {
        // We are still waiting for base elements.
        return ++sliceIter;
      }
      /**
       * Update slice also require the element to be ready.
       * Although this has responded, a multi-slice element may still
       * not be ready.
       */
      if (S->isUpdateStream() && !element->isReady()) {
        LLC_ELEMENT_DPRINTF(element, "[Update] Slice blocked by me.\n");
        return ++sliceIter;
      }
    }
    // We can finally process it.
    this->processDirectAtomicSlice(dynS, sliceId);

  } else if (S->isUpdateStream()) {
    /**
     * DirectUpdateStream requires special handling now.
     * 1. If processed -- check if we can post-process it.
     * 2. Otherwise, process it and then wait for the computation done.
     */
    if (slice->isProcessed()) {
      if (!this->tryPostProcessDirectUpdateSlice(dynS, slice)) {
        return ++sliceIter;
      } else {
        // Fall through to be finally released.
      }
    } else {
      this->tryProcessDirectUpdateSlice(dynS, slice);
      return ++sliceIter;
    }
  }

  /**
   * We are done with this slice.
   * If this is a StoreStream with RangeSync, we send back the Ack
   * here. NOTE: For DirectStoreComputeStream with RangeSync, the
   * StreamDone message really completes the whole workflow. For
   * simplicity, here we send back Ack ideally.
   */
  if (dynS->shouldRangeSync() && S->isStoreComputeStream()) {
    bool forceIdea = false;
    if (!dynS->isIndirect()) {
      forceIdea = true;
    }
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
  return this->releaseSlice(sliceIter);
}

void LLCStreamEngine::tryStartComputeLoadComputeSlice(LLCDynStreamPtr dynS,
                                                      LLCStreamSlicePtr slice) {
  const auto &sliceId = slice->getSliceId();
  for (auto elemIdx = sliceId.getStartIdx(); elemIdx < sliceId.getEndIdx();
       ++elemIdx) {
    auto elem = dynS->getElemPanic(elemIdx, "StartComputeLoadComputeSlice");
    if (!elem->isReady()) {
      continue;
    }
    if (elem->isComputationScheduled()) {
      continue;
    }
    if (elem->isComputedValueReady()) {
      continue;
    }
    this->pushReadyComputation(elem, true /* tryVectorize */);
  }
}

void LLCStreamEngine::processLoadComputeSlice(LLCDynStreamPtr dynS,
                                              LLCStreamSlicePtr slice) {
  this->tryStartComputeLoadComputeSlice(dynS, slice);

  const auto &sliceId = slice->getSliceId();
  bool allLoadComputeValueReady = true;
  for (auto elemIdx = sliceId.getStartIdx(); elemIdx < sliceId.getEndIdx();
       ++elemIdx) {
    auto elem = dynS->getElemPanic(elemIdx, "ProcessLoadComputeSlice");
    if (!elem->isComputedValueReady()) {
      allLoadComputeValueReady = false;
    }
  }
  if (!allLoadComputeValueReady) {
    return;
  }

  // Check if need to send back the LoadComputeValue back to core.
  auto S = dynS->getStaticS();
  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  Addr paddr = 0;
  assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
  auto paddrLine = makeLineAddress(paddr);
  DataBlock loadValueBlock;
  int payloadSize = 0;
  for (auto elemIdx = sliceId.getStartIdx(); elemIdx < sliceId.getEndIdx();
       ++elemIdx) {
    auto elem = dynS->getElemPanic(elemIdx, "ProcessLoadComputeSlice");
    const auto &loadComputeValue = elem->getComputedValue();

    int sliceOffset;
    int elemOffset;
    int overlapSize = elem->computeLoadComputeOverlap(
        sliceId.vaddr, RubySystem::getBlockSizeBytes(), sliceOffset,
        elemOffset);
    if (overlapSize == 0) {
      continue;
    }
    payloadSize += S->getCoreElementSize();

    /**
     * Copy the value from LoadComputeValue to LoadValueBlock.
     * For simplicity we just copy MemElementSize, but the real data
     * size should be CoreElementSize. But this is OK as long as the
     * user only uses the first CoreElementSize bytes' data.
     */
    assert(elemOffset < 64 && "What");
    auto valuePtr = loadComputeValue.uint8Ptr(elemOffset);
    loadValueBlock.setData(valuePtr, sliceOffset, overlapSize);
  }

  // TotalOverlapSize should never exceed the line size.
  if (payloadSize > RubySystem::getBlockSizeBytes()) {
    payloadSize = RubySystem::getBlockSizeBytes();
  }

  if (coreNeedValue) {
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(), payloadSize /* payloadSize */,
        0 /* Line offset */);
    S->statistic.numLLCSentSlice++;
    S->se->numLLCSentSlice++;
    LLC_SLICE_DPRINTF(sliceId,
                      "Send LoadComputeValue to MLC: PAddrLine %#x "
                      "Data %s PayloadSize %d.\n",
                      paddrLine, loadValueBlock, payloadSize);
  } else {
    LLC_SLICE_DPRINTF(sliceId,
                      "Not send LoadComputeValue to MLC: PAddrLine %#x Data %s "
                      "PayloadSize %d.\n",
                      paddrLine, loadValueBlock, payloadSize);
  }

  /**
   * Send the data to receiver stream.
   */
  for (const auto &edge : dynS->sendToEdges) {
    LLC_SLICE_DPRINTF(
        sliceId,
        "Send LoadComputeValue to RecevStream: %s Data %s PayloadSize %d.\n",
        edge.data->dynamicId, loadValueBlock, payloadSize);
    this->issueStreamDataToLLC(dynS, sliceId, loadValueBlock, edge,
                               payloadSize);
  }
  slice->setLoadComputeValueSent();
}

void LLCStreamEngine::processDirectAtomicSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  auto S = dynS->getStaticS();
  assert(S->isAtomicComputeStream() && S->isDirectMemStream() &&
         "Not DirectAtomicComputeStream.");
  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  auto numMicroOps = S->getComputationNumMicroOps();

  // The final value return to the core.
  DataBlock loadValueBlock;
  uint32_t totalPayloadSize = 0;
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto element = dynS->getElemPanic(idx, "Process slice of AtomicS");
    LLC_SLICE_DPRINTF(sliceId, "TriggerAtomic for elem %llu vaddr %#x.\n",
                      element->idx, element->vaddr);
    if (!element->isReady()) {
      // Not ready yet. Break.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu not ready while we are triggering update.",
                      idx);
    }
    if (!element->areBaseElemsReady()) {
      // We are still waiting for base elements.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu has base element not ready when updating.",
                      idx);
    }
    uint32_t payloadSize = 0;
    this->triggerAtomic(dynS, element, sliceId, loadValueBlock, payloadSize);
    totalPayloadSize += payloadSize;

    /**
     * IndirectAtomics are modelled by ComputeEngine, thus we record
     * DirectAtomicStats here.
     * For now we don't bother add the stats to the core in my bank.
     */
    S->recordComputationInCoreStats();
    this->controller->m_statLLCPerformedAtomics++;
    this->controller->m_statLLCScheduledComputation++;
    this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
    this->recordComputationMicroOps(S);
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  } else {
    this->issueStreamAckToMLC(sliceId);
  }
}

void LLCStreamEngine::processIndirectAtomicSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  auto S = dynS->getStaticS();
  assert(S->isAtomicComputeStream() && !S->isDirectMemStream() &&
         "Not IndirectAtomicComputeStream.");
  /**
   * Speical case for the second request for IndirectAtomicStream
   * with core usage. We just need to send back an Ack.
   */
  auto elemIdx = sliceId.getStartIdx();
  auto elem = dynS->getElemPanic(elemIdx,
                                 "Check IndirectAtomicElement second request.");
  if (elem->hasFirstIndirectAtomicReqSeen()) {
    // This is the second time, should already be handled in
    // receiveStreamIndirectRequest().
    LLC_SLICE_PANIC(sliceId, "[Commit] Atomic should be release when "
                             "receiving the second request.");
  }

  LLC_SLICE_DPRINTF(sliceId,
                    "[IndirectAtomic] Schedule computation for vaddr %#x.\n",
                    elem->vaddr);
  if (!elem->isReady()) {
    // Not ready yet. Break.
    LLC_SLICE_PANIC(sliceId, "Element not ready while triggering atomic.");
  }
  if (!elem->areBaseElemsReady()) {
    // We are still waiting for base elements.
    LLC_SLICE_PANIC(sliceId, "Base element not ready when process atomic.");
  }

  /**
   * Push ready computation.
   */
  elem->indirectAtomicSliceId = sliceId;
  this->pushReadyComputation(elem);
}

void LLCStreamEngine::postProcessIndirectAtomicSlice(
    LLCDynStreamPtr dynS, const LLCStreamElementPtr &element) {

  const auto &sliceId = element->indirectAtomicSliceId;
  assert(sliceId.isValid() && "Invalid IndirectAtomic slice id.");

  // The final value return to the core.
  DataBlock loadValueBlock;
  uint32_t totalPayloadSize = 0;

  uint32_t payloadSize = 0;
  this->triggerAtomic(dynS, element, sliceId, loadValueBlock, payloadSize);
  totalPayloadSize += payloadSize;

  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(
        sliceId, "[IndirectAtomic] Send Data to MLC: PAddrLine %#x Data %s.\n",
        paddrLine, loadValueBlock);
  } else {
    this->issueStreamAckToMLC(sliceId);
  }

  /**
   * Try to release element if we don't need to issue after commit.
   */
  if (!dynS->shouldIssueAfterCommit()) {
    while (!dynS->idxToElementMap.empty()) {
      auto elementIter = dynS->idxToElementMap.begin();
      const auto &element = elementIter->second;
      if (!element->isComputationDone()) {
        LLC_ELEMENT_DPRINTF(
            element, "[IndirectAtomic] Cannot release ComputationDone %d.\n",
            element->isComputationDone());
        break;
      }
      dynS->eraseElem(elementIter);
    }
  }
}

void LLCStreamEngine::processIndirectUpdateSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId,
    const DataBlock &storeValueBlock) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  auto S = dynS->getStaticS();
  assert(S->isUpdateStream() && !S->isDirectMemStream() &&
         "Not IndirectUpdateStream.");
  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  // The final value return to the core.
  DataBlock loadValueBlock;
  uint32_t totalPayloadSize = 0;
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto element = dynS->getElemPanic(idx, "Process slice of IndUpdateS");
    LLC_SLICE_DPRINTF(sliceId, "TriggerIndUpdate for elem %llu vaddr %#x.\n",
                      element->idx, element->vaddr);
    if (!element->isReady()) {
      // Not ready yet. Break.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu not ready while we are triggering update.",
                      idx);
    }
    if (!element->areBaseElemsReady()) {
      // We are still waiting for base elements.
      LLC_SLICE_PANIC(sliceId,
                      "Element %llu has base element not ready when updating.",
                      idx);
    }
    uint32_t payloadSize = 0;
    this->triggerUpdate(dynS, element, sliceId, storeValueBlock, loadValueBlock,
                        payloadSize);
    totalPayloadSize += payloadSize;
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {
    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  } else {
    bool forceIdea = dynS->isNextIdeaAck();
    dynS->ackedOneSlice();
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
}

bool LLCStreamEngine::tryProcessDirectUpdateSlice(LLCDynStreamPtr dynS,
                                                  LLCStreamSlicePtr slice) {
  const auto &sliceId = slice->getSliceId();

  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto elem =
        dynS->getElemPanic(idx, "Check base elements ready for update.");
    if (!elem->areBaseElemsReady()) {
      // We are still waiting for base elements.
      return false;
    }
    /**
     * Update slice also require the element to be ready.
     * Although this has responded, a multi-slice element may still
     * not be ready.
     */
    if (!elem->isReady()) {
      LLC_ELEMENT_DPRINTF(elem, "[Update] Slice blocked by me.\n");
      return false;
    }
  }

  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto elem = dynS->getElemPanic(idx, "Process UpdateStream");
    LLC_SLICE_DPRINTF(sliceId, "TriggerDirectUpdate for elem %llu vaddr %#x.\n",
                      elem->idx, elem->vaddr);
    if (!elem->isComputedValueReady() && !elem->isComputationScheduled()) {
      this->pushReadyComputation(elem, true /* TryVectorize */);
    }
  }

  slice->setProcessed();
  return true;
}

bool LLCStreamEngine::tryPostProcessDirectUpdateSlice(LLCDynStreamPtr dynS,
                                                      LLCStreamSlicePtr slice) {
  /**
   * We hato to check that all elements are computed.
   */
  const auto &sliceId = slice->getSliceId();
  for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
    auto element = dynS->getElemPanic(idx, "Process UpdateStream");
    LLC_SLICE_DPRINTF(sliceId,
                      "TryPostProcess for UpdateElem %llu vaddr %#x.\n",
                      element->idx, element->vaddr);
    if (!element->isComputationDone()) {
      return false;
    }
  }
  this->postProcessDirectUpdateSlice(dynS, sliceId);
  return true;
}

void LLCStreamEngine::postProcessDirectUpdateSlice(
    LLCDynStreamPtr dynS, const DynStreamSliceId &sliceId) {

  /**
   * First we check whether we should send back value or ack.
   * Also we do not handle elements in-order, as we want the message
   * sent back to MLC is correctly sliced.
   */
  bool coreNeedValue = false;
  auto dynCoreS = dynS->getCoreDynS();
  if (dynCoreS && dynCoreS->shouldCoreSEIssue()) {
    coreNeedValue = true;
  }

  // This is to make sure traffic to MLC is correctly sliced.
  if (coreNeedValue) {

    /**
     * Construct the returning value from elements.
     */
    DataBlock loadValueBlock;
    uint32_t totalPayloadSize = 0;
    for (auto idx = sliceId.getStartIdx(); idx < sliceId.getEndIdx(); ++idx) {
      auto element = dynS->getElemPanic(idx, "PostProcess UpdateStream");
      LLC_SLICE_DPRINTF(sliceId, "PostDirectUpdate for elem %llu vaddr %#x.\n",
                        element->idx, element->vaddr);
      if (!element->isReady()) {
        // Not ready yet. Break.
        LLC_SLICE_PANIC(
            sliceId,
            "Element %llu not ready while we are post-processing update.", idx);
      }

      /**
       * Send back the overlap value within this line.
       */
      const auto lineSize = RubySystem::getBlockSizeBytes();
      Addr loadBlockVAddrLine = makeLineAddress(sliceId.vaddr);
      int elementOffset = 0;
      int loadBlockOffset = 0;
      auto overlapSize = element->computeOverlap(
          loadBlockVAddrLine, lineSize, loadBlockOffset, elementOffset);
      loadValueBlock.setData(element->getUInt8Ptr(elementOffset),
                             loadBlockOffset, overlapSize);
      totalPayloadSize += overlapSize;
    }

    Addr paddr = 0;
    assert(dynS->translateToPAddr(sliceId.vaddr, paddr));
    auto paddrLine = makeLineAddress(paddr);
    this->issueStreamDataToMLC(
        sliceId, paddrLine,
        loadValueBlock.getData(0, RubySystem::getBlockSizeBytes()),
        RubySystem::getBlockSizeBytes(),
        std::min(totalPayloadSize, RubySystem::getBlockSizeBytes()),
        0 /* Line offset */);
    LLC_SLICE_DPRINTF(sliceId,
                      "Send StreamData to MLC: PAddrLine %#x Data %s.\n",
                      paddrLine, loadValueBlock);
  } else {
    bool forceIdea = dynS->isNextIdeaAck();
    dynS->ackedOneSlice();
    this->issueStreamAckToMLC(sliceId, forceIdea);
  }
}

void LLCStreamEngine::performStore(Addr paddr, int size, const uint8_t *value) {
  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support store stream without BackingStore.");
  assert((paddr % RubySystem::getBlockSizeBytes()) + size <=
             RubySystem::getBlockSizeBytes() &&
         "Can not store to multi-line elements.");
  RequestPtr req =
      std::make_shared<Request>(paddr, size, 0 /* Flags */, 0 /* MasterId */);
  PacketPtr pkt = Packet::createWrite(req);
  pkt->dataStaticConst(value);
  rubySystem->getPhysMem()->functionalAccess(pkt);
  delete pkt;
}

PacketPtr
LLCStreamEngine::createAtomicPacket(Addr vaddr, Addr paddr, int size,
                                    std::unique_ptr<StreamAtomicOp> atomicOp) {
  /**
   * Create the packet.
   */
  MasterID masterId = 0;
  Addr pc = 0;
  int contextId = 0;

  Request::Flags flags;
  flags.set(Request::ATOMIC_RETURN_OP);
  RequestPtr req = std::make_shared<Request>(vaddr, size, flags, masterId, pc,
                                             contextId, std::move(atomicOp));
  req->setPaddr(paddr);
  PacketPtr pkt = Packet::createWrite(req);
  // Fake some data.
  uint8_t *pkt_data = new uint8_t[req->getSize()];
  pkt->dataDynamic(pkt_data);
  return pkt;
}

std::pair<uint64_t, bool> LLCStreamEngine::performStreamAtomicOp(
    LLCDynStreamPtr dynS, LLCStreamElementPtr element, Addr elementPAddr,
    const DynStreamSliceId &sliceId) {
  assert(sliceId.getNumElements() == 1 &&
         "Can not support multi-element atomic op.");
  auto S = dynS->getStaticS();
  auto elementSize = S->getMemElementSize();

  auto rubySystem = this->controller->params()->ruby_system;
  assert(rubySystem->getAccessBackingStore() &&
         "Do not support atomicrmw stream without BackingStore.");
  assert(elementSize <= 8 && "At most 8 byte data.");
  assert((elementPAddr % RubySystem::getBlockSizeBytes()) + elementSize <=
             RubySystem::getBlockSizeBytes() &&
         "Can not atomicrmw to multi-line elements.");

  /**
   * Create the atomic op.
   */
  const auto &formalParams = dynS->configData->storeFormalParams;
  FIFOEntryIdx entryIdx(
      sliceId.getDynStreamId(),
      LLVMDynamicInst::INVALID_SEQ_NUM /* Fake ConfigSeqNum */);
  entryIdx.entryIdx = sliceId.getStartIdx();
  auto getBaseStreamValue = [element](uint64_t baseStreamId) -> StreamValue {
    return element->getBaseStreamValue(baseStreamId);
  };
  auto atomicOp =
      S->setupAtomicOp(entryIdx, elementSize, formalParams, getBaseStreamValue);

  /**
   * Create the packet.
   */
  auto pkt = this->createAtomicPacket(element->vaddr, elementPAddr, elementSize,
                                      std::move(atomicOp));
  /**
   * Send to backing store to perform atomic op.
   */
  rubySystem->getPhysMem()->functionalAccess(pkt);
  LLC_SLICE_DPRINTF_(LLCRubyStreamStore, sliceId,
                     "Functional accessed pkt, isWrite %d, vaddr "
                     "%#x, paddr %#x, size %d.\n",
                     pkt->isWrite(), pkt->req->getVaddr(), pkt->getAddr(),
                     pkt->getSize());

  // Get the loaded value.
  uint64_t loadedValue = 0;
  bool memoryModified = false;
  {
    auto atomicOp = dynamic_cast<StreamAtomicOp *>(pkt->getAtomicOp());
    loadedValue = atomicOp->getLoadedValue().front();
    memoryModified = atomicOp->modifiedMemory();
  }

  // Don't forget to release the packet.
  delete pkt;

  return std::make_pair(loadedValue, memoryModified);
}

void LLCStreamEngine::tryVectorizeElem(LLCStreamElementPtr &elem,
                                       bool tryVectorize) {

  if (!this->controller->myParams->enable_stream_vectorize) {
    return;
  }
  if (elem->size > 32) {
    return;
  }
  if (!tryVectorize && !elem->S->isReduction()) {
    // Apply reduction when required or on ReduceStream.
    return;
  }

  /**
   * If we enabled vectorization, and this is not the first Element in
   * this slice, we mark the element's computation vectorized, so that it
   * is treated as fake computation that does not consume any resources.
   */
  bool shouldVectorized = false;
  if (elem->S->isReduction()) {
    /**
     * Hack: For ReductionStream, each slice has only one element, thus here
     * we approximate by counting how many elements per cache line.
     */
    auto elemsPerLine = RubySystem::getBlockSizeBytes() / elem->size;
    if (elem->idx % elemsPerLine != 0) {
      shouldVectorized = true;
    }
  } else if (elem->idx != elem->getSliceAt(elem->getNumSlices() - 1)
                              ->getSliceId()
                              .getStartIdx()) {
    shouldVectorized = true;
  }

  if (shouldVectorized) {
    LLC_ELEMENT_DPRINTF(elem, "[PushReadyCmp] Vectorized.\n");
    elem->vectorizedComputation();
  }
}

void LLCStreamEngine::pushReadyComputation(LLCStreamElementPtr &elem,
                                           bool tryVectorize) {
  LLC_ELEMENT_DPRINTF(elem, "[PushReadyCmp] Ready %d Infly %d TryVec %d.\n",
                      this->readyComputations.size(),
                      this->inflyComputations.size(), tryVectorize);
  assert(elem->areBaseElemsReady() && "Element is not ready yet.");
  if (!elem->isNDCElement) {
    auto dynS = LLCDynStream::getLLCStream(elem->strandId);
    if (!dynS) {
      LLC_ELEMENT_DPRINTF(elem, "Skip computation as Stream is released.\n");
      return;
    }
    if (!dynS->hasComputation()) {
      LLC_ELEMENT_PANIC(elem, "Stream has no computation.");
    }

    this->tryVectorizeElem(elem, tryVectorize);

    if (!elem->isComputationVectorized()) {
      dynS->incompleteComputations++;
    }

    const auto seMachineID = this->controller->getMachineID();
    auto floatMachineType = dynS->getFloatMachineTypeAtElem(elem->idx);
    if (seMachineID.getType() != floatMachineType) {
      LLC_ELEMENT_PANIC(elem, "[PushReadyCmp] Offload %s != SE MachineType %s.",
                        floatMachineType, seMachineID);
    }
  }
  if (elem->isComputationVectorized()) {
    this->skipComputation(elem);
  } else {
    elem->scheduledComputation(this->curCycle());
    this->readyComputations.emplace_back(elem);
    this->scheduleEvent(Cycles(1));
  }
}

void LLCStreamEngine::skipComputation(LLCStreamElementPtr &elem) {
  assert(elem->isComputationVectorized() && "Skip Compute Vectorized Elem.");
  assert(!elem->isNDCElement && "Skip NDC Elem.");
  elem->scheduledComputation(this->curCycle());

  auto dynS = LLCDynStream::getLLCStream(elem->strandId);
  assert(dynS && "No DynS for SkipComputation");
  assert(!dynS->isIndirectReduction() &&
         "IndReduction should never be skipped.");

  LLC_ELEMENT_DPRINTF(elem, "Skip computation. Vectorized %d.\n",
                      elem->isComputationVectorized());
  StreamValue result = dynS->computeElemValue(elem);
  dynS->completeComputation(this, elem, result);
}

void LLCStreamEngine::pushInflyComputation(LLCStreamElementPtr &elem,
                                           const StreamValue &result,
                                           Cycles &latency) {
  const int maxInflyCmp =
      this->controller->myParams->llc_stream_engine_max_infly_computation;
  assert(this->numInflyRealCmps < maxInflyCmp && "Too many infly results.");
  assert(latency < 1024 && "Latency too long.");

  if (!elem->isComputationVectorized()) {
    // This is a real computation.
    auto S = elem->S;
    // For now we don't bother add the stats to the core in my bank.
    S->recordComputationInCoreStats();

    int numMicroOps = S->getComputationNumMicroOps();
    auto &statistic = S->statistic;
    this->controller->m_statLLCScheduledComputation++;
    this->controller->m_statLLCScheduledComputeMicroOps += numMicroOps;
    this->recordComputationMicroOps(S);
    statistic.numLLCComputation++;
    statistic.numLLCComputationComputeLatency += latency;
    statistic.numLLCComputationWaitLatency +=
        this->curCycle() - elem->getComputationScheduledCycle();

    this->numInflyRealCmps++;
  }

  Cycles readyCycle = this->curCycle() + latency;
  for (auto iter = this->inflyComputations.rbegin(),
            end = this->inflyComputations.rend();
       iter != end; ++iter) {
    if (iter->readyCycle <= readyCycle) {
      this->inflyComputations.emplace(iter.base(), elem, result, readyCycle);
      return;
    }
  }
  this->inflyComputations.emplace_front(elem, result, readyCycle);
}

void LLCStreamEngine::recordComputationMicroOps(Stream *S) {
  auto microOps = S->getComputationNumMicroOps();
  auto category = S->getComputationCategory();

#define record_micro_ops(Addr, Compute)                                        \
  if (category.first == Stream::ComputationType::Compute &&                    \
      category.second == Stream::ComputationAddressPattern::Addr) {            \
    this->controller->m_statLLCScheduled##Addr##Compute##MicroOps += microOps; \
    return;                                                                    \
  }
  record_micro_ops(Affine, LoadCompute);
  record_micro_ops(Affine, StoreCompute);
  record_micro_ops(Affine, AtomicCompute);
  record_micro_ops(Affine, Update);
  record_micro_ops(Affine, Reduce);
  record_micro_ops(Indirect, LoadCompute);
  record_micro_ops(Indirect, StoreCompute);
  record_micro_ops(Indirect, AtomicCompute);
  record_micro_ops(Indirect, Update);
  record_micro_ops(Indirect, Reduce);
  record_micro_ops(PointerChase, LoadCompute);
  record_micro_ops(PointerChase, StoreCompute);
  record_micro_ops(PointerChase, AtomicCompute);
  record_micro_ops(PointerChase, Update);
  record_micro_ops(PointerChase, Reduce);
  record_micro_ops(MultiAffine, LoadCompute);
  record_micro_ops(MultiAffine, StoreCompute);
  record_micro_ops(MultiAffine, AtomicCompute);
  record_micro_ops(MultiAffine, Update);
  record_micro_ops(MultiAffine, Reduce);
#undef record_micro_ops
}

void LLCStreamEngine::startComputation() {
  int startedComputation = 0;
  const int computationWidth =
      this->controller->getLLCStreamEngineComputeWidth();
  const int maxInflyComputation =
      this->controller->myParams->llc_stream_engine_max_infly_computation;
  while (startedComputation < computationWidth &&
         !this->readyComputations.empty() &&
         this->numInflyRealCmps < maxInflyComputation) {
    auto &elem = this->readyComputations.front();
    auto S = elem->S;

    Cycles latency = S->getEstimatedComputationLatency();
    if (auto llcDynS = LLCDynStream::getLLCStream(elem->strandId)) {
      if (llcDynS->configData->overrideComputeLatency > 0) {
        latency = Cycles(llcDynS->configData->overrideComputeLatency);
      }
    }

    if (!this->controller->myParams->has_scalar_alu || S->isSIMDComputation()) {
      /**
       * Here we charge extra latency for accessing the core.
       * 1. If this is SIMD operation.
       * 2. If we disable scalar ALU in the stream engine.
       */
      latency += Cycles(this->controller->myParams->llc_access_core_simd_delay);
    }

    auto forceZeroLat =
        this->controller->isLLCStreamEngineZeroComputeLatencyEnabled();
    if (forceZeroLat) {
      latency = Cycles(0);
    }
    /**
     * For IndirectReductionStream, we separate out charging the
     * latency from the real computation. Here we charge the latency,
     * but the real computation is left in completeComputation().
     */
    StreamValue result;

    if (elem->isNDCElement) {
      /**
       * StreamNDC elements are handled by LLCStreamNDCController.
       */
      assert(!elem->isComputationVectorized() && "NDC cannot be vectorized.");
      if (!this->ndcController->computeStreamElementValue(elem, result)) {
        LLC_ELEMENT_DPRINTF(elem,
                            "Discard NDC computation as stream is released.\n");
        this->readyComputations.pop_front();
        continue;
      }
    } else {
      /**
       * Normal Stream Computing.
       */
      auto dynS = LLCDynStream::getLLCStream(elem->strandId);
      if (!dynS) {
        LLC_ELEMENT_DPRINTF(elem,
                            "Discard computation as stream is released.\n");
        this->readyComputations.pop_front();
        continue;
      }

      if (!dynS->isIndirectReduction()) {
        LLC_ELEMENT_DPRINTF(
            elem,
            "Start computation. Latency %llu (ZeroLat %d) Vectorized %d.\n",
            latency, forceZeroLat, elem->isComputationVectorized());
        result = dynS->computeElemValue(elem);
      } else {
        LLC_ELEMENT_DPRINTF(elem,
                            "Start IndirectReduction fake computation. Latency "
                            "%llu (ZeroLat %d).\n",
                            latency, forceZeroLat);
        result.fill(0);
      }
    }
    this->pushInflyComputation(elem, result, latency);

    this->readyComputations.pop_front();

    /**
     * VectorizedElem does not count as StartedComputation.
     */
    if (!elem->isComputationVectorized()) {
      startedComputation++;
    }
  }
}

void LLCStreamEngine::completeComputation() {
  // We don't charge complete width.
  auto curCycle = this->curCycle();
  while (!this->inflyComputations.empty()) {
    auto &computation = this->inflyComputations.front();
    auto &elem = computation.elem;
    if (computation.readyCycle > curCycle) {
      LLC_ELEMENT_DPRINTF(elem,
                          "Cannot complete computation, readyCycle "
                          "%llu, curCycle %llu.\n",
                          computation.readyCycle, curCycle);
      break;
    }
    LLC_ELEMENT_DPRINTF(elem, "Complete computation.\n");
    if (elem->isNDCElement) {
      this->ndcController->completeComputation(elem, computation.result);
    } else {
      auto dynS = LLCDynStream::getLLCStream(elem->strandId);
      if (dynS) {
        dynS->completeComputation(this, elem, computation.result);
      } else {
        LLC_ELEMENT_DPRINTF(
            elem, "Discard computation result as stream is released.\n");
      }
    }
    if (!elem->isComputationVectorized()) {
      // This is not a fake Computation.
      this->numInflyRealCmps--;
    }
    this->inflyComputations.pop_front();
  }
}

void LLCStreamEngine::incrementIssueSlice(StreamStatistic &statistic) {
  if (this->myMachineType() == MachineType_Directory) {
    statistic.numMemIssueSlice++;
  } else {
    statistic.numLLCIssueSlice++;
  }
}
