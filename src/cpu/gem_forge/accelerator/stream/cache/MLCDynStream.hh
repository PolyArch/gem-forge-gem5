#ifndef __CPU_GEM_FORGE_MLC_DYN_STREAM_H__
#define __CPU_GEM_FORGE_MLC_DYN_STREAM_H__

#include "DynStreamAddressRange.hh"

#include "cpu/gem_forge/accelerator/stream/stream.hh"

#include "mem/ruby/common/DataBlock.hh"

// Generated by slicc.
#include "mem/ruby/protocol/ResponseMsg.hh"

#include <list>

namespace gem5 {

namespace ruby {
class AbstractStreamAwareController;
class MessageBuffer;
} // namespace ruby

class MLCDynStream {
public:
  MLCDynStream(CacheStreamConfigureDataPtr _configData,
               ruby::AbstractStreamAwareController *_controller,
               ruby::MessageBuffer *_responseMsgBuffer,
               ruby::MessageBuffer *_requestToLLCMsgBuffer, bool _isMLCDirect);

  virtual ~MLCDynStream();

  Stream *getStaticStream() const { return this->stream; }

  const DynStrandId &getDynStrandId() const { return this->strandId; }
  const DynStreamId &getDynStreamId() const {
    return this->strandId.dynStreamId;
  }
  DynStream *getCoreDynS() const {
    return this->getStaticStream()->getDynStream(this->getDynStreamId());
  }

  bool getIsPseudoOffload() const { return this->isPseudoOffload; }
  uint64_t getFirstFloatElemIdx() const {
    return this->config->floatPlan.getFirstFloatElementIdx();
  }

  virtual const DynStreamId &getRootDynStreamId() const {
    // By default this we are the root stream.
    return this->getDynStreamId();
  }

  /**
   * Helper function to check if a slice is valid within this stream context.
   * So far always valid, except the first element of indirect stream that is
   * behind by one iteration.
   */
  virtual bool isSliceValid(const DynStreamSliceId &sliceId) const {
    return true;
  }

  /**
   * Get where is the RemoteStream is at the end of current allocated credits.
   */
  virtual std::pair<Addr, ruby::MachineType>
  getRemoteTailPAddrAndMachineType() const {
    panic("Should only call this on direct stream.");
  }

  virtual void receiveStreamData(const DynStreamSliceId &sliceId,
                                 const ruby::DataBlock &dataBlock,
                                 Addr paddrLine, bool isAck) = 0;
  void recvCoreReq(const DynStreamSliceId &sliceId);
  void recvCoreReqHit(const DynStreamSliceId &sliceId);

  /**
   * Before end the stream, we have make dummy response to the request
   * we have seen to make the ruby system happy.
   */
  void endStream();

  uint64_t getHeadSliceIdx() const { return this->headSliceIdx; }
  uint64_t getTailSliceIdx() const { return this->tailSliceIdx; }

  void receiveStreamRange(const DynStreamAddressRangePtr &range);
  virtual void receiveStreamDone(const DynStreamSliceId &sliceId);

  void scheduleAdvanceStream();

  /**
   * Whether this stream requires range-based syncrhonization.
   */
  bool shouldRangeSync() const { return this->config->rangeSync; }

  const std::vector<CacheStreamConfigureData::DepEdge> &getSendToEdges() const {
    return this->sendToEdges;
  }

  /**
   * API for this to check if overflowed.
   */
  virtual bool hasOverflowed() const = 0;
  virtual int64_t getTotalTripCount() const = 0;
  virtual bool hasTotalTripCount() const = 0;
  virtual int64_t getInnerTripCount() const = 0;
  virtual bool hasInnerTripCount() const = 0;
  virtual void breakOutLoop(int64_t totalTripCount) = 0;
  bool hasLoopBound() const {
    return this->config->loopBoundCallback != nullptr;
  }

  bool isWaitingAck() const { return this->isWaiting == WaitType::Ack; }
  bool isWaitingData() const { return this->isWaiting == WaitType::Data; }
  bool isWaitingNothing() const { return this->isWaiting == WaitType::Nothing; }

  using ElementCallback = std::function<void(const DynStreamId &, uint64_t)>;
  bool isElementAcked(uint64_t strandElemIdx) const;
  void registerElementAckCallback(uint64_t elementIdx,
                                  ElementCallback callback);

  CacheStreamConfigureDataPtr getConfig() { return this->config; }

protected:
  Stream *stream;
  DynStrandId strandId;
  CacheStreamConfigureDataPtr config;
  bool isPointerChase;
  bool isPUMPrefetch;
  bool isPseudoOffload;
  const bool isMLCDirect;

  std::vector<CacheStreamConfigureData::DepEdge> sendToEdges;

  ruby::AbstractStreamAwareController *controller;
  ruby::MessageBuffer *responseMsgBuffer;
  ruby::MessageBuffer *requestToLLCMsgBuffer;
  uint64_t maxNumSlices;

  /**
   * Represent an allocated stream slice at MLC.
   * Used as a meeting point for the request from core
   * and data from LLC stream engine.
   */
  struct MLCStreamSlice {
    DynStreamSliceId sliceId;
    ruby::DataBlock dataBlock;
    // Whether the core's request is already here.
    bool dataReady;
    enum CoreStatusE {
      NONE = 0,
      WAIT_DATA, // The core is waiting the data.
      WAIT_ACK,  // The core is waiting the ack.
      ACK_READY, // The ack is ready, waiting to be reported to core in order.
      DONE,
      FAULTED,
      NUM_CORE_STATUS
    };
    CoreStatusE coreStatus;
    // For debug purpose, we also remember core's request sliceId.
    DynStreamSliceId coreSliceId;
    // Statistics.
    Cycles dataReadyCycle;
    Cycles coreWaitCycle;

    MLCStreamSlice(const DynStreamSliceId &_sliceId)
        : sliceId(_sliceId), dataBlock(), dataReady(false),
          coreStatus(CoreStatusE::NONE) {}

    void setData(const ruby::DataBlock &dataBlock, Cycles currentCycle) {
      assert(!this->dataReady && "Data already ready.");
      this->dataBlock = dataBlock;
      this->dataReady = true;
      this->dataReadyCycle = currentCycle;
    }

    static std::string convertCoreStatusToString(CoreStatusE status);
  };

  std::list<MLCStreamSlice> slices;
  using SliceIter = std::list<MLCStreamSlice>::iterator;
  // Slice index of allocated [head, tail).
  uint64_t headSliceIdx;
  uint64_t tailSliceIdx;

  EventFunctionWrapper advanceStreamEvent;

  virtual void advanceStream() = 0;
  void makeResponse(MLCStreamSlice &slice);
  void makeAck(MLCStreamSlice &slice);

  /**
   * Find the correct slice for a core request.
   * Used in receiveStreamRequest() and recvCoreReqHit().
   */
  virtual SliceIter
  findSliceForCoreRequest(const DynStreamSliceId &sliceId) = 0;

  /**
   * Helper function to translate the vaddr to paddr.
   */
  Addr translateVAddr(Addr vaddr) const;

  /**
   * Helper function to direct read data from memory.
   */
  void readBlob(Addr vaddr, uint8_t *data, int size) const;

  /**
   * Pop slices. Flags to remember why we are blocked.
   * @return whether popped at least one slice.
   */
  bool tryPopStream();
  void popOneSlice();
  bool popBlocked = false;

  bool checkRecvDynSForPop(const DynStreamSliceId &sliceId);

  /**
   * These function checks if we are waiting for something.
   */
  enum WaitType {
    Nothing,
    Ack,
    Data,
  };
  std::string to_string(WaitType type) {
    switch (type) {
    case WaitType::Nothing:
      return "Nothing";
    case WaitType::Ack:
      return "Ack";
    case WaitType::Data:
      return "Data";
    default:
      return "Unknown";
    }
  }
  WaitType isWaiting;
  WaitType checkWaiting() const;

  bool isCoreDynSReleased() const { return !this->getCoreDynS(); }

  /**
   * This remember the received StreamRange.
   */
  std::list<DynStreamAddressRangePtr> receivedRanges;

  /**
   * @brief Remember the callbacks.
   */
  using ElementCallbackList = std::list<ElementCallback>;
  std::map<uint64_t, ElementCallbackList> elementAckCallbacks;

public:
  /**
   * A helper function to dump some basic status of the stream when panic.
   */
  void panicDump() const;

  Cycles curCycle() const { return this->controller->curCycle(); }

  /**
   * Sample some statistic.
   */
  virtual void sample() const;

  /**
   * Get the next credit element idx.
   */
  virtual uint64_t getNextCreditElemIdx() const = 0;

  /**
   * State to serialize the LLCStreamLoopBound results.
   */
  uint64_t nextLoopBoundDoneElemIdx = 0;
  std::map<uint64_t, bool> loopBoundResults;
  void receiveStreamLoopBoundResult(uint64_t elemIdx, bool brokenOut);
  void advanceStreamLoopBound();

  // This stream has been cut by LLCStreamBound.
  bool loopBoundBrokenOut = false;

};

} // namespace gem5

#endif
