#include "MLCDynamicDirectStream.hh"
#include "LLCStreamEngine.hh"
#include "MLCDynamicIndirectStream.hh"
#include "cpu/gem_forge/accelerator/stream/coalesced_stream.hh"

// Generated by slicc.
#include "mem/ruby/protocol/CoherenceMsg.hh"
#include "mem/ruby/protocol/RequestMsg.hh"
#include "mem/simple_mem.hh"

#include "mem/ruby/slicc_interface/AbstractStreamAwareController.hh"

#include "cpu/gem_forge/llvm_trace_cpu.hh"

#include "base/trace.hh"
#include "debug/MLCRubyStream.hh"

#define DEBUG_TYPE MLCRubyStream
#include "../stream_log.hh"

MLCDynamicDirectStream::MLCDynamicDirectStream(
    CacheStreamConfigureData *_configData,
    AbstractStreamAwareController *_controller,
    MessageBuffer *_responseMsgBuffer, MessageBuffer *_requestToLLCMsgBuffer,
    const std::vector<MLCDynamicIndirectStream *> &_indirectStreams)
    : MLCDynamicStream(_configData, _controller, _responseMsgBuffer,
                       _requestToLLCMsgBuffer),
      slicedStream(_configData, true /* coalesceContinuousElements */),
      llcTailSliceIdx(0), indirectStreams(_indirectStreams) {

  // Initialize the llc bank.
  assert(_configData->initPAddrValid && "InitPAddr should be valid.");
  this->tailPAddr = _configData->initPAddr;
  this->tailSliceLLCBank = this->mapPAddrToLLCBank(_configData->initPAddr);

  // Set the base stream for indirect streams.
  for (auto dynIS : this->indirectStreams) {
    dynIS->setBaseStream(this);
  }

  // Initialize the buffer for some slices.
  // Since the LLC is bounded by the credit, it's sufficient to only check
  // hasOverflowed() at MLC level.
  while (this->tailSliceIdx < this->maxNumSlices &&
         !this->slicedStream.hasOverflowed()) {
    this->allocateSlice();
  }

  this->llcTailSliceIdx = this->tailSliceIdx;
  this->llcTailPAddr = this->tailPAddr;
  this->llcTailSliceLLCBank = this->tailSliceLLCBank;

  // Set the CacheStreamConfigureData to inform the LLC stream engine
  // initial credit.
  _configData->initAllocatedIdx = this->llcTailSliceIdx;

  MLC_S_DPRINTF("InitAllocatedSlice %d overflowed %d.\n", this->llcTailSliceIdx,
                this->slicedStream.hasOverflowed());
}

void MLCDynamicDirectStream::advanceStream() {

  this->popStream();
  /**
   * In order to synchronize the direct/indirect stream, we want to make sure
   * that the direct stream is only ahead of the indirect stream by a reasonable
   * distance.
   */
  uint64_t indirectSlices = 0;
  for (auto dynIS : this->indirectStreams) {
    assert(dynIS->getTailSliceIdx() >= dynIS->getHeadSliceIdx() &&
           "Illegal Head/TailSliceIdx.\n");
    indirectSlices = std::max(
        dynIS->getTailSliceIdx() - dynIS->getHeadSliceIdx(), indirectSlices);
  }
  uint64_t indirectSlicesThreshold =
      2 * this->maxNumSlices *
      std::max(static_cast<uint64_t>(1),
               static_cast<uint64_t>(this->slicedStream.getElementPerSlice()));
  MLC_S_DPRINTF("IndirectSlices %llu Threshold %llu.\n", indirectSlices,
                indirectSlicesThreshold);
  // Of course we need to allocate more slices.
  if (indirectSlices < indirectSlicesThreshold) {
    while (this->tailSliceIdx - this->headSliceIdx < this->maxNumSlices &&
           !this->hasOverflowed()) {
      // Although wierd, do not allocate more slices than indirect stream to
      // avoid running too much ahead.
      // TODO: Make this more robustic.
      // bool waitForIndirectStream = false;
      // for (auto dynIS : this->indirectStreams) {
      //   if (dynIS->getTailSliceIdx() - dynIS->getHeadSliceIdx() >
      //       this->maxNumSlices * 8) {
      //     waitForIndirectStream = true;
      //     break;
      //   }
      // }
      // if (waitForIndirectStream) {
      //   break;
      // }
      this->allocateSlice();
    }
  }

  // We may need to schedule advance stream if the first slice is FAULTED,
  // as no other event will cause it to be released.
  // Same for DONE elements because we may have no core user and not receive
  // data From LLC.
  if (!this->slices.empty()) {
    auto frontCoreStatus = this->slices.front().coreStatus;
    if (frontCoreStatus == MLCStreamSlice::CoreStatusE::FAULTED ||
        frontCoreStatus == MLCStreamSlice::CoreStatusE::DONE) {
      this->scheduleAdvanceStream();
    }
  }

  /**
   * There are two cases we need to send the token:
   * 1. We have allocated more half the buffer size.
   * 2. The stream has overflowed.
   * 3. The llc stream is cutted.
   */
  if (!this->llcCutted) {
    if (!this->slicedStream.hasOverflowed()) {
      if (this->tailSliceIdx - this->llcTailSliceIdx > this->maxNumSlices / 2) {
        this->sendCreditToLLC();
      }
    } else {
      if (this->tailSliceIdx > this->llcTailSliceIdx) {
        this->sendCreditToLLC();
      }
    }
  } else {
    if (this->llcCutSliceIdx > this->llcTailSliceIdx) {
      this->sendCreditToLLC();
    }
  }
}

void MLCDynamicDirectStream::allocateSlice() {
  auto sliceId = this->slicedStream.getNextSlice();
  MLC_SLICE_DPRINTF(sliceId, "Allocated %#x.\n", sliceId.vaddr);

  this->slices.emplace_back(sliceId);
  this->stream->statistic.numMLCAllocatedSlice++;

  // Update the llc cut information.
  if (this->llcCutLineVAddr == sliceId.vaddr) {
    // This should be cutted.
    this->llcCutSliceIdx = this->tailSliceIdx;
    this->llcCutted = true;
  }

  // Try to handle faulted slice.
  Addr paddr;
  auto cpuDelegator = this->getStaticStream()->getCPUDelegator();
  if (cpuDelegator->translateVAddrOracle(sliceId.vaddr, paddr)) {
    /**
     * This address is valid.
     * Check if we have reuse data.
     */
    auto reuseIter = this->reuseBlockMap.find(sliceId.vaddr);
    if (reuseIter != this->reuseBlockMap.end()) {
      this->slices.back().setData(reuseIter->second,
                                  this->controller->curCycle());
      this->reuseBlockMap.erase(reuseIter);
    }

    /**
     * ! We cheat here to notify the indirect stream immediately,
     * ! to avoid some complicate problem of managing streams.
     */
    assert(this->controller->params()->ruby_system->getAccessBackingStore() &&
           "This only works with backing store.");
    this->notifyIndirectStream(this->slices.back());

    /**
     * The address is valid, but we check if this stream has no core user,
     * or if this is just a PseudoOffload.
     */
    if (this->isWaitingAck()) {
      this->slices.back().coreStatus = MLCStreamSlice::CoreStatusE::WAIT_ACK;
    } else if (!this->stream->hasCoreUser() || this->isPseudoOffload) {
      // We mark this slice done.
      this->slices.back().coreStatus = MLCStreamSlice::CoreStatusE::DONE;
    }
  } else {
    // This address is invalid. Mark the slice faulted.
    this->slices.back().coreStatus = MLCStreamSlice::CoreStatusE::FAULTED;
  }

  // Try to find where the LLC stream would be at this point.
  this->tailSliceIdx++;
  if (cpuDelegator->translateVAddrOracle(
          this->slicedStream.peekNextSlice().vaddr, paddr)) {
    // The next slice would be valid.
    this->tailPAddr = paddr;
    this->tailSliceLLCBank = this->mapPAddrToLLCBank(paddr);

  } else {
    // This address is invalid.
    // Do not update tailSliceLLCBank as the LLC stream would not move.
  }
}

void MLCDynamicDirectStream::sendCreditToLLC() {
  /**
   * The LLC stream will be at llcTailSliceLLCBank, and we need to
   * update its credit and the new location is tailSliceLLCBank.
   *
   * This will not work for pointer chasing stream.
   */
  assert(this->tailSliceIdx > this->llcTailSliceIdx &&
         "Don't know where to send credit.");

  // Send the flow control.
  MLC_S_DPRINTF("Extended %lu -> %lu, sent credit to LLC%d.\n",
                this->llcTailSliceIdx, this->tailSliceIdx,
                this->llcTailSliceLLCBank.num);
  auto msg = std::make_shared<RequestMsg>(this->controller->clockEdge());
  msg->m_addr = this->llcTailPAddr;
  msg->m_Type = CoherenceRequestType_STREAM_FLOW;
  msg->m_XXNewRewquestor.add(this->controller->getMachineID());
  msg->m_Destination.add(this->llcTailSliceLLCBank);
  msg->m_MessageSize = MessageSizeType_Control;
  DynamicStreamSliceId sliceId;
  sliceId.streamId = this->dynamicStreamId;
  sliceId.lhsElementIdx = this->llcTailSliceIdx;
  sliceId.rhsElementIdx = this->tailSliceIdx;
  msg->m_sliceIds.add(sliceId);

  Cycles latency(1); // Just use 1 cycle latency here.

  if (this->controller->isStreamIdeaFlowEnabled()) {
    auto llcController =
        this->controller->getController(this->llcTailSliceLLCBank);
    auto llcSE = llcController->getLLCStreamEngine();
    llcSE->receiveStreamFlow(sliceId);
  } else {
    this->requestToLLCMsgBuffer->enqueue(
        msg, this->controller->clockEdge(),
        this->controller->cyclesToTicks(latency));
  }

  // Update the record.
  this->llcTailSliceIdx = this->tailSliceIdx;
  this->llcTailPAddr = this->tailPAddr;
  this->llcTailSliceLLCBank = this->tailSliceLLCBank;
}

void MLCDynamicDirectStream::receiveStreamData(
    const DynamicStreamSliceId &sliceId, const DataBlock &dataBlock,
    Addr paddrLine) {
  assert(sliceId.isValid() && "Invalid stream slice id for stream data.");

  auto numElements = sliceId.getNumElements();
  assert(this->dynamicStreamId == sliceId.streamId &&
         "Unmatched dynamic stream id.");
  MLC_SLICE_DPRINTF(sliceId, "Receive data %#x.\n", sliceId.vaddr);

  /**
   * It is possible when the core stream engine runs ahead than
   * the LLC stream engine, and the stream data is delivered after
   * the slice is released. In such case we will ignore the
   * stream data.
   *
   * TODO: Properly handle this with sliceIdx.
   */
  if (this->slices.empty()) {
    assert(this->hasOverflowed() && "No slices when not overflowed yet.");
    // Simply ignore it.
    return;
  } else {
    // TODO: Properly detect that the slice is lagging behind.
    const auto &firstSlice = this->slices.front();
    bool laggingBehind = false;
    if (sliceId.lhsElementIdx < firstSlice.sliceId.lhsElementIdx) {
      laggingBehind = true;
    }
    if (sliceId.lhsElementIdx == firstSlice.sliceId.lhsElementIdx &&
        sliceId.vaddr < firstSlice.sliceId.vaddr) {
      // Due to multi-line elements, we have to also check vaddr.
      laggingBehind = true;
    }
    if (laggingBehind) {
      // The stream data is lagging behind. The slice is already
      // released.
      MLC_SLICE_DPRINTF(sliceId, "Discard as lagging behind %s.\n",
                        firstSlice.sliceId);
      return;
    }
  }

  /**
   * Find the correct stream slice and insert the data there.
   * Here we reversely search for it to save time.
   */
  for (auto slice = this->slices.rbegin(), end = this->slices.rend();
       slice != end; ++slice) {
    if (this->matchSliceId(slice->sliceId, sliceId)) {
      // Found the slice.
      if (slice->sliceId.getNumElements() != numElements) {
        // Also consider llc stream being cut.
        if (this->llcCutLineVAddr > 0 &&
            slice->sliceId.vaddr < this->llcCutLineVAddr) {
          MLC_S_PANIC("Mismatch numElements, incoming %d, slice %d.\n",
                      numElements, slice->sliceId.getNumElements());
        }
      }
      if (slice->dataReady) {
        // Must be from reuse.
      } else {
        slice->setData(dataBlock, this->controller->curCycle());
      }

      // // Notify the indirect stream. Call this after setData().
      // this->notifyIndirectStream(*slice);

      if (slice->coreStatus == MLCStreamSlice::CoreStatusE::WAIT_DATA) {
        this->makeResponse(*slice);
      } else if (slice->coreStatus == MLCStreamSlice::CoreStatusE::WAIT_ACK) {
        // Ack the stream element.
        // TODO: Send the packet back via normal message buffer.
        // hack("Indirect slices acked element %llu size %llu header %llu.\n",
        //      sliceId.lhsElementIdx, this->slices.size(),
        //      this->slices.front().sliceId.lhsElementIdx);
        this->makeAck(*slice);
      }
      this->advanceStream();
      return;
    }
  }

  MLC_SLICE_PANIC(sliceId, "Fail to find the slice. Tail %lu.\n",
                  this->tailSliceIdx);
}

void MLCDynamicDirectStream::notifyIndirectStream(const MLCStreamSlice &slice) {

  if (this->indirectStreams.empty()) {
    return;
  }

  bool hasIndirectAddrStreams = false;
  auto S = this->getStaticStream();
  for (auto dynIS : this->indirectStreams) {
    auto IS = dynIS->getStaticStream();
    if (S->addrDepStreams.count(IS)) {
      hasIndirectAddrStreams = true;
      break;
    }
  }
  if (!hasIndirectAddrStreams) {
    // The indirect stream is not really dependent on me to compute the address.
    // We do not bother to notify indirect streams.
    // TODO: Too hacky?
    return;
  }

  const auto &sliceId = slice.sliceId;
  MLC_SLICE_DPRINTF(sliceId, "Notify IndirectSream.\n");
  for (auto elementIdx = sliceId.lhsElementIdx;
       elementIdx < sliceId.rhsElementIdx; ++elementIdx) {

    // Try to extract the stream data.
    auto elementVAddr = this->slicedStream.getElementVAddr(elementIdx);
    auto elementSize = this->slicedStream.getMemElementSize();
    auto elementLineOffset = elementVAddr % RubySystem::getBlockSizeBytes();

    /**
     * For multi-line base element, we make sure that we only notify the
     * indirect stream once.
     * TODO: Really handle this case.
     */
    if (makeLineAddress(elementVAddr) != makeLineAddress(sliceId.vaddr)) {
      continue;
    }

    std::vector<uint8_t> elementData(elementSize, 0);
    auto rubySystem = this->controller->params()->ruby_system;
    if (rubySystem->getAccessBackingStore()) {
      // Get the data from backing store.
      // Using this API to handle page crossing.
      this->readBlob(elementVAddr, elementData.data(), elementData.size());
      // Addr elementPAddr = this->translateVAddr(elementVAddr);
      // RequestPtr req = std::make_shared<Request>(elementPAddr, elementSize,
      // 0,
      //                                            0 /* MasterId */);
      // PacketPtr pkt = Packet::createRead(req);
      // pkt->dataStatic(elementData.data());
      // rubySystem->getPhysMem()->functionalAccess(pkt);
      // delete pkt;
    } else {
      // Get the data from the cache line.
      assert(elementLineOffset + elementSize <=
                 RubySystem::getBlockSizeBytes() &&
             "Cannot support multi-line element with indirect streams without "
             "backing store.");
      for (auto byteOffset = 0; byteOffset < elementSize; ++byteOffset) {
        elementData[byteOffset] =
            slice.dataBlock.getByte(byteOffset + elementLineOffset);
      }
    }
    MLC_SLICE_DPRINTF(
        sliceId, "Extract element %lu data %s.\n", elementIdx,
        GemForgeUtils::dataToString(elementData.data(), elementData.size()));
    auto CS = dynamic_cast<CoalescedStream *>(S);
    assert(CS && "Every stream should be coalesce stream now.");
    for (auto indirectStream : this->indirectStreams) {
      auto IS = indirectStream->getStaticStream();
      if (S->addrDepStreams.count(IS) == 0) {
        // This indirect stream does not use my data to generate address.
        continue;
      }
      uint64_t baseData = 0;
      int32_t subOffset = 0;
      int32_t subSize = elementSize;
      /**
       * In case the base stream is coalesced, we have to translate the offset
       * for the indirect streams.
       */
      const auto &baseEdges = IS->addrBaseEdges;
      if (baseEdges.empty()) {
        MLC_SLICE_PANIC(sliceId, "IS has no base edges.", baseEdges.size());
      }
      auto baseId = baseEdges.front().toStaticId;
      for (const auto &baseEdge : baseEdges) {
        if (baseEdge.toStaticId != baseId) {
          MLC_SLICE_PANIC(sliceId, "IS has multiple base streams.",
                          baseEdges.size());
        }
      }
      CS->getCoalescedOffsetAndSize(baseId, subOffset, subSize);
      assert(subOffset + subSize <= elementSize &&
             "Overflow of coalesced base element.");
      baseData =
          GemForgeUtils::rebuildData(elementData.data() + subOffset, subSize);
      MLC_SLICE_DPRINTF(sliceId,
                        "Notify indirect base %lu offset "
                        "%d size %d data %llu.\n",
                        elementIdx, subOffset, subSize, baseData);
      indirectStream->receiveBaseStreamData(elementIdx, baseData);
    }
  }
}

MLCDynamicDirectStream::SliceIter
MLCDynamicDirectStream::findSliceForCoreRequest(
    const DynamicStreamSliceId &sliceId) {
  if (this->slices.empty()) {
    MLC_SLICE_PANIC(
        sliceId, "No slices for request, overflowed %d, totalTripCount %lu.\n",
        this->hasOverflowed(), this->getTotalTripCount());
  }
  // Try to allocate more slices.
  while (!this->hasOverflowed() &&
         this->slices.back().sliceId.lhsElementIdx <= sliceId.lhsElementIdx) {
    this->allocateSlice();
  }
  for (auto iter = this->slices.begin(), end = this->slices.end(); iter != end;
       ++iter) {
    /**
     * So far we match them on vaddr.
     * TODO: Really assign the sliceIdx and match that.
     */
    if (iter->sliceId.vaddr == sliceId.vaddr) {
      return iter;
    }
  }

  MLC_S_PANIC("Failed to find slice for core %s.\n", sliceId);
}

void MLCDynamicDirectStream::receiveReuseStreamData(
    Addr vaddr, const DataBlock &dataBlock) {
  MLC_S_DPRINTF("Received reuse block %#x.\n", vaddr);
  /**
   * Somehow it's possible that the slice is already allocated.
   * Search for it.
   */
  bool reused = false;
  for (auto &slice : this->slices) {
    if (slice.sliceId.vaddr == vaddr) {
      reused = true;
      if (!slice.dataReady) {
        slice.setData(dataBlock, this->controller->curCycle());
        if (slice.coreStatus == MLCStreamSlice::CoreStatusE::WAIT_DATA) {
          this->makeResponse(slice);
        }
        this->advanceStream();
      }
      break;
    }
  }
  if (!reused) {
    this->reuseBlockMap.emplace(vaddr, dataBlock).second;
  }
  /**
   * TODO: The current implementation may have multiple reuses, in
   * TODO: the boundary cases when streams overlapped.
   */
}
